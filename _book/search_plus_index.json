{"./":{"url":"./","title":"Introduction","keywords":"","body":"java-note-2020 介绍 Java 学习笔记 all in one 软件架构 软件架构说明 安装教程 xxxx xxxx xxxx 使用说明 xxxx xxxx xxxx 参与贡献 Fork 本仓库 新建 Feat_xxx 分支 提交代码 新建 Pull Request 码云特技 使用 Readme_XXX.md 来支持不同的语言，例如 Readme_en.md, Readme_zh.md 码云官方博客 blog.gitee.com 你可以 https://gitee.com/explore 这个地址来了解码云上的优秀开源项目 GVP 全称是码云最有价值开源项目，是码云综合评定出的优秀开源项目 码云官方提供的使用手册 https://gitee.com/help 码云封面人物是一档用来展示码云会员风采的栏目 https://gitee.com/gitee-stars/ "},"Part-I/Spring/01-IoC.html":{"url":"Part-I/Spring/01-IoC.html","title":"Spring IoC","keywords":"","body":"Spring IoC org.springframework spring-context ${spring.version} 代码配置和 xml 配置 Spring 从 2.x 开始，提供注解，用以简化 XML 配置文件配置 Spring 从 3.x 开始，基于注解功能，提供了全新的配置方式：Java 代码配置方式。 到 4.x 时代，Spring 官方推荐使用 Java 代码配置，以完全替代 XML 配置，实现零配置文件。 到了 Spring Boot 时代，Spring 官方甚至直接将 推荐使用 中的 推荐 二字给拿掉了。 实际上无论是从实际使用的灵活性、方便性，还是从官方的态度，都应该优先使用 Java 代码配置方式。 实例化 Spring IoC 容器 Spring 核心容器的理论很简单：Spring 核心容器就是一个超级大工厂，所有的对象都会被当成 Spring 核心容器管理的对象。 你必须实例化 Spring IoC 容器，读取其配置文件来创建 Bean 实例。然后你可以从 Spring IoC 容器中得到可用的 Bean 实例。 BeanFactory └── ApplicationContext ├── ClassPathXmlApplicationContext └── AnnotationConfigApplicationContext Spring IoC 容器主要是基于 BeanFactory 和 ApplicationContext 两个接口： BeanFactory 是 Spring IoC 容器的顶层接口 ApplicationContext 是最常用接口 ClassPathXmlApplicationContext 是 ApplicationContext 的实现类。顾名思义，它从 classpath 中加载一个 XML 配置文件，构建一个应用程序上下文。你也可以指定多个配置文件。 AnnotationConfigApplicationContext 也是 ApplicationContext 的实现类。不过它需要的是一个配置类，而非配置文件。 BeanFactory 接口定义了 Spring IoC 整个体系中 最重要的方法（簇）：getBean() 方法。这个方法用于从 Spring IoC 容器中获得 Bean 。 new AnnotationConfigApplicationContext(ApplicationConfig.class); new AnnotationConfigApplicationContext(ServiceConfig.class, DaoConfig.class); new ClassPathXmlApplicationContext(\"applicationContext.xml\"); new ClassPathXmlApplicationContext(\"service.xml\", \"dao.xml\"); 在获得应用程序上下文（也就是IoC容器）后，你只需要调用 getBean() 方法并传入唯一的 Bean ID/名称和 Bean 的 Class 对象，就可以获得容器中的 Bean。 // 某些情况下 id 非必须 Human tom = context.getBean(\"tom\", Human.class); Spring 创建 Bean Spring 可以“帮”你创建、管理 Bean 对象，但是前提是你必须“告诉”它创建、管理哪些 Bean 对象。 Spring 允许你在一个（或多个）XML 配置文件中配置 Bean，对于 Spring IoC 容器，这个配置文件就是创建、管理 Bean 的依据。 一个 Spring XML 配置文件的基本样式是： 创建 Bean 的方式常见三种： 类自身的构造方法 工厂类提供的工厂方法 工厂对象提供的工厂方法 使用类自身的构造方法 每个 bean 都必须提供一个唯一的名称或id，以及一个完全限定的类名，用来让 Spring IoC 容器对其进行创建。Spring 通过类的构造方法来创建 Bean 对象。 使用工厂类提供的工厂方法 使用工厂对象提供的工厂方法 Spring 装配简单类型属性 装配，即为 Bean 的属性进行 初始化 / 赋值。 简单类型 是指： 基本数据类型、基本数据类型包装类 和 字符串 。 装配方式有两种： 通过 构造方法 装配 通过 setter 装配 构造方法装配 通过构造方法装配，即设置 Spring 通过调用有参构造方法（默认是调用无参构造方法）来创建对象。在 bean 元素内使用 constructor-arg 子元素，即可触发构造方法装配。 ... index 属性表示构造函数形参 索引（从0开始）。如果参数的类型具有唯一性，那么可以使用 type 属性，通过 参数类型 来指定构造方法和参数值。 为了简化配置，Spring 提供了一个名为 c 的 schema，来简化配置。 使用这种简写方式，完全不用出现 costructor-arg 子元素，只需在 bean 元素中多增加几个 c:_索引=\"参数值\" 这样的属性。 setter 装配 通过 setter 装配，即设置 Spring 在（通过无参构造方法）创建对象后，通过调用对象的属性的 setter 方法来为对象的属性赋值。在 bean 元素内使用 property 子元素，即可触发 setter 装配。 ... property 元素的 name 属性用于指定对象的属性名，value 属性用于指定要设置值。 为了简化配置，Spring 提供了一个名为 p 的 schema，来简化配置。 ... 使用这种简写方式，完全不用出现 property 子元素，只需在 bean 元素中多增加几个 p:属性名=\"属性值\" 这样的属性。 Spring 装配引用类型属性 对象的属性不一定都是简单类型，还有可能有引用类型，即对象间有“has-a”关系。为引用类型的属性赋值不同于基本类型的属性，不是使用 value，而是 ref 。 构造方法装配 构造方法装配的简写形式中，对于引用类型必须写成： c:_索引-ref=\"参数值\" 。 setter 装配 属性赋值的简写形式中，对于引用类型必须写成：p:属性名-ref 。 Spring 装配集合类型属性 更复杂的属性类型是集合类型（数组、List、Set、Map）属性。 Bean 的属性可能远不止基本类型这么简单，还有可能是基本类型的集合（List、Set 和 Map）。这种情况下，属性的赋值不再是 property-value 这种结构，而是 property-list-value 三层结构。 xxx ... xxx ... xxx ... ... 如果集合是引用类型的集合，那么使用的子元素就从 value 改为 ref。map 使用的是 key-ref 和 value-ref 。 引用的集合还有一种简写形式 自动装配 当一个 Bean 需要访问另一个 Bean 时，你可以显示指定引用装配它。不过，Spring IoC 容器提供自动装配功能，只需要在 bean 的 autowire 属性中指定自动装配模式就可以了。 装配模式 说明 no 默认值。不执行自动装配。你必须显示地装配所依赖对象 byName 以 Bean 的属性名为依据，装配一个与属性名同名的 Bean byType 以 Bean 的属性类型为依据，装配一个与之同类型的 Bean constructor 通过构造方法初始化 Bean 的属性，并依据参数的类型，装配一个与参数同类型的 Bean 尽管自动装配很强大，但是代价是降低了 Bean 配置的可读性。在实践中，建议仅在依赖关系不复杂的应用中使用。 注解替代 XML 配置 在 XML 配置文件中加上 即可开启 Spring 的自动扫描功能，这是使用注解替代XML配置的前提 。 @Component 注解 @Component 注解用于标注于 Bean 的类上。凡是被标注了该注解的类（只要在扫描路径下）都会被 Spring 创建。 @Component 注解有唯一的属性 value 属性。它用来为 Bean 命名。 @Component 注解有三个语义化的子注解： @Repository（用于持久层） @Service （用于业务层） @Controller（用于 Web 层） @Value 注解 @Value 注解用于标注于简单类型属性上。凡是被标注了该注解的属性都会被 Spring 注入值（赋值）。 @Value 注解有唯一的属性 value 属性。它用来为简单属性指定值。 @Autowired 注解 @Autowired 注解用于标注于引用类型属性上。凡是被标注了该注解的属性都会被 Spring 以 类型 为依据注入另一个 Bean 的引用。 @Autowired 注解有唯一的属性 required 属性（默认值为 true）。它用来指示该对该属性的注入是否为必须（默认必须），即，在 Spring IoC 容器中没有发现符合类型的其他Bean时，会抛出异常。 @Qualifier 注解 @Qualifier 注解需要结合 @Autowired 注解使用。它用于标注于引用类型属性上。凡是被标注了该注解的属性都会被 Spring 以 名字 为依据注入另一个 Bean 的引用。 @Qualifier 注解有唯一的属性 value 属性。它用于指示需要注入的另一个 Bean 的名字。 Bean 的作用域 默认情况下，Spring IoC 容器只会对一个 Bean 创建一个实例。即单例。Spring IoC 提供了 4 种 作用域，它决定了 Spring IoC 是否/何时 生成一个新的对象。常见有： singleton（单例）：默认值。在整个应用中，Spring 只为其生成一个 Bean 的实例。 prototype（原型）：Spring 每次都会生成一个 Bean 的实例。 在 XML 配置文件中， 通过 bean 元素的 scope 属性进行设置。该属性取值：singleton | prototype | 其他 。 在 注解 配置中，使用 @Scope 注解，该注解标注于 Bean 的类上（常见于 @Component 之下）。该注解有唯一属性 value 属性，其取值有： singleton | prototype | 其他。 使用 Spring 表达式（Spring EL） Spring 表达式可以出现在 @Value 注解中，用以表达有逻辑关系的赋值。Spring 表达式的基本语法是 #{表达式}，即 @Value(\"#{表达式}\") 。 Spring EL 中，数字常量直接书写，即 @Value(\"#{9527}\")。 Spring EL 中，字符串常量使用单引号（'）括起来，即 @Value(\"#{'Hello World'}\") 。 Spring EL 中，对象的引用直接书写对象名，即 @Value('#{tom}') 。 在 Spring EL 中，使用对象的属性和方法就像书写点语法表达式。 @Value(\"#{tom.age}\") @Value(\"#{tom.getName().toUpperCase()}\") 有时候我们可能希望使用一些静态方法和常量。在 Spring EL 中，书写方式如下： @Value(\"#{T(Math).PI}\") @Value(\"#{T(Math).random()}\" Spring EL 表达是中可以使用运算符进行运算，包括：算术运算、字符串拼接、逻辑运算、比较运算、甚至是可以使用三元运算符。 案例：Spring 整合 Druid 数据库连接池 其它 Spring 解析、加载及实例化 Bean 的顺序： @ComponentScan > @Import > @Bean "},"Part-I/Spring/02-AOP.html":{"url":"Part-I/Spring/02-AOP.html","title":"Spring AOP","keywords":"","body":"Spring AOP AOP 基本概念 显示中有一些内容并不是面向对象技术（OOP）可以解决的，比如事务处理。在 JDBC 代码中，最繁琐的问题就是无穷无尽的 try ... catch ... finally ... 语句 和 数据库资源关闭 的问题，而且代码会存在大量的重复，而你又不能不写。 一个正常执行的 SQL 的逻辑步骤如下： 打开通过数据库连接池获得数据库链接资源，并做一定的设置工作。 执行对应的 SQL 语句（通常是增删改），对数据进行操作。 如果 SQL 执行过程中发生异常，回滚事务。 如果 SQL 执行过程中没有发生异常，最后提交事物。 到最后的阶段，需要关闭一些连接资源。 参看上述流程，你会发现无论是执行什么具体的 SQL，流程都是一样的！即，到了特定时刻一定会执行某个特定操作，并不因 SQL 的不同而不同 ! 在 OOP 中，模块化单元是『类』（Class），而在 AOP 中，模块化的单元是『 切面』（Aspect）。 AOP 最早由 AOP 联盟的组织提出的，并制定了一套规范。Spring AOP 遵守 AOP 联盟的规范。 Spring 的 AOP 的底层用到两种代理机制： JDK 动态代理 如果目标类遵循某个接口，Spring AOP 底层采用 JDK 方案生成代理对象 Cglib 动态代理 如果目标类不遵循任何接口，Spring AOP 底层采用 cglib 方案生成代理对象。 核心概念 AOP 涉及到如下问题：在 什么类 的 什么方法 的 什么地方，做出 什么样 的增强。AOP 的功能简而言之就是：在不修改方法源文件的情况下，为源文件的特定部位增加新的代码 。 切入点表达式 切入点表达式决定了哪些类的哪些方法会被『插入』新代码。它『回答』了对 什么类 的 什么方法 做出增强。 最常用的切入点表达式是 execution 表达式，其语法格式如下： [方法访问修饰符] 方法返回值 包名.类名.方法名(方法的参数) 『方法访问修饰符』部分是可选部分；『其它』部分是必要部分。 例如： execution( * com.demo.dao.EmployeeDao.*(..) ) execution( public * demo.dao.EmployeeDao.*(..) ) execution( public String demo.dao.EmployeeDao.*(..) ) execution( public String demo.dao.EmployeeDao.*(String, ..) ) execution( * demo.dao.*.*(..) ) 返回值匹配: 可以为 *，表示任何返回值，全路径的类名等。 方法名匹配: 指定方法名。 例如：* 代表所有方法； set*，代表以 set 开头的所有方法. 参数匹配: 指定方法参数(数量、类型及顺序)。 例如：(..) 代表所有参数；(*) 代表一个参数； (*, String) 代表第一个参数为任何值，第二个为 String 类型。 通知类型 通知类型回答了 什么位置 增强 什么样 的代码。 注解 通知 说明 @Before 在被代理对象的方法前调用 @Around 将被代理方法封装起来 环绕通知，它将覆盖原有方法，但是允许通过反射调用原有方法 @After 在被代理对象方法后调用 @AfterReturning 在被代理对象正常返回后调用 要求被代理对象的方法执行过程中没有发生异常 @AfterThrowing 在被代理对象的方法抛出异常后调用 要求被代理对象的方法执行过程中发生异常 Spring 只支持方法拦截 。 使用 @AspectJ 注解配置 Spring AOP Spring 实现 AOP 功能的方式有两种：@AspectJ 注解 方式，要求会写；XML 配置 方式要求会看。 补充，AOP 概念并非 Spring 所特有，Spring 也并非支持 AOP 编程的唯一框架。在 Spring 之前提供 AOP 功能的，具有里程碑式的框架叫 AspectJ 框架。AspectJ 框架的使用方式比较独特（不简便），在 Spring AOP 出现后就慢慢被 Spring AOP 所取代。但是，AspectJ 框架设计了一套注解，非常简便和合理，并且被广大 AspectJ 的使用者所熟知，所以 Spring AOP 直接借用这套注解，也就是我们这里所说的 @AspectJ 注解。 由于 @AspectJ 注解是 Spring『借用』的别人的注解，所以使用时需要引入它。 org.aspectj aspectjrt ${aspectj.version} org.aspectj aspectjweaver ${aspectj.version} 在 Spring 的配置文件中，也需要引入/声明 AOP 的 namspace : 并且，由于 @AspectJ 注解并非 Spring 框架的一部分，所以需要在配置文件中声明 『启用 @AspectJ 注解』 功能，否则，Spring 并『不认识』 @AspectJ 的一系列注解。 再重复一遍，使用 Spring AOP 的核心问题：在 什么类 的 什么方法 的 什么地方，做出 什么样 的增强。 @Aspect // 注意，不要忘记在切面类的头上加 @Aspect 注解。 public class DeptAspect1 { @Before(\"execution(* bean.Dept.sayHi(..))\") public void before() { System.out.println(\"before ...\"); } @After(\"execution(* bean.Dept.sayHi(..))\") public void after() { System.out.println(\"after ...\"); } @Around(\"execution(* bean.Dept.sayHi(..))\") public void around(ProceedingJoinPoint jp) { System.out.println(\"hello\"); try { jp.proceed(); } catch (Throwable e) { e.printStackTrace(); } System.out.println(\"world\"); } @AfterReturning(\"execution(* bean.Dept.sayHi(..))\") public void afterReturuing() { System.out.println(\"afterReturning ...\"); } @AfterThrowing(\"execution(* bean.Dept.sayHi(..))\") public void afterThrowing() { System.out.println(\"afterThrowing ...\"); } } 可以发现，上述代码中 execution(...) 部分有大量重复现象。为此，可以提供一个 @Pointcut 来进行“缩写”。 @Aspect public class DeptAspect1 { @Pointcut(\"execution(* bean.Dept.sayHi(..))\") public void xxx() { // 这个方法是空的。需要的不是它的内容，需要的是它的名字。 } @Before(\"xxx()\") public void before() { ... } @After(\"xxx()\") public void after() { ... } @Around(\"xxx()\") public void around() { ... } @AfterReturning(\"xxx())\") public void afterReturning() { ... } @AfterThrowing(\"xxx())\") public void afterThrowing() { ... } } 另外，有时你要拦截/增强的方法是有参数的，例如： public void sayHi(String name, int age) { ... } 为此，你也可以在增强方法中获得这些参数， @Pointcut(\"execution(* bean.Dept.sayHi(..))\") public void xxx() {} @Before(\"execution(* bean.Dept.sayHi(..)) && args(name, age)\") public void before(String name, int age) { ... } @After(\"xxx() && args(name, age)\") public void after(String name, int age) { ... } 使用 XML 配置 Spring AOP 通过 XML 配置 Spring AOP 功能，在 XML 文件中出现的各种『要素』本质上和 @AspectJ 注解中出现过的内容本质上并没有两样。 public class DeptAspect2 { public void before() { ... } public void after() { ... } public void around(ProceedingJoinPoint jp) { ... } public void afterReturuing() { ... } public void afterThrowing() { ... } } "},"Part-I/Spring/03-tx.html":{"url":"Part-I/Spring/03-tx.html","title":"Spring TX","keywords":"","body":"Spring 中 @transactional 的使用 事务管理是应用系统开发中必不可少的一部分。Spring 为事务管理提供了丰富的功能支持。 声明式事务有两种方式，一种是在配置文件（xml）中做相关的事务规则声明，另一种是基于 @Transactional 注解的方式。注释配置是目前流行的使用方式。 Transactional 注解管理事务的实现步骤 使用 @Transactional 注解管理事务的实现步骤分为两步。 第一步，在 xml 配置文件中添加事务配置信息。 第二步，将 @Transactional 注解添加到合适的方法上，并设置合适的属性信息。 @Transactional 注解的属性信息 属性名 说明 name 当在配置文件中有多个 TransactionManager , 可以用该属性指定选择哪个事务管理器。 propagation 事务的传播行为，默认值为 REQUIRED 。 isolation 事务的隔离度，默认值采用 DEFAULT 。 timeout 事务的超时时间，默认值为 -1 。如果超过该时间限制但事务还没有完成，则自动回滚事务。 read-only 指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true。 rollback-for 用于指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，各类型之间可以通过逗号分隔。 no-rollback-for 抛出 no-rollback-for 指定的异常类型，不回滚事务。 除此以外，@Transactional 注解也可以添加到类级别上。当把 @Transactional 注解放在类级别时，表示所有该类的公共方法都配置相同的事务属性信息。 方法级别的事务属性信息会覆盖类级别的相关配置信息。 @Transactional 注解的标注于类上： @Transactional(propagation= Propagation.SUPPORTS, readOnly=true) @Service(value =\"employeeService\") public class EmployeeService 注解方式的事务使用注意事项 当您对 Spring 的基于注解方式的实现步骤和事务内在实现机制有较好的理解之后，就会更好的使用注解方式的事务管理，避免当系统抛出异常，数据不能回滚的问题。 正确的设置 @Transactional 的 propagation 属性 本来期望目标方法进行事务管理，但若是错误的配置这三种 propagation，事务将不会发生回滚。 TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务； 如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。 正确的设置 @Transactional 的 rollbackFor 属性 默认情况下，如果在事务中抛出了未检查异常（继承自 RuntimeException 的异常）或者 Error，则 Spring 将回滚事务；除此之外的异常，Spring 都不会回滚事务！ 如果在事务中抛出其他类型的异常，并期望 Spring 能够回滚事务，可以指定 rollbackFor。例： @Transactional(propagation= Propagation.REQUIRED, rollbackFor= MyException.class) 若在目标方法中抛出的异常是 rollbackFor 指定的异常的子类，事务同样会回滚。 @Transactional 只能应用到 public 方法才有效 只有 @Transactional 注解应用到 public 方法，才能进行事务管理。 Spring AOP 会检查目标方法的修饰符是不是 public，若不是 public，就不会获取 @Transactional 的属性配置信息，最终会造成不会用 TransactionInterceptor 来拦截该目标方法进行事务管理。 避免 Spring 的 AOP 的自调用问题 在 Spring 的 AOP 代理下，只有目标方法由外部调用，目标方法才由 Spring 生成的代理对象来管理，这会造成自调用问题。 若同一类中的其他没有 @Transactional 注解的方法内部调用有 @Transactional 注解的方法，有 @Transactional 注解的方法的事务被忽略，不会发生回滚。 @Service public class OrderService { private void insert() { insertOrder(); } @Transactional public void insertOrder() { //insert log info //insertOrder //updateAccount } } insertOrder() 方法尽管有 @Transactional 注解，但它被内部方法 insert() 调用，因此 insertOrder() 的事务被忽略，出现异常事务不会发生回滚。 "},"Part-I/Spring/06-spring-jdbc.html":{"url":"Part-I/Spring/06-spring-jdbc.html","title":"Spring JDBC","keywords":"","body":"spring jdbc org.springframework spring-jdbc ${spring.version} Spring 为了提供对 Jdbc 的支持，在 Jdbc API 的基础上封装了一套实现，以此建立一个 JDBC 存取框架。 （作为 Spring JDBC 框架的核心）JDBC Template 的设计目的主要是两个： 简化 JDBC 的操作代码。 可以将事务的管理工作委托给 Spring，进一步简化代码。 JdbcTemplate 使用很简单：要求 Spring『帮』我们创建一个 JdbcTemplate 的单例对象，随后，我们在代码（Dao）中，注入这个 template 单例对象，使用它即可。 需要注意的是，Spirng 创建 JdbcTemplte 单例对象时，需要传入 DataSource 单例对象。传入 DataSource 的目的在于，JdbcTempate 会自己从 DataSource 中取 Connection 对象进行数据库操作。从而不再需要我们从 Service 层中传入 Connection 对象。 配置文件 !FILENAME web.xml Archetype Created Web Application HelloWeb org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:application-context.xml 1 HelloWeb / !FILENAME application-context.xml Dao 和 Service !FILENAME DepartmentDAO.java @Repository public class DepartmentDAO { private static final Logger log = LoggerFactory.getLogger(DepartmentDAO.class); @Autowired private JdbcTemplate template; public void delete(int id) { log.info(\"DAO: delete\"); template.update(\"delete from department where id = ?\", id); if (id % 2 == 0) throw new RuntimeException(); } } !FILENAME DepartmentService.java @Transactional @Service public class DepartmentService { private static final Logger log = LoggerFactory.getLogger(DepartmentService.class); @Autowired private DepartmentDAO dao; public void delete(Integer id) { log.info(\"Service: delete\"); dao.delete(id); } } Spring-JDBC API：增删改 JdbcTemplate 为 DAO 中的 增删改操作提供了 update() 方法。 template.update(\"INSERT INTO exam_user VALUE(NULL, ?, ?)\", username, password); template.update(\"DELETE FROM exam_user WHERE uid = ?\", uid); template.update(\"UPDATE exam_user SET username = ?, password = ? WHERE uid = ?\", newUsername, newPassword, uid); Spring-JDBC API：查询 User user = template.queryForObject(\"SELECT * FROM exam_user WHERE username = ?\", new BeanPropertyRowMapper<>(User.class), username); List list = template.query(\"select * from exam_user\", new BeanPropertyRowMapper<>(User.class)); 在 JavaBean 的属性名与数据库名一致的情况下，Spring Jdbc 提供了自带的一个 BeanPropertyRowMapper 类，用于将 ResultSet 中的数据库数据『映射/转换』成 JavaBean 。 template.queryForObject() 方法有一个『问题』，由于涉及到 ResultSet 到 JavaBean 的转换，queryForObject() 默认是要求 必须 要查得到数据的。如果你的 SQL 在数据库中查不到任何数据（也许本来就没有这样的一条数据），那么 queryForObject() 方法会抛出异常：EmptyResultDataAccessException 。 因此，对于逻辑上本来就有可能查不到数据的情况，建议也使用 query 方法查询，得到一个 List 后，在通过判断 List 的 .size()，来确定查没查到数据，并进行后续处理。 自定义映射结果集 对于数据库中的字段的名字与 JavaBean 的属性名不一致的情况，如果无法将其两者统一，那么在使用 query() 和 queryForObject() 时，就需要自己『定制』ResultSet 到 JavaBean 的转换规则（即，实现 RowMapper 接口）。 template.query(\"\", (resultSet, n) -> { User user = new User(); user.setUid(resultSet.getLong(\"uid\")); user.setUsername(resultSet.getString(\"username\")); user.setPassword(resultSet.getString(\"password\")); return user; }); "},"Part-I/Spring/07-spring-code-config.html":{"url":"Part-I/Spring/07-spring-code-config.html","title":"Spring 代码配置","keywords":"","body":"Spring 的 Java 代码配置方式 Spring 从 2.x 开始，提供注解，用以简化 XML 配置文件配置 Spring 从 3.x 开始，基于注解功能，提供了全新的配置方式：Java 代码配置方式。 到 4.x 时代，Spring 官方推荐使用 Java 代码配置，以完全替代 XML 配置，实现零配置文件。 到了 Springboot 时代，Spring 官方甚至直接将 推荐使用 中的 推荐 二字给拿掉了。 需要注意的是，在 Java 项目中使用 Spring 的 Java 代码配置时，使用过 AnnotationConfigApplicationContext 加载配置类。 AbstractApplicationContext container = new AnnotationConfigApplicationContext(XxxConfig.class); ... container.close(); spring-dao.xml 演变 !FILENAME spring-dao.xml --> 演变为： !SpringDaoConfig.java @Configuration public class SpringDaoConfig { /* @Bean(name = \"dataSource\", initMethod = \"init\", destroyMethod = \"close\") public DruidDataSource dataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://127.0.0.1:3306/scott?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=UTC\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); return dataSource; } */ @Bean(name = \"dataSource\", destroyMethod = \"close\") public HikariDataSource dataSource() { HikariDataSource dataSource = new HikariDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://127.0.0.1:3306/scott?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=UTC\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); return dataSource; } } 加载配置文件的代码，也从加载 .xml 配置文件，演变为加载 .class 类。 ApplicationContext context = new AnnotationConfigApplicationContext(SpringDaoConfig.class); Bean 的引用的体现 在 Spring 的 Java 代码配置中，Bean 的引用关系有 2 种体现方式： 一个 Bean 方法内部调用另一个 Bean 方法： @Bean public DataSourceTransactionManager txManager() { DataSourceTransactionManager manager = new DataSourceTransactionManager(); manager.setDataSource(dataSource()); // 看这里 return manager; } 通过 Bean 方法的参数引用另一个 Bean： @Bean public DataSourceTransactionManager txManager(DataSource ds) { // 看这里 DataSourceTransactionManager manager = new DataSourceTransactionManager(); manager.setDataSource(ds); return manager; } 推荐使用上述第二种方式。 SSM 的 Java 代码配置 web.xml 被 WebAppInitializer 替代 从 Servlet 3.0 开始 web.xml 的作用就逐渐被其它新增的特性所替代，直到可以完全不存在！ 在没有 web.xml 的情况下，Web 容器在启动 webapp 时，会在代码中查找一个 WebApplicationInitializer 接口的实现类，该实现类就起到了 web.xml 等同的配置功能。 Spring MVC 进一步简化这个过程，我们只需要继承 AbstractAnnotationConfigDispatcherServletInitializer 类，就间接实现了 WebApplicationInitializer 接口。 WebAppInitializer 替代的是 web.xml，它并非 Spring 的配置文件，因此它的头上是不需要 @Configuration 注解的。 !FILENAME 样例 public class WebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class[] getRootConfigClasses() { return new Class[]{ SpringServiceConfig.class, SpringDaoConfig.class }; } @Override protected Class[] getServletConfigClasses() { return new Class[]{ SpringWebConfig.class }; } @Override protected String[] getServletMappings() { return new String[]{\"/\"}; } @Override protected Filter[] getServletFilters() { Filter encodingFilter = new CharacterEncodingFilter(\"UTF-8\", true); return new Filter[]{encodingFilter}; } } spring-web.xml 被 SpringWebConfig 替代 如前面所说，在 Java 代码配置形势下，Spring 的 .xml 配置文件会被等价的标注了 @Configuration 的配置类所取代。 和后续的 SpringServiceConfig（替代了 spring-service.xml）、SpringDaoConfig（替代了 spring-dao.xml） 配置类不同的是，它有个『额外』的要求：它必须实现 WebMvcConfigurer 接口（实际上Spring 之所以这么要求也是为了帮我们简化配置）。 !FILENAME 样例 @Configuration @EnableWebMvc @ComponentScan(\"xxx.yyy.zzz.web\") public class SpringWebConfig implements WebMvcConfigurer { @Bean public InternalResourceViewResolver viewResolver() { InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(\"/WEB-INF/jsp/\"); viewResolver.setSuffix(\".jsp\"); return viewResolver; } // 配置启用 DefaultServletHandler。目的是通过使用它不去拦截静态资源。 @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) { configurer.enable(); } /* // 另一种静态资源不拦截的配置。 @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/static/**\") // 过滤静态资源路径 .addResourceLocations(\"/static/\");// 定位资源 } */ /* // 配置 URL 路径的匹配规则。 @Override public void configurePathMatch(PathMatchConfigurer configurer) { // 默认值是 true，这种情况下 SpringMVC 会忽略掉 URL 请求中的后缀。 // 例如，URL hello.do 能触发 @RequestMapping(\"/hello\") // xml 中配置为： // // // configurer.setUseSuffixPatternMatch(false); } */ } spring-service.xml 被 SpringServiceConfig 替代 !FILENAME 样例 @Configuration @ComponentScan(\"xxx.yyy.zzz.service\") @EnableTransactionManagement @EnableAspectJAutoProxy(proxyTargetClass = true) // 强制指定使用 cglib 动态代理 public class SpringServiceConfig { /** * 需要注意。JPA 和 Mybatis 使用的 事务管理器不一样。 * 不要无脑复制粘贴。 */ @Bean(\"txManager\") public DataSourceTransactionManager getTXManager(DataSource ds) { DataSourceTransactionManager manager = new DataSourceTransactionManager(); manager.setDataSource(ds); return manager; } } spring-dao.xml 被 SpringDaoConfig 替代 !FILENAME 样例 @Configuration public class SpringDaoConfig { /* @Bean(name=\"dataSource\", initMethod = \"init\", destroyMethod = \"close\") public DruidDataSource dataSource() { DruidDataSource ds = new DruidDataSource(); ds.setDriverClassName(\"com.mysql.jdbc.Driver\"); ds.setUrl(\"jdbc:mysql://localhost:3306/month_exam?serverTimezone=UTC&useUnicode=true&characterEncoding=UTF8&useSSL=false\"); ds.setUsername(\"root\"); ds.setPassword(\"123456\"); return ds; } */ @Bean(name = \"dataSource\", destroyMethod = \"close\") public HikariDataSource dataSource() { HikariDataSource dataSource = new HikariDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://127.0.0.1:3306/scott?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=UTC\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); return dataSource; } @Bean public SqlSessionFactoryBean sqlSessionFactoryBean(DataSource ds) throws IOException { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(ds); factoryBean.setConfigLocation(new ClassPathResource(\"mybatis/mybatis-config.xml\")); factoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(\"mybatis/mapper/*.xml\")); return factoryBean; } @Bean public MapperScannerConfigurer mapperScannerConfigurer() { MapperScannerConfigurer configurer = new MapperScannerConfigurer(); configurer.setBasePackage(\"dao\"); return configurer; } } "},"Part-I/Springmvc/01-第一个SpringMVC.html":{"url":"Part-I/Springmvc/01-第一个SpringMVC.html","title":"第一个 SpringMVC 应用程序","keywords":"","body":"第一个 SpringMVC 应用程序 Spring MVC 是 Spring 提供的一个实现了 Web MVC 设计模式的轻量级 Web 框架。它与 Struts 2 框架一样，都属于 MVC 框架，但其使用和性能等方面都比 Struts 2 更加优异。 Spring MVC 的核心包是： spring-web spring-webmvc 依赖于： commons-logging spring-aeans spring-beans spring-context spring-core spring-expression 配置 web.xml springmvc org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:spring-web.xml 1 springmvc / 在上述 web.xml 文件中主要对 和 元素进行了配置。 在 中配置了 Spring MVC 的前端控制器 DispatcherServlet 。 子元素 配置了 Spring MVC 配置文件的位置。 元素中的 1 表示容器（Tomcat）在启动时立即加载这个 DispatcherServlet。 在 中，通过 元素的 /，会对所有 URL 拦截（不包括 jsp / html 等），并交由 DispatcherServlet 处理。 创建 Controller 类 注意，以下写法和相关配置是『上古时代』写法，仅作了解。实际中并不会这么写。 /** * 控制器类 */ public class HelloController implements Controller { @Override public ModelAndView handleRequest(HttpServletRequest req, HttpServletResponse resp) throws Exception { ModelAndView mav = new ModelAndView(); mav.addObject(\"msg\", \"这是我的第一个 SpringMVC 程序\"); mav.setViewName(\"/WEB-INF/jsp/hello.jsp\"); return mav; } } 配置控制器映射信息 实际上从 Spring 4.0 开始，如果不配置处理器映射器、处理器适配器和视图解析器，Spring 会使用默认配置来完成相应工作。 创建视图 入门程序 hello.jsp ${msg} "},"Part-I/Springmvc/02-工作流程.html":{"url":"Part-I/Springmvc/02-工作流程.html","title":"SpringMVC 的工作流程","keywords":"","body":"SpringMVC 的工作流程 如上图，Spring MVC 程序的完整执行流程如下： 用户通过浏览器发送请求，请求会被 Spring MVC 的前端控制器 DispatcherServler 接受。 DispatcherServlet 拦截到请求后，会调用 HandlerMapping 处理器映射器。 处理器映射器根据请求 URL 找到具体的处理器，生成处理器对象（如果有，还会生成拦截器对象）并返回给 DispatcherServlet。 DispatcherServlet 根据返回信息（Handler）选择合适的处理器适配器（HandlerAdapter）。 HandlerAdapter 会调用并指定 Handler（处理器）。此处和上述所说的处理器 Handler，就是我们所编写的 Controller 类。 Controller 执行完成后，会返回一个 ModelAndView 对象，该对象中会包含视图名和模型对象。 HandlerAdapter 将 ModelAndView 返回给 DispatcherServlet。 DispatcherServlet 会根据返回信息（ModelAndView）选择一个合适的视图解析器：ViewResolver。 视图解析器 ViewResolver 解析视图后，会向 DispatcherServlet 返回具体的 View 对象。 DispatcherServlet 对 View 进行渲染。即，将模型数据填充至视图中。 DispatcherServlet 将渲染后的结果返回/发送给客户端浏览器。 在上述执行过程中，DispatcherServlet、HandlerMapping、HandlerAdapter 和 ViewResolver 对象的工作都是在框架内部执行的，开发人员并不需要关心这些对象内部实现过程。 "},"Part-I/Springmvc/03-DispatcherServlet.html":{"url":"Part-I/Springmvc/03-DispatcherServlet.html","title":"DispatcherServlet","keywords":"","body":"SpringMVC 的工作流程 DispatcherServlet Spring Web 的模型 - 视图 - 控制器（MVC）框架是围绕 DispatcherServlet 设计的，它处理所有的 HTTP 请求和响应。 以下是对应于到 DispatcherServlet 的传入 HTTP 请求的事件顺序： 在接收到 HTTP 请求后，DispatcherServlet 会查询 HandlerMapping，并通过 Adapter 调用相应的 Controller 。 Controller 接受请求并根据使用的 GET 或 POST 方法调用相应的服务方法。 服务方法将基于定义的业务逻辑设置模型数据，并将视图名称返回给 DispatcherServlet 。 DispatcherServlet 将从 ViewResolver 获取请求的定义视图。当视图完成，DispatcherServlet 将模型数据传递到最终的视图，并在浏览器上呈现。 必需的配置 需要通过使用 web.xml 文件中的 URL 映射来映射希望 DispatcherServlet 处理的请求。 HelloWeb org.springframework.web.servlet.DispatcherServlet 1 HelloWeb *.do 加载配置文件的两个时机 SpringMVC 有两次加载 Spring 配置文件的时机： 首先在 SpringMVC 项目启动时，会依据 web.xml 配置文件中所配置的监听器：ContextLoaderListener 去加载对应位置下的 Spring 配置文件。 ... org.springframework.web.context.ContextLoaderListener contextConfigLocation classpath:spring/spring-dao.xml, classpath:spring/spring-service.xml ... 无论该监听器有没有配置，那么 Spring MVC 都会继续进入第二个加载配置文件时机，根据 DispatcherServlet 的初始化配置（init-param）加载对应位置的 Spring 配置文件： ... ... org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:spring-web.xml 1 ... 如果 没有配置，那么默认相当于是： contextConfigLocation WebContent/WEB-INF/[servlet-name]-servlet.xml 这里的 Spring 配置文件的路径如果是以 classpath: 开始，则表示配置文件是在 classpath 路径下。否则，就是在项目的工程根目录（webapp）下。 SpringMVC 首先加载的是 配置的内容，而并不会去初始化 servlet。只有进行了网站的跳转，经过了 DispatcherServlet 的导航的时候，才会初始化 servlet，从而加载 中的内容。 一般而言， 配置的 Spring 配置文件，习惯性叫 applicationContext，或 webApplicationContext，表示全局性 Spring 配置。 配置的 Spring 配置文件可以叫 spring-mvc，表示 spirng-webmvc （web 层）相关的 Spring 配置。 现在来看看 HelloWeb-servlet.xml 文件的必需配置，放在 Web 应用程序的 WebContent/WEB-INF 目录中： 定义控制器 DispatcherServlet 将请求委派给控制器以执行特定于其的功能。 @Controller 注释指示特定类充当控制器的角色。@RequestMapping 注释用于将 URL 映射到整个类或特定处理程序方法。 @Controller public class HelloController { @RequestMapping ( value = \"/hello\", method = RequestMethod.GET ) public ModelAndView printHello() { ModelAndView mav = new ModelAndView(); mav.addObject(\"message\", \"Hello Spring MVC Framework!\"); mav.setViewName(\"/WEB-INF/jsp/hello.jsp\"); return mav; } } @Controller 注释将类定义为 Spring MVC 控制器。 @RequestMapping 的第一个用法表示此控制器上的所有处理方法都与 /hello 路径相关。 @RequestMapping(method = RequestMethod.GET) 用于声明 printHello() 方法作为控制器的默认服务方法来处理 HTTP GET请求。可以定义另一个方法来处理同一 URL 的任何 POST 请求。 value 属性指示处理程序方法映射到的 URL，method 属性定义处理 HTTP GET 请求的服务方法。关于以上定义的控制器，需要注意以下几点： 在服务方法中定义所需的业务逻辑。可以根据需要在此方法内调用其他方法。 基于定义的业务逻辑，将在此方法中创建一个模型。可以设置不同的模型属性，这些属性将被视图访问以呈现最终结果。此示例创建且有属性 “message” 的模型。 定义的服务方法可以返回一个 String，它包含要用于渲染模型的视图的名称。此示例将 “hello” 返回为逻辑视图名称。 创建 JSP 视图 Spring MVC 支持许多类型的视图用于不同的表示技术。包括 JSP，HTML，PDF，Excel 工作表，XML，Velocity 模板，XSLT，JSON，Atom 和 RSS 源，JasperReports 等。这里使用的是 JSP 模板，并在 /WEB-INF/hello/hello.jsp 中写一个简单的 hello 视图： Hello Spring MVC ${message} 这里 ${message} 是在 Controller 中设置的属性。可以在视图中显示多个属性。 "},"Part-I/Springmvc/04-Controller.html":{"url":"Part-I/Springmvc/04-Controller.html","title":"Controller 的编写和配置","keywords":"","body":"Controller 的编写和配置 @Controller 注解和 @RequestMapping 注解是 SpringMVC 最重要的两个注解。 使用基于注解的控制器的优点如下： 一个 Controller 类可以处理多个动作，而实现了一个 Controller 接口的控制器只能处理一个动作。 基于 Controller 注解的控制器的请求映射不需要写在配置文件中。使用 @RequestMapping 注解类型，可以对一个方法进行请求处理。 Controller 注解类型 Spring 使用扫描机制来找到应用程序中所有基于注解的控制器类。为了保证 Spring 能找到你的控制器，必须完成两件事： 注意，不要让 Spring 扫描一个太广泛的包，这会包含无意义的行为。 RequestMapping 注解类型 @RequestMapping 注解类型的作用如同起名字所暗示：映射一个请求和一个方法。可以使用它注解一个方法或类。 被 @RequestMapping 注解的方法将成为一个 请求处理方法 ，在接收到URL请求时被调用。 @RequestMapping(value=\"/hello\", method = {RequestMethod.GET, RequestMethod.POST}) public ModelAndView printHello() { System.out.println(\"Hello World\"); ModelAndView mav = new ModelAndView(); mav.addObject(\"message\", \"Hello Spring MVC Framework!\"); mav.setViewName(\"hello\"); return mav; } value 属性是 @RequestMapping 的默认属性，唯一时可省略属性名。 method 属性用来指示该方法仅处理哪些 HTTP 方法。若 method 属性只有一个值时，则无须花括号。若没有指定 method 属性值，则请求方法可处理任意 HTTP 方法。 此外，如果用 @RequestMapping 注解一个控制器类，那么，所有的方法都将映射为 相对于 类级别的请求。 编写请求方法 每个请求处理方法的参数和返回值 既灵活又严格 。 最为常见的参数类型有： HttpServletRequest、HttpServletResponse、HttpSession Map、Model、ModelMap 表单对象 带指定注解的参数 最为常见的参数类型有： ModelAndView Model、View String （被当作 View 的模型对象的）任意类型 请求参数和路径变量 Spring MVC 提供了一个更简单的方法来获取 Get 请求参数：通过使用 @RequestParam 注解。 @RequestMapping(\"/hehe/{id}\") public ModelAndView printGoodbye(@PathVariable int id) { System.out.println(id); ModelAndView mav = new ModelAndView(); mav.setViewName(\"hello\"); return mav; } 此处需要注意的是，你的拦截规则是拦截所有请求，还是拦截特定后缀（无法拦截并触发该方法的执行）？！ "},"Part-I/Springmvc/05-参数绑定.html":{"url":"Part-I/Springmvc/05-参数绑定.html","title":"参数绑定","keywords":"","body":"参数绑定 数据绑定是一个自动转换及赋值的过程，它负责将 HTTP 请求中的 String 类型的参数，转换为其他类型的请求处理方法的参数。 绑定简单类型 当 HTTP 请求的参数名和处理方法参名一致时，SpringMVC 会将请求参数与形参进行绑定。 参数类型强烈建议使用 包装类 。 如果没有那么『凑巧』，HTTP 请求参数名和方法形参名不一致，可通过 @RequestParam 注解进行手动指定。 属性 作用 value 指定 request 中参数的名称。 required 指定是否必须，是否必须，默认是 true。必须意味着为空时，报错退出。 defaultValue 默认值，表示如果请求中没有同名参数时的默认值。 public String login1(String username, @RequestParam(value = \"password\", required = false, defaultValue = \"N/A\") String password) { ... ... ... } 绑定到 JavaBean JavaBean 对象中的属性名和表单中 的 name 属性一致，并且 Controller 方法以 JavaBean 为形参即可。 男 女 提交 public class Student { private String name; private Integer age; private Boolean male; ... } public String login(Student student) { ... } 绑定到复合 JavaBean 需要将表单中的数据绑定到一个对象中的某个对象属性上。例如：FormVO 对象下的 Student 属性。 这种情况下，需要页面 元素的 name 为“属性名.属性名”。 public class Student { private String name; private Integer age; ... } public class Teacher { private String name; private Integer age; private Student student; /* name, age */ } public String demo(Student student) { ... } 绑定到数组 如果页面上使用了 那么，Http 提交到后台的将是一个数组。 足球 篮球 乒乓球 游泳 跑步 和前面类似，Spring MVC 可以自动将这些同名的多个数据绑定到数组中，绑定方式有两种： 绑定到 Controller 方法的数组型参数中 public ModelAndView register(..., String[] likes) 绑定到 Controller 方法的参数对象的数组型属性中 ```java public class Student { private String[] likes; ... } public ModelAndView register(Student student) 即，数组既可以做方法的参数对象本身，又可以做参数对象的属性。 # 绑定到 List List 只能作方法的参数对象的属性，而不能做参数对象本身。 ```xml public class Teacher { private String name; private String age; private List students; ... } 绑定到 Set Set 和 List 类似，它只能作方法的参数对象的属性，而不能做参数对象本身。 另外，作为属性的 Set 必须提前初始化，且其中有相对应的模型对象。 public class Teacher { private String name; private String age; private Set students; public Teacher() { set = new HashSet<>(); // 这是不同于 List（和 Map）的地方。 set.add(new Student()); set.add(new Student()); set.add(new Student()); } ... } 绑定到 Map Map 和 Set、List 类似，它只能作方法的参数对象的属性，而不能做参数对象本身。 public class Teacher { private String name; private Integer age; private Map students; ... } for (Map.Entry entry : teacher.getStudents().entrySet()) { log.info(\"{}, {}\", entry.getKey(), entry.getValue()); } @DateTimeFormat 和 @NumberFormat 有时会从前台向后台传入日期格式字符串，例如： 一般情况下，不至于用到（后面所说的自定义类型转换），Spring MVC 提供了现成的 @DateTimeFormat 注解来解决 String 到 Date 的转换。 public Student { ... @DateTimeFormat(pattern = \"yyyy-MM-dd\") private Date birthday; ... } 另外，对于有特定格式的字符串，也有类似的注解：@NumberFormat 可用。 @NumberFormat(\"###,###.##\") public double price; "},"Part-I/Springmvc/06-自定义类型转换.html":{"url":"Part-I/Springmvc/06-自定义类型转换.html","title":"自定义类型转换","keywords":"","body":"自定义类型转换 SpringMVC 中实现自定义的参数类型转换有两种途径： 实现 Converter 接口 实现 Formatter 接口 使用 Converter 接口 通过 Convert 接口来实现自定义转换及参数绑定，需要为 Spring 提供一个实现了 Converter 接口的类，并在 Spring MVC 中进行注册。 import org.springframework.core.convert.converter.Converter; public class DateConverter implements Converter { ... } @Override public Date convert(String str) { SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyy-MM-dd HH:mm:ss\"); Date date = null; try { date = simpleDateFormat.parse(str); } catch (ParseException e) { e.printStackTrace(); } return date; } 使用 Formatter 接口 Formatter 接口的使用于 Converter 接口类似。 public DateFormatter(String datePattern) { dateFormat = new SimpleDateFormat(\"MM-dd-yyyy\"); } @Override public String print(Date object, Locale locale) { return dateFormat.format(object); } @Override public Date parse(String text, Locale locale) throws ParseException { return dateFormat.parse(text); } "},"Part-I/Servlet/05-EL.html":{"url":"Part-I/Servlet/05-EL.html","title":"EL","keywords":"","body":"EL 表达式 JSP 2.0 的最重要特性就是表达式语言（EL），EL 的目的是帮助程序员编写无脚本的 JSP 页面。 最初 EL 表达式被创造出来是为了 JSTL 服务，配合 JSTL 使用的。不过从 JSP 2.0 开始即便项目中没有引入 JSTL，也可以（单独）使用 EL 。 在 JSP 的 page 指令中，通过 isELIgnored 属性可以在当前页面 启用/禁止 EL 表达式。 或者在 web.xml 作出全局性设置： *.jsp false EL 语法 EL 表达式以 ${ 开头，并以 } 结束，其结构为 ${ 表达式 }，其计算结果的类型是一个 字符串 。 EL 表达式的结果值可以是任何类型，但是浏览器会将其值以字符串形式（toString 方法）的形式将其“替换”到 EL 表达式所处位置。 EL 表达式可以返回任意类型的值。如果 EL 表达式的结果是一个带有属性的对象，则可以利用 [ ] 或者 . 运算符来访问该属性。如果是使用 [ ] ，属性名需要用引号括起来。例如： ${object[\"propertyName\"]} ${object.propertyName} 如果，propertyName 不是一个有效的 Java 变量名，例如：accept-language，那么，此时只能使用 [ ] 语法，而不能使用 . 语法。 如果，对象的属性碰巧又是另一个对象，那么可以用 [ ]，也可以使用 . 运算符来访问第二个对象的属性。例如： ${pageContext[\"request\"][\"servletPath\"]} ${pageContext.request[\"servletPath\"]} ${pageContext.request.servletPath} ${pageContext[\"request\"].servletPath} 如果 object 的类型是一个 Map，那么，这里使用的是键值对的键：${object[\"key\"]} 如果 object 的类型是一个 Array 或 List，那么这里使用的是其下标索引：${object[0]}。这里的下标索引 0 没有使用 \"\"，它必须是一个数字。 EL 隐式对象 在 JSP 页面中，可以利用 JSP 脚本来访问 JSP 隐式对象， 注意，在页面上显示 EL 表达式的值时，不需要 out.print() 或者 ，容器会执行 EL 表达式并将其结果“写在”它所在的位置。 隐含对象 描述 pageContext 当前 JSP 页面的 pageContext 对象 initParam Application 的初始化参数，初始化参数通常是在 web.xml 中通过 及其子元素 和 配置项配置 param 一个包含了所有请求参数的 Map，其中请求参数名为 key。不过，它无法处理一个请求参数，多个值的情况。通过 key 始终只有第一个值返回。 paramValues 和 param 类似，不过它可以处理一个参数名有多个参数值的情况。不过，如果参数只有一个值，它的返回值仍然是一个数组 applicationScope 包含了 ServletContext 对象中所有属性的 map，并用属性名作 key。 sessionScope 包含了 HttpSession 对象中所有属性的 Map，并用属性名作 key。 requestScope 包含了 HttpServletRequest 对象中所有属性的Map，并用属性名作key。 pageScope 包含了全页面范围内的属性的 Map，并用属性名作 Key。 cookie 包含了当前请求对象中所有 Cookie 对象的Map。以 Cookie 的名称作为 key，并且每一个 key 都映射到一个 Cookie 对象。 header HTTP 请求信息头，字符串 headerValues HTTP 信息头，字符串数组。对应一个请求名，多个请求值的情况。通过 key 取出的始终是数组。 E L表达式所提供的隐式对象中，并没有 request、response、session、application、out 等这些JSP中所存在的隐式对象。这是 EL 隐式对象与 JSP 隐式对象的区别。 不过 EL 的隐式对象中有 pageContext（和 JSP 中一样），通过它我们依旧可以访问到上述这些 JSP 中直接提供，但 EL 中没有直接提供的对象。 EL 表达式中可以使用 + 、- 、*、/、% 五种算数运算符。 EL 表达式中可以使用 &&、||、！ 三种逻辑运算符。 EL 表达式中可以使用 ==、！=、>、>=、 EL 表达式中提供了一个 empty 运算符专门用于 空和非空 的判断（当然，你也可以用 == null 判断）。例如： ${empty X} X 为 null，或者 X 是一个空字符串，或者 X 是一个空数组、空List、空Map、空Set，它都将返回 true 。 "},"Part-I/Servlet/06-JSTL.html":{"url":"Part-I/Servlet/06-JSTL.html","title":"JSTL","keywords":"","body":"JSTL 标签库 JSP 标准标签库（JSTL）是一个定制标签库的集合，它的出现是为了实现呈现层与业务层的分离功能。使用 JSTL（结合EL表达式）在绝大多数情况下，JSP 页面中不再需要“嵌入”Java 代码（scriplet）。 **使用 JSTL 需要额外导入 jstl 库。** 根据 JSTL 标签所提供的功能，可以将其分为 5 个类别：核心（Core）标签、格式化标签、SQL 标签、XML 标签、JSTL 函数。其中以核心（Core）标签最为常用。 使用不同类别的 JSTL 库，需要在 JSP 页面的头文件中做出相应的“声明”。例如： 如果忘记引入 jstl 库，上述声明会报错。 c:out 标签用来显示一个表达式的结果，与 作用相似，它们的区别就是 标签可以直接通过 \".\" 操作符来访问属性。 out 的语法有两种形式： 形式一： 形式二： 默认内容 其中 value 属性是必要部分。 c:set set 标签常见 2 种形式/作用： 第一种用于创建一个有界变量，并用 value 属性在其中定义一个要创建的字符串或者现存的有界对象： 第二种形式是设置有界变量的属性。 例如： ${requestScope.username}, ${requestScope.password} 注意，这种形式中，target 属性中 必须使用一个 EL 表达式 来引用这个有界变量。 例如： ${requestScope.dept.deptno} ${requestScope.dept.dname} ${requestScope.dept.loc} c:remove remove 标签用于删除有界变量。 c:if if 标签是对某一个条件进行测试，假如结果为 true，就处理它的 body content 。另外，测试的结果可以保存在一个 Boolean 对象中，并创建有界变量来引用这个 Boolean 对象。 if 的语法有两种形式。第一种是没有 body content： 第二种形式使用了一个 body content： body content c:choose、c:when 和 c:otherwise choose-when-otherwise 标签的作用与 Java 中的 switch-case-default 类似。 choose 标签中必须嵌有一个或多个 when 标签，并且每个 when 标签都有一种可以计算和处理的情况。otherwise 标签则用于默认的条件块。 choose 和 otherwise 标签没有属性。when 标签必须带有定义的测试条件 test 属性，来决定是否应该处理 body content 。 ... ... ... ... c:forEach forEach 标签会无数次反复便利 body content 或者对象集合。 forEach 标签的语法有两种。第一种形式是固定次数地重返 body content： body content 这种形式与集合对象无关。类似于 Java 代码中的 for (int i = 0; i 例如： hello world ${item} 第二种形式用于遍历对象集合。类似于 Java 代码中的 for (String string : list) body content 对于每一次遍历，forEach 标签都将创建一个有界变量，变量名通过 var 属性定义，可在 body content 中使用。 该有界变量只能在 body content 部分使用。 forEach 标签有一个类型为 javax.servlet.jsp.jstl.core.LoopTagStatus 的变量 varStatus，这个变量有一个 count 属性，其中记录了当循环遍历的次数，该数值从1开始。 例如： 第 ${loop.count} 个：${dept.deptno}, ${dept.dname}, ${dept.loc} fmt 进行日期格式化 引入申明： \" type=\"date\" pattern=\"yyyy-MM-dd\"%/> "},"Part-I/Springmvc/07-转发和重定向.html":{"url":"Part-I/Springmvc/07-转发和重定向.html","title":"转发和重定向","keywords":"","body":"转发和重定向 View Resolver Spring MVC 中的视图解析器（View Resolver）负责解析视图。可以通过在配置文件中定义一个 View Resolver 来配置视图解析器： 对于一个已知的 逻辑视图名，DispatcherServlet 会将请求转发到 prefix + view_name + suffix 的页面。 Note：InternalResourceViewResolver 是最常用的视图解析器，但不是唯一的一个，Spring MVC 还有其他的视图解析器，例如：XmlViewResolver。 Model 和 ModelAndView Spring MVC 提供了一个 Model 接口（及其子接口 ModelMap），它功能类似于 java.util.Map 接口。ModelMap 是其实现类。 如果 Controller 的处理方法中有 ModeMap 作为参数，那么 Spring MVC 会将创建 ModelMap 对象，并传入方法。ModelMap 对象将作为模型数据的存储容器。 在 Controller 方法中，我们可以从 ModelMap 对象中，存/取数据。 如果处理方法的返回结果是 ModelAndView ，则其既包含模型数据信息，也包含视图信息。 在 JSP 页面，可以直接通过 EL 表达式从模型对象中，取出模型数据以供页面展示。 Note，此处需要使用 EL 表达式功能，所以需要在 web.xml 或 jsp 中进行配置，否则默认 JSP 会忽略 EL 表达式。 转发、重定向 和 Flash 属性 Spring MVC中实现转发和重定向非常简单： // 注意，字符串中的 : 后面，没有空格 return \"forward:\"; /* 或 */ mav.setViewName(\"forward:\"); return mav; return \"redirect:\"; /* 或 */ mav.setViewName(\"redirect:\"); return mav; 例如： return \"forward:/department/main\"; 重定向不方便的一个原因在于：无法轻松地传值给下一个页面。而采用转发，则可以简单地将属性添加到 Model，由于重定向经过客户端，所以 Model 中的一切都在重定向中丢失。 Spring 3.1 开始提供了一种解决上述不便的方案：Flash 属性。 要使用 Flash 属性，必须在 Spring MVC 配置文件中添加 。然后必须在方法上多加一个参数，参数类型为 RedirectAttributes 。RedirectAttributes 是 Model 接口的实现类。 注意： 使用 RedirectAttributes 的 addAttribute 方法传递参数会跟随在 URL 后面。 使用 addFlashAttribute 不会跟随在 URL 后面，会把该参数值暂时保存于 session，待重定向 url 获取该参数后从 session 中移除，这里的 redirect 必须是方法映射路径，jsp 无效 。 @RequestMapping(\"/forward1.do\") public String demo1(RedirectAttributes model) { model.addFlashAttribute(\"msg\", \"hello world\"); return \"redirect:/forward2.do\"; } @RequestMapping(\"/forward2.do\") public String demo2() { return \"demo\"; } 跳转异常页面 全局异常处理后续专项讲解 在 Webapp 中，一旦发生了异常可以层层上抛，直到抛给 Spring MVC 的 DispacherServlet 。而 DispacherServlet 可以根据开发者所配置的配置一个 全局异常处理器，来决定跳转哪个页面，展示何种信息。 默认情况下，Spring MVC 所使用的异常处理器是：SimpleMappingExceptionResolver，它所处理的效果正是我们当前所看到的内容。 自定义的异常处理器需要实现 Spring MVC 提供的 HandlerExceptionResolver 接口，在其中 resolveException() 方法中可以根据自定义的逻辑返回 ModelAndView 对象，以决定跳转页面和展示信息。 使用自定义的异常处理器，需要在 Spring MVC 配置文件中做出配置： "},"Part-I/Springmvc/08-Session和Cookie.html":{"url":"Part-I/Springmvc/08-Session和Cookie.html","title":"操作 Session 和 Cookie","keywords":"","body":"SpringMVC 操作 Session 和 Cookie 操作 Session 方式一：方法中声明/使用 HttpServletRequest 参数 这种情况下，Spring MVC 在调用请求处理方法时，会传入本次请求的 Request 对象，后续可以像普通同的 Servlet 代码一样操作 Session 。 @RequestMapping(\"/...\") public String demo1(HttpServletRequest request, ...) { HttpSession session = request.getSession(); session.setAttribute(..., ...); ... } 方式二：方法中直接声明/使用 HttpSession 参数 该方式是 方式一 的改进版。直接要求 SpringMVC “帮”我们去调用 request.getSession() 后再传入到请求处理方法中。 @RequestMapping(\"/...\") public String login(HttpSession session, ...) { .... } 操作 Cookie 在 SpringMVC 中操作 Cookie 和操作 Session 非常类似，你可以要求 SpringMVC 将当前请求的 Response 对象传入你的方法中，而后对其添加 Cookie ： @RequestMapping(\"...\") public String demo1(HttpServletResponse resp) { Cookie cookie = new Cookie(\"name\", \"hello world\"); cookie.setMaxAge(60); resp.addCookie(cookie); } SpringMVC 提供了一个 @CookieValue 注解来简化获取获得客户端传入的 Cookie 数据： @RequestMapping(\"...\") public String demo2(@CookieValue(\"name\") String value) { System.out.println(value); ... } "},"Part-I/Springmvc/09-静态资源访问.html":{"url":"Part-I/Springmvc/09-静态资源访问.html","title":"静态资源访问","keywords":"","body":"SpringMVC 中的静态资源访问 SpringMVC 中设置访问静态资源有两种思路： 类似普通的 Java Web 项目的『分工』：JSP 请求由 JspServlet 处理，Servlet 请求由 DispacherServlet 处理，对静态资源的请求『漏给』DefaultServlet 。 将 Servlet 请求和静态资源请求 都交给 DispacherServlet，然后『告诉』它其中 哪种/哪部分 请求是静态资源请求，让它对其特殊处理。 思路一的相关配置： 将 DispatchServlet 的 url-pattern 配置为 *.do（或其他类似情况），以此作为 Servlet 请求的标志，将所有的 Servlet 请求都交给 DispatcherServlet 。 web.xml HelloWeb org.springframework.web.servlet.DispatcherServlet ... HelloWeb *.do 那么除了 Servlet 请求、JSP 请求之外的请求，都会被当作是静态资源请求，由 Tomcat 的 DefaultServlet 处理。 通过 spring-web.xml 中添加 mvc:default-servlet-handler 元素表示使用容器默认的 DefaultServlet 进行『兜底』处理静态资源： spring-web.xml： 考虑到并非所有的容器的默认的 DefaultSevlet 的 name 并非是 default，所以在非 Tomcat 容器中，需要手动指定其 name 。 Tomcat, Jetty, JBoss, and GlassFish：\"default\" Google App Engine：\"_ah_default\" WebLogic：\"FileServlet\" WebSphere：\"SimpleFileServlet\" 思路二的相关配置： 将 DispatchServlet 的 url-pattern 配置为 /，此时，DispatcherServlet 作为『兜底』的 Servlet 它会处理除了 JSP 请求之外的所有请求（即，Servlet 请求和静态资源请求）。 web.xml HelloWeb org.springframework.web.servlet.DispatcherServlet ... HelloWeb / 然后，再通过 mvc:resources『告诉』DispatcherServlet，哪些请求是静态资源请求（而不是 Servlet 请求）： !FILENAME spring-web.xml !FILENAME 例如： my-app │── img │ ├── ... │ └── ... │── js │ ├── ... │ └── ... │── css │ ├── ... │ └── ... └── WEB-INF └── jsp ├── ... └── ... location 元素表示 webapp 目录下的 xxx 目录；mapping 元素表示以 /xxx 开头的所有请求路径。 两个属性共同表明了：但凡以 /xxx 开始的请求，都是针对 /xxx/ 目录下的静态资源的访问。 "},"Part-I/Springmvc/10-拦截器.html":{"url":"Part-I/Springmvc/10-拦截器.html","title":"拦截器和 POST 中文乱码","keywords":"","body":"Spring MVC 的拦截器 Spring MVC 中的拦截器（Interceptor）类似于 Servlet 中的过滤器（Filter），它主要用于拦截用户请求并做出相应的处理。 拦截器的定义 通过实现 HandlerInterceptorAdapter 接口，并向 Spring MVC 注册既可使用自定义拦截器。 HandlerInterceptorAdapter 接口提供了三个方法： preHandle() 在业务处理器处理请求之前被调用 该方法会在 Controller 方法前执行 返回值表示是否继续后续操作： 返回 true 时，表示继续向下执行； 返回 false 时，会中断后续所有操作（包括调用下一个拦截器和 Controller 中的方法执行）。 postHandle() 在业务处理器处理请求执行完成后，生成视图之前执行 在 Controller 方法调用之后，且解析视图之前执行。 可以通过此方法对模型和视图做出进一步修改。 afterCompletion() 在 DispatcherServlet 完全处理完请求后被调用，可用于清理资源等。 该方法会在整个请求完成（即，视图渲染结束）之后执行。 可以通过此方法实现一些资源清理、记录日志信息等工作。 拦截器的配置 要使自定义的拦截器类生效，还需要在 Spring MVC 的配置文件（spring-web.xml）中进行配置： 如 1 所示，在 interceptors 下注册的拦截器是全局拦截器，会拦截所有请求 如 2 | 6 所示，在 interceptor 下注册的拦截器是局部拦截器，需要明确配置该拦截器拦截哪些请求。 如 3 所示，表示拦截所有路径 如 4 所示，表示在拦截某些请求的前提下，排除/不拦截某些请求 如 7 所示，表示拦截所有以 /hello 开头的路径 当设置多个拦截器时，先按顺序调用 preHandle 方法，然后逆序调用每个拦截器的 postHandle 和 afterCompletion 方法，即： A-pre B-pre C-pre C-post C-after B-post B-after A-post A-after Spring MVC POST 请求乱码问题 Spring MVC 专门提供了一个 Filter 用于解决 POST 请求乱码问题，只需要在 web.xml 文件中配置使用即可： characterEncodingFilter org.springframework.web.filter.CharacterEncodingFilter encoding UTF-8 forceEncoding true characterEncodingFilter /* 关于 get 请求问题，一般是通过修改 tomcat 配置设置文件解决。 "},"Part-I/Springmvc/11-文件上传和下载.html":{"url":"Part-I/Springmvc/11-文件上传和下载.html","title":"文件上传和下载","keywords":"","body":"Spring MVC 中文件上传和下载 为了能上传文件，必须将表单的 method 设置为 POST，并将 enctype 设置为 multipart/form-data 。 有两种实现文件上传的方式： 底层使用 Apache Commons FileUpload 包 底层使用 Servlet 3.1 内置的文件上传功能 无论是哪种方式，其使用方式都是一样的：提供一个 MultipartResolver，并将 file 类型的请求参数绑定到请求处理方法的 MultipartFile 类型的参数上。（两者具体的类型有所不同） 利用 commons-fileupload 文件上传 利用 commons-fileupload 文件上传需要利用引入 commons-fileupload 包（它依赖于 commons-io 包） commons-fileupload commons-fileupload 1.4 Spring MVC 是通过 MultipartResolver 的 JavaBean 提供/支持文件上传功能。commons-fileupload 中该接口的实现类是 CommonsMultipartResolver 。 在 spring-web.xml 中添加如下配置，让 Spring 负责创建并初始化该 Bean 。 至此，配置结束。在 Spring MVC 的 Controller 中，Spring MVC 就可以将用户上传的数据绑定到 CommonsMultipartFile 类型的参数上。 注意，此处的 @RequestParam() 不能省略，即便是 name 与 name 一致。 @RequestMapping(\"/upload.do\") public String upload(String username, String password, @RequestParam(\"uploadfile\") CommonsMultipartFile uploadfile) throws IOException { log.info(\"{}\", uploadfile.getName()); log.info(\"{}\", uploadfile.getOriginalFilename()); String path = \"D:/\" + new Date().getTime() + uploadfile.getOriginalFilename(); uploadfile.transferTo(new File(path)); return \"\"; } CommonsMultipartFile 支持如下功能： 方法 说明 byte[] getBytes() 以字节数组的形式返回文件的内容 String getContentType() 返回文件的内容类型 InputStream getInputStream() 返回一个 InputStream，可以从中去读文件内容 String getName() 返回请求参数的name String getOriginalFilename() 返回文件原本的文件名 long getSize() 返回文件大小（单位字节） boolean isEmpty() 判断上传的文件是否为空 void transferTo(File destination) 将上传的文件保存到指定位置 如果从页面上同时上传多个文件，那么页面上的 file 可以使用同一个 name，而代码中则使用 CommonsMultipartFile 的数组类型的参数接受。数组中的每一个 MultipartFile 就代表着一个上传的文件。 @RequestParam(\"files\") CommonsMultipartFile[] files 使用 Servlet 3.1 内置的文件上传功能 补充，其实 Servlet 3.0 就已经开始提供内置的上传功能，只不过该功能在 Servlet 3.1 中进一步增强/改进/完成。因此一般的说法是 Servlet 3.1 支持内置的文件上传功能。 利用 Servlet 3.1 实现文件上传的概念和使用过程和利用 commons-fileupload 本质上并无太大区别。只不过有几处小区别： 提供文件上传功能的是 StandardServletMultipartResolver，不再是 CommonsMultipartResolver 。 spring-web.xml 对上传过程中的相关配置，是配置在 web.xml 中的 DispacherServlet 下，而非 spring-web.xml 中的 MultipartResolver 下。 web.xml hello org.springframework.web.servlet.DispatcherServlet ... ... d:/ 2097152 4194304 Controller 代码中使用的注解是 @RequestPart(\"file\")，而非 @RequestParam；绑定的参数类型是 MultipartFile，而不是 CommonsMultipartFile 。 @RequestMapping(\"/upload.do\") public String upload(String username, String password, @RequestPart(\"files\") MultipartFile[] files) MultipartFile 对象的功能与 CommonsMultipartFile 基本类似。 不过，有网友发现使用 StandardServletMultipartResolver 实现上传时有坑，见 stakoverflow 。所以，还是优先考虑使用 commons-fileupload 上传。 文件下载 Spring MVC 提供了一个 ResponseEntity 类型，使用它可以很方便地定义返回 HttpHeaders 和 HttpStatus ，以实现下载功能。 @RequestMapping(\"/download\") public ResponseEntity download( HttpServletRequest req, @RequestParam(\"filename\") String filename, Model model) throws Exception { System.out.println(filename); String path = req.getServletContext().getRealPath(\"upload\"); File file = new File(path + File.separator + filename); HttpHeaders headers = new HttpHeaders(); // 解决文件名乱码问题 // String downloadFileName = new String(filename.getBytes(\"UTF-8\"), \"iso-8859-1\"); headers.setContentDispositionFormData(\"attachment\", filename); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); return new ResponseEntity<>(FileUtils.readFileToByteArray(file), headers, HttpStatus.CREATED); } "},"Part-I/Springmvc/12-统一异常处理.html":{"url":"Part-I/Springmvc/12-统一异常处理.html","title":"统一异常处理","keywords":"","body":"Spring MVC 中的统一异常处理 Spring MVC 中跳转自定义 404 页面的两种常见方式 在 web.xml 中指定自定义的 404 页面 404 /WEB-INF/jsp/404.jsp 提供一个匹配 * 的 Controller 请求处理方法 // 凡是不能精确匹配的 url，都会由这个请求处理方法处理 @RequestMapping(\"*\") public String error404() { return \"404\"; } 使用 @ExceptionHandler 注解 @ExceptionHandler 注解用于标注于某个 Controller 的方法上，例如： @Controller public class GlobalController { /** * 用于处理异常的 */ @ExceptionHandler({AException.class, BException.class, ...}) public String exception(MyException e) { ... } @RequestMapping(\"test1\") public void test2() { ... } @RequestMapping(\"test2\") public void test2() { ... } } 当 Controller 的请求方法发生指定异常时，@ExceptionHandler 所标注的方法将会被执行。返回给服务器的数据也就由该方法的返回值决定。 @ExceptionHandler 所标注的方法的参数有以下几种： 一个异常参数。代表所发生的异常。 HttpServletRequest / HttpServletResponse 对象、 HttpSession 对象 Model 对象 等等。 @ExceptionHandler 所标注的方法的返回值的类型支持： ModelAndView 对象 Model 对象 Map 对象 View 对象 被解析成一个视图名称的 String 值 等等 另外，可以将 @ResponseStatus 与 @ExceptionHandler 结合使用，来定义 HTTP 响应的响应状态。 可以看到，这种方式最大的缺陷就是不能全局控制异常。每个类都要写一遍。 使用 @ControllerAdvice + @ ExceptionHandler 注解 @ExceptionHandler 需要进行异常处理的方法必须与出错的方法在同一个 Controller 里面。那么当代码加入了 @ControllerAdvice，则不需要必须在同一个 controller 中了。这也是 Spring 3.2 带来的新特性。从名字上可以看出大体意思是控制器增强。 使用示例 请确保此 WebExceptionHandle 类能被扫描到并装载进 Spring 容器中。由于标注了 @ControllerAdvice 注解，在开启了包扫描的情况下，Spring 会创建该类的单例对象。 @Slf4j @ControllerAdvice(assignableTypes = FirstController.class) public class FirstControllerExceptionHandler { @ExceptionHandler(IllegalArgumentException.class) public String demo1(Exception e) { log.warn(\"IllegalArgumentException\"); return \"\"; } @ExceptionHandler(NullPointerException.class) public String demo(Exception e) { log.warn(\"NullPointerException\"); return \"\"; } } 上述方法中的参数对象就是 Controller 层抛出的异常对象。注意，该方法如果有第二个参数，那么该机制会失效，无法捕获-处理 Controller 抛出的异常！ 控制生效的 Controller 范围 注意到，我是这样编写注解的： @ControllerAdvice(assignableTypes = {FirstController.class}) 它用来限定这些异常处理函数起作用的 Controller 的范围。如果不写，则默认对所有 Controller 有效。 这也是 ControllerAdvice 进行统一异常处理的优点，它能够细粒度的控制该异常处理器针对哪些 Controller 有效，这样的好处是： 一个系统里就能够存在不同的异常处理器，Controller 也可以有选择的决定使用哪个，更加灵活。 不同的业务模块可能对异常处理的方式不同，通过该机制就能做到。 设想一个一开始并未使用全局异常处理的系统，如果直接引入全局范围内生效的全局异常处理，势必可能会改变已有 Controller 的行为，有侵入性。 也就是说，如果不控制生效范围，即默认对所有 Controller 生效。如果控制生效范围，则默认对所有 Controller 不生效，降低侵入性。 ControllerAdvice 支持的限定范围： 按注解：@ControllerAdvice(annotations = RestController.class) 按包名：@ControllerAdvice(\"org.example.controllers\") 按类型：@ControllerAdvice(assignableTypes = {ControllerInterface.class, AbstractController.class}) "},"Part-I/Springmvc/13-Ajax.html":{"url":"Part-I/Springmvc/13-Ajax.html","title":"SpringMVC 处理 Ajax 请求","keywords":"","body":"$.ajax() 和 SpringMVC ajax() 方法 $.ajax({ url: ..., method: ..., contentType: ..., data: ..., dataType: ..., success : function(result) { ... } error: function(XMLHttpRequest, textStatus, errorThrown) {...} complete: function(XMLHttpRequest, textStatus) {...} }); 属性名 类型 说明 url string 所请求的 URL method string 请求方式 contentType string 所发送的参数数据的格式/类型默认值为： application/x-www-form-urlencoded data string 所发送的请求的参数数据 dataType string （预期的）服务器返回的数据格式/类型。使用时，通常就是 json。 注意，一不小心很容易错写成 application/json，从而导致程序总是进入 error 部分。 success function 成功收到服务器回的数据之后执行的回调函数 error function 收到服务器返回的错误信息之后执行的回调函数 常见的三个工具方法 var str = $.param(obj); // 对象转请求参数字符串 var str = JSON.stringify(obj); // 对象转json格式字符串 var obj = JSON.parse(json_str); // json格式字符串转对象 ajax() 发送普通请求的参数 这种情况下，和表单 的提交传参没有任何区别。Spring MVC 在后台都是通过 @RequestParam 进行参数绑定，获得 get/post 请求的请求参数。 无论是 get 类型的请求，还是 post 类型的请求，ajax() 方法的 data 属性需要的是一个请求参数字符串。 不过，get 类型的请求可以不必放在 data 属性部分，而是直接拼接在 uri 之后。 $.ajax({ ... data: 'empno=20&ename=tom', ... }); 原则上，此时 data 属性是需要一个请求参数字符串的。不过，ajax() 方法在此处有一个简化：你可以直接给 data 指定一个对象，由 ajax() 方法它自己去将对象转成请求参数字符串，而不需要我们手动来调用 $.param() 方法进行转换。 ajax() 发送简单类型数组的一个坑 类似于表单元素 checkbox 的那种情况，有时候，你需要通过 $.ajax() 向后台传递同一个 key 的多个 value 。 var nums = [1, 2, 3]; var str = $.param({\"xxx\": nums}); console.info(str); // 注意此处的输出！ $.ajax({ ... data: str, ... }); 这种情况，本质上和普通的请求中的 checkbox 有很大（但又很不起眼）的不同，jQuery 会在请求参数字符串的 key 的名字中加上 %5b%5d，其实就是 [] 。 因此，在 SpringMVC 的 @RequestParam 中指明的请求参数并不是 xxx，而应该是 xxx[] 。 public void demo(@RequestParam(\"xxx[]\") Integer[] prodNums) { ... } ajax 发送 json 对象 通过 ajax 发送请求参数字符串（所谓的发送 js 对象，本质上还是在其内部转换成了请求参数字符串），SpringMVC 在接受参数时，各个参数是『散』在方法的形参中的。 对于简单的情况，借助高级的参数绑定功能，SpringMVC 也可以将各个参数『收拢』到一个 JavaBean 中。 var emp = { empno: 20, ename: 'tom' }; var str = $.param(emp); // empno=20&ename=tom $.ajax({ ... data: str, // emp ... }); public void demo(Integer empno, String ename) { } public void demo(Employee emp) { // 注意，此处不需要 @RequestParam 注解 } 3. ajax 发送 application/json 参数类型的请求 contentType 没有赋值时，其默认值是 application/x-www-form-urlencoded 表示是普通的 get/post 请求。 如果，我们将 contentType 赋值为 application/json 表示向后台发起请求时，是将一个 JSON 格式的字符串携带在了 Request 的 body 部分，需要 Spring MVC 通过 @RequestBody 进行参数绑定，获取并解析出这个 JSON 格式字符串。 例如，向后台传递一个对象的数组： var emp1 = { empno: 20, ename: 'tom' }; var emp2 = { empno: 19, ename: 'ben' }; var arr = [emp1, emp2]; var str = JSON.stringify(arr); // [{\"empno\":20,\"ename\":\"tom\"},{\"empno\":21,\"ename\":\"jerry\"}] $.ajax({ ... data: str, contentType: \"application/json\", // “额外”说明，这次发送的数据是一个 json 格式字符串，而不是参数字符串 ... }); public void add(@RequestBody Employee[] emps) { } ajax 方法的 error 参数 当 http 响应的状态码不是 200 的时候，就会执行 error function 。 NOTE：一个常见的 Bug 是 data 属性值本应是 json，但是不小心错写成 applicaiton/json。 这种情况下，ajax 方法总是会进入 error 部分。因为预期的返回的数据类型（application/json）与实际类型（json）并不一致，也算是 error 。 一般 error 函数返回的参数有三个：function(XMLHttpRequest, textStatus, errorThrown)。我们关注的是第一个 XMLHttpRequest 。 从第一个参数 XMLHttpRequest 中我们可以获得服务端返回的错误相关的信息： XMLHttpRequest.status 返回的 HTTP 状态码，例如 404、500 等错误代码。 XMLHttpRequest.statusText 对应状态码的错误信息。比如 404 错误信息是 not found；500 是 Internal Server Error 。 XMLHttpRequest.responseText 服务器响应返回的文本信息，即，Response 的 body 的内容。 "},"Part-I/mybatis/01-基本用法.html":{"url":"Part-I/mybatis/01-基本用法.html","title":"基本用法","keywords":"","body":"基本概念 MyBatis 的体系结构 MyBatis 中的常用对象有 SqlSessionFactory 和 SqlSession 。 SqlSessionFactory 对象是 MyBatis 的关键对象，它对应着单个数据库。 XML 配置文件 └── SqlSessionFactoryBuilder └── SqlSessionFactory └── SqlSession 最终是需要获得一个 SqlSession 对象来操作数据库。SqlSession 对象代表着与数据库之间的连接。 要『弄』到 SqlSession 对象首先先得弄到『弄』一个 SqlSessionFactory 对象。 要『弄』到 SqlSessionFactory 对象首先先得弄到『弄』一个 SqlSessionFactoryBuilder 对象。 而在这个过程中，需要用到 1 + N 个配置文件。 InputStream is = Resources.getResourceAsStream(\"mybatis-config.xml\"); SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); SqlSessionFactory factory = builder.build(is); SqlSession session = factory.openSession(true); ... 注意：使用完 SqlSession 之后 关闭 Session 很重要，应该确保使用 finally 块来关闭它。 一个 MyBatis 应用程序只需要一个 SqlSessionFactory 的对象。因此，SqlSessionFactory 对象应该是 单例对象 。再将 Mybatis 和 Spring 整合后，毫无疑问，SqlSessionFactory 单例对象的创建工作就交到了 Spring 手里。 SqlSession 是线程不安全的，所以 SqlSession 对象是非单例的。 使用 XML 构建 SqlSessionFactory MyBatis 中的 XML 文件分为两类，一类是基础配置文件，它只有一个。另一类是映射文件，它至少有一个。合计是 1 + N 个配置文件。 基础配置文件通常叫做 mybatis-config.xml 文件，处于项目的 ClassPath 路径下。 元素为一个类定义了一个别名，这样在后续使用该类时，可以直接使用别名，而不是它的完全限定名。 environment 元素描述了一个数据库相关信息。 它里面的 元素配置了 事务管理器 ，这里采用的是 MyBatis 的 JDBC 管理器方式。 它里面的 元素配置了数据库连接的相关信息，其中属性 type=\"POOLED\" 表示采用 MyBatis 内部提供的连接池方式。 元素代表引入指定的Mapper配置文件。 为了加载 XML 配置文件来构建 SqlSessionFactory 对象。MyBaits 专门提供了 Resources 类来加载配置文件。 String resource = \"mybatis-config.xml\"; SqlSessionFactory factory = null; InputStream is = null; try { is = Resources.getResourceAsStream(resource); factory = new SqlSessionFactoryBuilder().build(is); } catch (IOException e) { e.printStackTrace(); } SqlSession SqlSession 是 MyBatis 的核心接口。SqlSession 的作用类似于 JDBC 中的 Connection 对象，代表着一个数据库的连接。 它的作用有三个： 获取 Mapper 接口。 发送 SQL 给数据库。 控制数据库事务。 有了 SqlSessionFactory 创建 SqlSession 就十分简单了： SqlSession sqlSession = factory.openSession(); // 相当于 SqlSession sqlSession = factory.openSession(false); 由此可见，SqlSession 默认 未开启 事务的自动提交（autoCommit）功能。因此需要程序员手动操作事务。 另外，如果在建表时，有意或无意使用的是 MyIsam 引擎，那么此处无论是 true，或者 false，都无法回滚，因为 MyIsam 数据库引擎本身就不支持事务功能（这是它与 InnoDB 引擎的重要区别之一）。 SqlSession session = null; try { session = factory.openSession(); // some code ... session.commit(); // 提交事务 } catch (Exception e) { session.rollback(); // 回滚事务 } finally { if (session != null) session.close(); // 务必确保关闭 session } 默认的别名 别名 Java 类型 是否支持数组 别名 Java 类型 是否支持数组 _byte byte Y byte Byte Y _short short Y short Short Y _int int Y int Integer Y _integer int Y integer Integer Y _long long Y long Long Y _float float Y float Float Y _double double Y double Double Y _boolean boolean Y boolean Boolean Y decimal BigDecimal Y bigdecimal BigDecimal Y string String Y date Date Y object Object Y collection Collection —— map Map —— hashmap HashMap —— 补充 表示事务管理器配置，可选值有：JDBC 和 MANAGED 。 属性值 说明 JDBC 这个配置表示 MyBatis 底层使用 JDBC 中的 Connection 对象进行事务的提交和回滚。 MANAGED 这个配置表示 MyBatis 底层不进行任何事物的提交和回滚操作，而是由“别人”（容器）来进行事务的操作。 不过，默认情况下它会关闭连接，而有些容器并不希望如此，所以通常使用子元素 来取消这种行为。 在整合 Spring 和 MyBaits 时，不需要在此配置事务管理器，因为 Spring 会使用其自身的事务管理器来覆盖此处的配置。 表示数据源配置，其可选值有：UNPOOLED、POOLED 和 JNDI 。 属性值 说明 UNPOOLED 表示不使用连接池，因此每次请求都会打开/关闭连接。 POOLED 表示使用 MyBatis 内部的数连接池功能，此时在底层 Connection 对象会被复用。 JNDI 这表示这数据库连接由容器维护。使用较少。 "},"Part-I/mybatis/02-执行SQL语句/":{"url":"Part-I/mybatis/02-执行SQL语句/","title":"执行SQL语句","keywords":"","body":"基本概念 Mapper 是 MyBatis 最强大的工具与功能，它用于执行 SQL 语句。 ... ... ... ... 元素 描述 备注 select 查询语句，常用又复杂 可以自定义参数，返回结果集等 insert 插入语句 执行后返回一个整数，代表插入的条数 update 更新语句 执行后返回一个整数，代表更新的条数 delete 删除语句 执行后返回一个整数，代表删除的条数 resultMap 定义查询结果映射关系，常用又复杂 它将提供映射规则 "},"Part-I/mybatis/02-执行SQL语句/01-增删改.html":{"url":"Part-I/mybatis/02-执行SQL语句/01-增删改.html","title":"执行增删改操作","keywords":"","body":"增删改操作 insert 元素 insert 元素的必要属性有 ： 元素名 说明 id 和 Mapper 的 namespace 组合起来是唯一的，提供给 MyBatis 调用。 parameterType 类的完全限定名，或内置/自定义的类的别名（Alias）。 可以向 SQL 传递 JavaBean 和 Map 等复杂参数类型，但 Map 参数不建议使用。 MyBatis 在执行插入之后会返回一个 整数，以表示插入的记录数。 INSERT INTO dept(dname, loc) VALUES(#{dname}, #{loc}); InputStream is = Resources.getResourceAsStream(\"mybatis-config.xml\"); SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(is); SqlSession session = factory.openSession(); Department dept = new Department(\"Test\", \"BeiJing\"); int n = session.insert(\"xxx.yyy.zzz.insertDepartment\", dept); System.out.println(n); // 输出打印 1 session.commit(); session.close(); insert 过程中的主键回填 大多数情况下，插入信息的主键是由数据库底层生成的，在插入数据后，我们往往需要这个主键，以便于未来的操作。为此，MyBatis 提供了主键回填功能。 开启主键回填功能的 insert 必要属性： 属性 说明 useGeneratedKeys 启用主键回填功能的开关属性。\"true\" keyProperty 指定需要回填的 Bean 属性（对应数据库主键列的那个属性） delete 元素 和 update 元素 和 insert 元素一样，MyBatis 执行完 update 元素 和 delete 元素后会返回一个整数，标示执行后影响的记录条数。 UPDATE dept SET dname = #{dname}, loc = #{loc} WHERE deptno = #{deptno} DELETE FROM dept WHERE deptno = #{deptno} ... session.insert(\"xxx.yyy.zzz.insertDepartment\", dept); ... session.update(\"xxx.yyy.zzz.updateDepartment\", dept); ... session.delete(\"xxx.yyy.zzz.deleteDepartment\", 41); ... "},"Part-I/mybatis/02-执行SQL语句/02-getMapper.html":{"url":"Part-I/mybatis/02-执行SQL语句/02-getMapper.html","title":"getMapper的使用","keywords":"","body":"getMapper 方法 通过 SqlSession 的 insert、upate、delete 和 selectOne、selectList 方法可以去调用 Mapper.xml 中定义的配置文件，进而操作数据库。不过，MyBatis 提供了更『高端』的操作，『帮』程序员去实现 DAO 层代码。 如果将 Mapper.xml 配置文件的 namespace『故意』写的和一个 DAO 接口的完全路径名一样，并且该接口中的方法名有『碰巧』和 Mapp.xml 配置文件中的各个 SQL 语句的 id 值一样，那么 MyBatis 就会去为该接口动态生成一个实现类。 通过 SqlSession 的 getMapper() 方法传入接口的类对象，就可以获得这个由 MyBatis 动态生成的 DAO 接口的实现类。 三个『保持一致』： Mapper.xml 的 namespace 与接口的完全限定名保持一致。 SQL 语句的 id 与接口中的方法名保持一致。 SQL 语句的 parameterType 与接口的方法的参数类型保持一致。 package com.xja.hemiao.dao; public interface DepartmentDao { public List listDepartments(); ... } SELECT * FROM dept ... DepartmentDao dao = session.getMapper(DepartmentDao.class); List list = dao.listDepartments(); "},"Part-I/mybatis/02-执行SQL语句/03-查.html":{"url":"Part-I/mybatis/02-执行SQL语句/03-查.html","title":"执行查操作","keywords":"","body":"查操作 select 元素 通过 MyBatis 执行 SQL 后，MyBatis 通过其强大的映射规则，可以自动地将返回的结果集绑定到 JavaBean 中。 select 元素的必要属性有： 属性 说明 id 和 Mapper 的 namespace 组合起来必须唯一 parameterType 类的完全限定名，或内置/自定义的类的别名（Alias）。可以向 SQL 传递 JavaBean 和 Map 等复杂参数类型。 resultType 类的完全限定名，查询结果将通过固定规范进行映射；或者定义为 int、double、float 等参数。 resultMap resultType 的“高级版”，允许我们自定义映射规则。不能与 resultType 同时使用。 select 与 聚合函数 并不是所有的 select 语句都会返回一行，或多行记录。例如，在 select 中使用聚合函数。这种情况对于 MyBatis 而言最为简单，因为不需要将结果集映射成 JavaBean ，它只需要返回一行一列的单个数据。 SELECT * FROM dept WHERE deptno = #{deptno} SELECT count(empno) FROM emp; int n = session.selectOne(\"xxx.yyy.zzz.getMaxSal\"); System.out.println(n); String str = session.selectOne(\"xxx.yyy.zzz.getemployeeCount\"); System.out.println(str); MyBatis 可以很智能地将返回结果转换为你所指定的类型，如：int、String 等。 "},"Part-I/mybatis/02-执行SQL语句/04-传递多个参数.html":{"url":"Part-I/mybatis/02-执行SQL语句/04-传递多个参数.html","title":"传递多个参数","keywords":"","body":"传递多个参数 多参数的传递有三种方法： 传递方式 说明 使用 Map 传参 不建议使用（已被 JavaBean 传参替代） 使用 JavaBean 传参 大量多参 传递时使用 使用 注解 传参 少量多参 传递时使用 使用 Map 传递多参数 MyBatis 支持 Map 对象作为参数，此时，要求 select 元素的 parameterType 值为 map 。 List selectBySal1(Map salMap); select * from emp where sal >= #{minSal} and sal &lt; #{maxSal} Map map = new HashMap<>(); map.put(\"minSal\", 1000); map.put(\"maxSal\", 2000); List list = dao.selectBySal1(map); for (Employee emp : list) { log.info(\"{}\", emp); } 使用 JavaBean 传递多参 由于 Map 的无语义性，因此官方 不建议使用 Map 传参！ 此时，要求 select 元素的 parameterType 属性值为 JavaBean 的完全限定名（或别名）。 @Data public class SallaryRegion { private Integer minSallary; private Integer maxSallary; } List selectBySal2(SallaryRegion region); select * from emp where sal >= #{minSallary} and sal &lt; #{maxSallary} 使用注解方式传递多参数 如果所有的多参数传递都通过定义并使用 JavaBean 来进行，那么项目中会出现大量的参数 JavaBean 的定义，显然这也并不太合理。 为此，Mybatis 提供了参数注解，以减少参数 JavaBean 的定义。 List selectBySal3( @Param(\"xxx\") Integer minSallary, @Param(\"yyy\") Integer MaxSallary); select * from emp where sal >= #{xxx} and sal &lt; #{yyy} 补充，MyBatis 框架的注解功能相对而言比较薄弱，官方推荐使用 XML 配置，而非注解，但是少量的多参数传递，是 必须使用注解 的场景。 "},"Part-I/mybatis/02-执行SQL语句/05-动态SQL.html":{"url":"Part-I/mybatis/02-执行SQL语句/05-动态SQL.html","title":"动态 SQL","keywords":"","body":"动态 SQL 简而言之，动态 SQL 就是在 Mapper 中使用分支、循环等逻辑。常见的动态 SQL 元素包括： if 元素 choose-when-otherwise 元素 where 元素 set 元素 foreach 元素 if 元素 if 元素是我们最常见的元素判断语句，相当于 Java 中的 if 语句。它的 test 属性是它的必要属性。 SELECT * FROM dept WHERE deptno = #{deptno} choose-when-otherwise 元素 MyBatis 并未提供类似 if-else 元素来处理分支情况，if 元素可出现多次，但它们是并列的判断，而非互斥的判断。 choose-when-otherwise 元素类似于 Java 中的 switch-case，用于处理多个条件间的互斥判断。 SELECT * FROM emp WHERE sal >= #{min} AND sal WHERE sal >= #{min} WHERE sal where 元素 如果我们强行规定，上述 choose-when-otherwise 所实现的功能必须使用 if 实现，那么将会写成如下形式： SELECT * FROM emp WHERE 1 = 1 AND sal >= #{min} AND sal 注意体会上面 WHERE 1 = 1 的位置及其作用。 由于判断条件有可能有，也可能没有，所有在 if 元素中，WHERE 关键字出现的地方就有些“尴尬”。WHERE 1 = 1 就是此问题的 非典型 解决方案。 MyBatis 提供了 Where 元素以解决上述尴尬问题。 SELECT * FROM emp AND sal >= #{min} AND sal set 元素 类似于 where 的元素，set 元素对应于 SQL 语句中的 SET 子句。它专用于 update 语句，用于包含所需更新的列。 set 元素常常和 if 元素联合使用。因为在“选择性更新”功能中，有一个最后一个逗号问题。 注意，更新行为务必要保证更新至少一个属性，否则 MyBatis 更新语句提示 update 语句错误 UPDATE dept dname = #{dname}, loc = #{loc}, WHERE deptno = #{deptno} foreach 元素 foreach 元素使用不多，但是当需要构建包含 IN 子句的查询时，则必用到。 SELECT * FROM emp WHERE deptno IN #{deptno} collection 属性表示集合类型，其属性值可以是 list 或 array，对应参数类型为 List 或 数组。 "},"Part-I/mybatis/03-映射结果集.html":{"url":"Part-I/mybatis/03-映射结果集.html","title":"映射结果集（基本）","keywords":"","body":"映射结果集（基本） 在前面的内容中，由于我们的 PO 类的属性名与数据库中表的列名是一致的，因此，在 Mapper.xml 配置文件中，Mybatis 省略/简化 掉了一块配置。 ... ... 很容易猜得到这个块配置的作用就是（在查询功能中）指定数据库的表的列与 PO 类的属性之间的对应关系 。 实际上，Mybatis 需要有这样的一个配置来 指导/告诉 它如何将结果集（ResultSet）中的数据映射成对象，或对象的集合。这是任何一个 ORM 框架的基本功能（重要功能）之一。 resultMap 元素必要的两个属性有： 属性名 说明 id resultMap 的唯一标识符。 type 它表示映射所返回的实际类型。 和 resultMap 最常见的两个子元素有： id 子元素 表示数据库表的主键列。 其中， column 属性表示表的列名； property 属性，表示映射对象的属性名 result 子元素 表示数据库的普通列。其中， column 属性，表示数据库表的列名； property 属性，表示映射对象的属性名 jdbcType 将 ResultSet 数据映射成对象时，会涉及到两种数据类型：数据库类型（varchar) 和 Java类型（String）。MyBatis 使用 类型转换器（typeHandler）来处理两种类型数据的转换问题。 补充，不同的数据库对于同一个数据类型的概念可能会使用不同的『单词』。例如： 整型，在 MySQL 中是 INT ，在 Oracle 中是 INTEGER 。 在 Java 的 JDBC 中，对不同数据库的各种类型的『称呼』进行了统一：JDBC 类型 。 整型的 JDBC Type 表示为 INTEGER ，既表示 MySQL 中的 INT ， 又表示 Oracle 中的 INTEGER 。 常见的有： JDBC Type Mysql Type Java Type SMALLINT SMALLINT short java.lang.Short INTEGER INTEGER int java.lang.Integer BIGINT BIGINT long java.lang.Long FLOAT FLOAT float java.lang.Float DOUBLE DOUBLE double java.lang.Double DECIMAL DECIMAL java.math.BigDecimal CHAR CHAR java.lang.String VARCHAR VARCHAR java.lang.String DATE DATE java.util.Date TIME TIME java.util.Date TIMESTAMP TIMESTAMP java.util.Date 注意： 对于 java.lang.Date 和 java.sql.Date，是两种不同的类型。在写 JavaBean 一定要确认你所使用的是哪个 Date 类型（一般都是使用 java.lang.Date）。 自动映射原理 在 MyBatis 的配置文件（settings 元素部分）中，有一个 autoMappingBehavior 配置，其默认值为 PARTIAL ，表示 MyBatis 会自动映射（简单的，没有嵌套关系的）结果集。 ... ... ... ... ... 如果你的类的属性名与表的字段名一致，那么 MyBatis 会自动将结果集的一行封装成一个 JavaBean 。 一般而言，数据库表和字段的命名风格是以下划线为分隔符，而 Java 中命名风格是驼峰命风格。 如果，PO 类的属性名和 Table 的列名仅仅是命名风格的不同，那么此时你可以使用 mapUnderscoreToCamelCase 进行控制，以便于自动转换或不转换。 ... ... ... ... ... "},"Part-I/mybatis/03-映射结果集-关系.html":{"url":"Part-I/mybatis/03-映射结果集-关系.html","title":"映射结果集（高级）","keywords":"","body":"映射结果集（高级） Table 的列名与 PO 类的属性名的不同，只是一个小 case。 真正的作用和价值并非在此，而是在于 关系映射 。 一对一映射 使用自定义映射的第二个，也是更重要的原因是：关联映射 。 两张表的一对一映射在类与类的关系上体现为 一个类“持有”另一个类。双向的一对一映射则表现为 两个类互相“持有”。 持有方所对应的表为『从表』，被持有方所丢应的表为『主表』。association 元素用于 从表 方。 association 元素的常用属性有： 属性 说明 property 属性 表示所映射对象的属性名。 column 属性 表示表的列名，此处必为 外键列 。 javaType 属性 表示属性所对应的类型名称。 select 属性 表示为了获取关联对象，所调用的另一条 MyBatis select 语句的 id 。 第一种写法：传统写法 ... 第二种写法：调用法 ... 一对多映射 一对多的映射在类与类的关系上体现为：一个类持有另一个类的一个对象，另一个类持有这个类的对象集合。 如果一对多映射是单向的，则只会使用到 collection 元素；如果一对多映射是双向的，那么还会使用到前面所说的 association 元素。 collection 元素的常用属性有： 属性 说明 property 属性 表示所映射对象的属性名。 column 属性 表示表的列名，此处必为 外键列 javaType 属性 表示属性所对应的类型名称，此处必为某种集合类型 ofType 属性 表示集合当中的单元类型 select 属性 表示为了获取关联对象，所调用的另一条 MyBatis select 语句的 id 第一种写法： select dept.deptno deptno, dept.dname dname, dept.loc loc, emp.empno empno, emp.ename ename, emp.job job, emp.mgr mgr, emp.hiredate hiredate, emp.sal sal, emp.comm com from dept, emp where dept.deptno = emp.deptno and dept.deptno = #{deptno} 第二种写法： ... 多对多映射 MyBatis 并没有提供专门的元素用于多对多方案，采取了一种“聪明”的办法，将“三张表”的多对多关系转化为“两张表”的一对多关系。 所以，在多对多关系中，使用的仍然是 collection 元素。 例如： ... "},"Part-I/mybatis/04-分页.html":{"url":"Part-I/mybatis/04-分页.html","title":"分页","keywords":"","body":"分页 Mybatis 中实现分页功能有两种途径： RowBounds 分页（不建议使用） PageHelper 分页 RowBounds 分页 MyBatis 本身通过 RowBounds 对象提供了分页功能，你仅需为你的 dao 的查询方法多添加 RowBounds 类型的一个参数，并且不需要对配置文件做任何调整。 RowBounds 也称原生分页、逻辑分页。 RowBounds bounds = new RowBounds(0, 4); List list = dao.select(bounds); 但是这种分页是一种 逻辑分页，MyBatis 并未使用 limit 子句，查询的仍是 所有数据，只是它仅给你“看”到了所有数据中的一部分，逻辑分页虽然完成了分页功能，但是它并未通过分页功能的对性能问题有所提升。 PageHelper 分页 PageHelper 是一款被广泛使用的 MyBatis 插件。它通过 Mybatis 的插件机制，巧妙地通过机制，在不需要配置文件（不需要写 limit 子句）的情况下，动态去修改你所执行的 SQL，在其后动态添加 limit 子句。 为了使用 PageHelper 需要引入相应的包： com.github.pagehelper pagehelper 5.1.8 PageHelper 是一款 MyBaits 插件，使用它需要向 Mybatis 注册 PageHelper，并对它作出相关配置（mybatis-config.xml）。 注意：pagehelper 有 4.x 和 5.x 两个版本，用法有所不同，并不是向下兼容，在使用 5.x 版本的时候可能会报错。例如，上面的 helperDialect 就是 5.x 中的配置，在 4.x 中使用的是 dialect 。 如果 Mybatis 整合进了 Spring，除了上述遮掩高配置外，还可以将相应的注册-配置工作就在 Spring 的配置文件中进行： params=value1 插件的属性配置： helperDialect 用于指明底层数据库类型：oracle, mysql, mariadb, sqlite, hsqldb, postgresql, db2, sqlserver, informix, h2, sqlserver2012, derby reasonable 是否启用『合理化』功能 启用（true）时，如果 pageNum ，会返回第一页内容；如果 pageNum > pages，会返回查询最后一页。 禁用（false）时，超出合理的范围会直接返回空数据。 在使用 PageHelper 时，PageHelper 提供了两种风格来描述分页： offset / limit 组合 PageHelper.offsetPage(0, 3); 很显然，这种风格就是 SQL 语句的分页写法 pageNum / pageSize 组合 PageHelper.startPage(1, 10); 这种风格实际上是在模拟“人的语气” 插件作者建议推荐方式 在你调用查询方法之前，调用 PageHelper 的上述两个方法中的任意一个，都可激活 PageHelper 插件的分页功能，使其动态地“帮”你修改SQL语句（添加limit子句）。而 Mybatis 的 select 返回的结果就返回的是一页数据。 PageHelper.startPage(4, 2); List list = empDao.selectByExample(null); PageInfo info = new PageInfo<>(list, 5); System.out.println(info); 注意，由于 PageHelper 插件的实现涉及到 ThreadLocal 原理，这导致一旦 PageHelper 生产了一个分页参数，但是没有被消费，这个参数就会一直保留在这个线程上。当这个线程再次被使用时，就可能导致不该分页的方法去消费这个分页参数，这就产生了莫名其妙的分页。所以，分页参数的创建代码，和查询方法的调用代码，必须“紧密的在一起”。 PageHelper 插件流行的原因在于，它不仅仅能实现分页功能，而且还进一步封装了页面上的 分页导航条 所需要的所有相关信息。 使用这一个功能时，你需要创建 PageInfo 对象，并为其设置 4 个关键数据： 页面上所需显示的数据（分页查询的结果） 导航栏上导航数字的个数 当前页号 页面大小 总数据量 例如： // >> PageInfo pageInfo = new PageInfo<>(empList, 5); pageInfo.setPageNum(4); // 当前页的页号 pageInfo.setPageSize(2);// 页面大小，即，每页显示的数据量 pageInfo.setTotal(32); // 数据库中的总数据量。该数据应该是执行另一条 count SQL 查出来的，而非写死的。 创建 PageInfo 对象，并为其 4 个核心属性赋值后，便可以使用它： log.info(\"是否有下一页：{}\", pageInfo.isHasNextPage()); log.info(\"是否有上一页：{}\", pageInfo.isHasPreviousPage()); log.info(\"导航栏上第一个页号：{}\", pageInfo.getNavigateFirstPage()); log.info(\"导航栏上最后一个页号：{}\", pageInfo.getNavigateLastPage()); log.info(\"导航栏上的五个导航数字：{}\", Arrays.toString(pageInfo.getNavigatepageNums())); log.info(\"共有 {} 页\", pageInfo.getPages()); log.info(\"{} / {} \", pageInfo.getPageNum(), pageInfo.getPages()); PageInfo 对象属性描述 属性 说明 举例 int pageNum 当前页 比如，当前为第 5 页 int pageSize 每页的数量 比如，每页（计划/预期）显示 10 条数据 int size 当前页的数量 比如，以 98 条总数据为例，每页最多显示 10 条（最后一页显示 8 条数据） int startRow 当前页面第一个元素在数据库中的行号 比如，以 98 条总数据的最后一页为例，第一条数据是第 91 条 int endRow 当前页面最后一个元素在数据库中的行号 比如，以 98 条总数据的最后一页为例，最后一条数据是第 98 条 int pages 总页数 比如，以 98 条总数据为例，每页显示 10 条（其中最后一页 8 条），因此共 10 页 int prePage 前一页 比如，当前是第 5 页，所以前一页为 4 int nextPage 下一页 比如，当前是第 5 页，所以下一页为 6 boolean isFirstPage = false 是否为第一页 比如，当前是第 5 页，不是第 1 页，所以为 false boolean isLastPage = false 是否为最后一页 比如，当前是第 5 页，不是最后 1 页，所以为 false boolean hasPreviousPage = false 是否有前一页 比如，当前是第 5 页，有前一页，所以为 true boolean hasNextPage = false 是否有下一页 比如，当前是第 5 页，有后一页，所以为 true int navigatePages 导航页码数 比如，页面导航栏显示 [3 4 5 6 7] 共 5 个数字 int[] navigatepageNums 所有导航页号 比如，页面导航栏显示 [3 4 5 6 7] 这 5 个数字 int navigateFirstPage 导航条上的第一页 比如，页面导航栏显示 [3 4 5 6 7] 时，第一页是第 3 页 int navigateLastPage 导航条上的最后一页 比如，页面导航栏显示 [3 4 5 6 7] 时，第一页是第 7 页 "},"Part-I/mybatis/05-Generator_Example.html":{"url":"Part-I/mybatis/05-Generator_Example.html","title":"MybatisGenerator和Example对象","keywords":"","body":"MyBatis Generator 和 Example 对象 Mybatis Generator Mybatis 属于 半自动 ORM 框架，在使用这个框架中，工作量最大的就是书写 Mapping 的映射文件，由于手动书写很容易出错，为此 Mybatis 官方提供了个 Mybatis-Generator 来帮我们自动生成文件。 早期的 Mybatis Generator 的使用十分原始，使用起来非常麻烦，在开源社区的努力下，截止目前为止，已经出现了图形化界面的使用方式，已经变得十分便捷（屏蔽掉了大量繁琐的生涩的配置操作）。 现在使用较多的图形化工具是 mybatis-generator-gui 使用方式十分简单： git clone https://github.com/zouzg/mybatis-generator-gui cd mybatis-generator-gui mvn jfx:jar cd target/jfx/app/ java -jar mybatis-generator-gui.jar 本工具由于使用了 Java 8 的众多特性，所以要求 JDK 1.8.0.60 以上版本，另外 JDK 1.9 及更高版本 暂时还不支持。 Mybatis Example 对象 Example 对象是一种简化条件查询的方案。通过它，你避免去编写大量的 DAO 中的 selectByXxx() 方法。 简单的情况（没有，或只有 and 关系）： EmployeeExample example = new EmployeeExample(); example.createCriteria() .andEmpnoEqualTo(7369) .andSalGreaterThanOrEqualTo(1500) .andSalLessThan(2000); List list = dao.selectByExample(example); System.out.println(list.size()); or() 方法是一个更通用的形式，可以用于实现任意的查询条件。其原理在于，任何一个复杂的查询语句，总能写成如下形式： where (... and ... and ...) or (... and ... and ...) or (...) 复杂的情况（有 or 关系，甚至是 and 和 or 混用）： TestTableExample example = new TestTableExample(); // 第 1 个括号中的两个并列条件 example.or() .andAaaEqualTo(5) .andBbbIsNull(); // 第 2 个括号中的两个并列条件 example.or() .andCccNotEqualTo(9) .andDddIsNotNull(); // 第 3 个括号中的唯一的条件 List list = new ArrayList(); list.add(8); list.add(11); list.add(14); list.add(22); example.or() .andEeeIn(field5Values); // 第 4 个括号中的唯一的条件 example.or() .andFffBetween(3, 7); 相当于 where (aaa = 5 and bbb is null) or (ccc != 9 and ddd is not null) or (eee in (8, 11, 14, 22)) or (fff between 3 and 7); "},"Part-I/mybatis/06-延迟加载.html":{"url":"Part-I/mybatis/06-延迟加载.html","title":"延迟加载","keywords":"","body":"延迟加载 如果一个对象关联另一个对象，那么在查询 A 对象的时候，会去关联查询 B 对象。 何时查询（加载）B 对象分为三种时机： 立即加载 激进式延迟加载 延迟加载 立即加载 MyBaits 默认是立即加载，即在查询 A 对象的时候，会立即查询其关联的 B 对象。如果，B 对象也有关联对象，例如 C 对象，那么还会立即查询 C 对象，... 因此类推，直到把所有有关联关系的数据全部查询出来。 激进式延迟加载 通过设置，可以启用延迟加载： 启用延迟加载之后，Mybatis 又是默认的激进地延迟加载。 Mybatis 内部会进行某种规则判断，从而使得激进式的延迟加载，有时候等同于立即加载，有时候等同于普通的延迟加载。 真-延迟加载 可以再通过配置关闭掉激进地延迟加载，从而进入普通的延迟加载： 普通的延迟加载只会在你真正用到 A 对象的 B 属性时，再去查询/加载 B 对象。 "},"Part-II/spring-boot/02-Java代码配置.html":{"url":"Part-II/spring-boot/02-Java代码配置.html","title":"Spring 中使用 Java 代码配置","keywords":"","body":"Java 代码配置 从 Spring 3.0 开始，Spring 官方就推荐大家使用 java 代码配置来代替以前的 xml 文件配置。而到了 SpringBoot，Java 代码配置更是成了标配。 Java 代码配置主要靠 Java 类和一些注解，比较常用的注解有： 常用注解 说明 @Configuration 声明一个类作为配置类，代替 .xml 文件 @Bean 声明在方法上，将方法的返回值加入Bean容器，代替 标签 @Value 属性注入 @PropertySource 指定外部属性文件 配置 Druid 数据库连接池的简单方式 Spring Boot 默认的数据库连接池是 HikariCP 。spring-boot-starter-parent 中设置了 HIkariCP 的版本信息。因此，如果使用 HikariCP 只用声明你要用它就行，而声明要使用 Druid，你需要自己指定所使用的版本。 引入依赖： mysql mysql-connector-java com.alibaba druid 1.1.6 编写 Java 配置类： @Configuration public class JdbcConfig { @Bean(initMethod = \"init\", destroyMethod = \"close\") public DataSource dataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://192.168.119.130:3306/scott?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8&useSSL=false\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123456\"); return dataSource; } } 以上代码配置等同于如下的 .xml 配置： 代码配置中引用关系的表示 上面的 DruidDataSource ，我们为其属性赋值时，它的四个属性都是简单类型属性，因此十分容易处理。但是，在 Spring 的容器中，Java Bean 可能会存在引用。 在 .xml 配置文件中，我们是通过 ref 属性为引用类型的属性赋值的。 例如： 而在 Java 代码配置中，有三种方式来配置 Java Bean 的引用关系（其中，推荐第三种）： 通过方法调用表示引用关系 如果两个 Java Bean 在同一个配置类中，可使用这种方式： @Bean public Employee employee() { Employee employee = new Employee(); employee.setId(10); employee.setName(\"tom\"); employee.setSalary(2000.0); employee.setDepartment(department()); return employee; } @Bean public Department department() { Department department = new Department(); department.setId(1); department.setName(\"研发部\"); department.setLocation(\"北京\"); return department; } 通过 @Autowire 表示引用关系 如果两个 Java Bean 分别在不同的 配置类中，可使用这种方式： @Autowired public Department department; @Bean public Employee employee() { Employee employee = new Employee(); employee.setId(10); employee.setName(\"tom\"); employee.setSalary(2000.0); employee.setDepartment(department); return employee; } 通过参数表示引用关系 无论两个 Java Bean 是在不同的配置类中，还是在同一个配置类中，都可使用这种方式： @Bean public Employee employee(Department department) { Employee employee = new Employee(); employee.setId(10); employee.setName(\"tom\"); employee.setSalary(2000.0); employee.setDepartment(department); return employee; } Druid 数据库连接池配置 v2 在上面的 Druid 的配置中，数据库连接的四大属性值是在代码中『写死』的。我们可以把它们『抽取』出来放在配置文件中。 配置文件 jdbc.properties jdbc.driverClassName = com.mysql.cj.jdbc.Driver jdbc.url = jdbc:mysql://127.0.0.1:3306/scott jdbc.username = root jdbc.password = 123456 在配置类中可以结合 @PropertySource 和 @Value 注解，让 Spring 从指定配置文件中读取数据，再注入到配置类中。 配置类 @Configuration @PropertySource(\"classpath:jdbc.properties\") // 这里 public class JdbcConfig { @Value(\"${jdbc.url}\") // 这里 String url; @Value(\"${jdbc.driverClassName}\") // 这里 String driverClassName; @Value(\"${jdbc.username}\") // 这里 String username; @Value(\"${jdbc.password}\") // 这里 String password; @Bean public DataSource dataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(url); dataSource.setDriverClassName(driverClassName); dataSource.setUsername(username); dataSource.setPassword(password); return dataSource; } } Druid 数据库连接池配置 v3 由于 Spring Boot 项目启动时，一定会加载项目的配置文件 application.properties，所以，我们可以直接将自定义的配置项写在 application.properties 中，而不必再单独的创建一个配置文件。 这种写法本质上，和上述的 jdbc.properties 的写法是一样的。 截至到这里，日常编程中的配置工作大体也就是如此。理论上，还有再进一步改进优化的余地，但是总体来说，必要性已经不大了。（可能，还把简单问题复杂化了）。 附：Druid 数据库连接池配置 v4 在配置类中，我们有四个属性用于接收/获取配置文件中的四项配置的值。我们可以将这个四个属性（及其功能）抽取到另一个单独的类中，从而使配置类的代码更简洁。 注意，这里我们需要使用一个叫 @EnableConfigurationProperties 的注解，为此，我们需要在 pom 中多引入一个依赖： org.springframework.boot spring-boot-configuration-processor true JdbcProperties： @ConfigurationProperties(prefix = \"jdbc\") // 去掉前缀 @PropertySource(\"classpath:application.properties\") public class JdbcProperties { private String url; private String driverClassName; private String username; private String password; /* * 其实，并不是严格要求属性文件中的属性名与成员变量名一致。 * 支持驼峰，中划线，下划线等转换。 */ // getter / setter ... } 配置类： @Configuration @EnableConfigurationProperties(JdbcProperties.class) // 这里 public class SpringDaoConfig { @Bean public DataSource dataSource(JdbcProperties jdbc) { // 这里 ... } } "},"Part-II/spring-boot/01-基础.html":{"url":"Part-II/spring-boot/01-基础.html","title":"Spring Boot 基础","keywords":"","body":"SpringBoot 基础 Spring Boot 是由 Pivotal 团队提供的基于 Spring 的全新框架，其设计目的是为了简化 Spring 应用的搭建和开发过程。该框架遵循『约定大于配置』原则，采用特定的方式进行配置，从而使开发者无需定义大量的 XML 配置。通过这种方式，Spring Boot 致力于在蓬勃发展的快速应用开发领域成为领导者。 Spring Boot 并不重复造轮子，而且在原有 Spring 的框架基础上封装了一层，并且它集成了一些类库（提供了默认的配置），用于简化开发。 简而言之，Spring Boot 就是一个大容器，其中包含了很多类库的默认配置，你只需要在项目中引入这些类库即可使用。 基本概念 SpringBoot 是 Spring 项目中的一个子工程，推崇约定大于配置的方式以便于你能够尽可能快速的启动并运行程序。 由于 SpringBoot 使用一些固定的方式来构建生产级别的 spring 应用，所有人们把 SpringBoot 称为搭建程序的 脚手架。 SpringBoot 简化了基于 Spring 的应用开发，只需要 run 就能创建一个独立的、生产级别的 Spring 应用。 SpringBoot 为 Spring 平台及第三方库提供开箱即用的设置（提供默认设置，存放默认配置的包就是启动器），这样我们就可以简单的开始。 多数 SpringBoot 应用只需要很少的 Spring 配置。 我们可以使用 SpringBoot 创建 java 应用，并使用 java –jar 启动它，就能得到一个生产级别的 web 工程。 SpringBoot 主要特点和目标是： 为所有 Spring 的开发者提供一个非常快速的、广泛接受的入门体验 开箱即用（启动器 `starter-* 其实就是 SpringBoot 提供的一个 jar 包），但通过自己设置参数（*.properties* 或 *.yml`* ），即可快速摆脱这种方式。 提供了一些大型项目中常见的非功能性特性，如内嵌服务器、安全、指标，健康检测、外部化配置等 绝对没有代码生成，也无需 XML 配置。 创建 SpringBoot 项目 创建一个 Maven 项目，但是不用勾选 Create from archetype。截止目前为止，该项目与 SpringBoot 还没有任何关系。 SpringBoot 提供了一个名为 spring-boot-starter-parent 的工程，里面已经对各种常用依赖（并非全部）的版本进行了管理，我们的项目需要以这个项目为父工程，这样我们就不用操心依赖的版本问题了，需要什么依赖，直接引入坐标即可！ 添加父工程坐标： org.springframework.boot spring-boot-starter-parent 2.1.11.RELEASE 添加 web 启动器： org.springframework.boot spring-boot-starter-web 需要注意的是，我们并没有在这里指定版本信息。因为 Spring Boot 的 父工程 已经对版本进行了管理了。 这些都是 Spring Boot 根据 spring-boot-starter-web 这个依赖自动引入的，而且所有的版本都已经管理好，不会出现冲突。 完整 pom 如下所示： 4.0.0 org.springframework.boot spring-boot-starter-parent 2.1.11.RELEASE hemiao3000.gitee.io springboot-demo 1.0-SNAPSHOT 1.8 org.springframework.boot spring-boot-starter-web 编码 编写启动类 SpringBoot 项目通过 main 函数即可启动，我们需要创建一个启动类： @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(SpringbootDemo1Application.class, args); } } 写 Controller 接下来的编码工作，就是正常的 Spring MVC 项目的开发过程。 @RestController public class HelloController { @GetMapping(\"/hello\") public String helo() { return \"hello world\"; } } 运行 / 测试 运行启动类的 main 方法，会在控制台中看见日志信息，其中有一条信息如下： Tomcat started on port(s): 8080 (http) with context path '' 监听的端口是 8080 Spring MVC 的映射路径是：/ /hello 路径已经映射到了 HelloController 中的 hello() 方法 打开页面访问：http://localhost:8080/hello properties 和 yaml Spring Boot 整个应用程序只有一个配置文件，那就是 .properties 或 .yml 文件。如果你的 Spring Boot 项目中没有包含这个配置文件，Spring Boot 对每个配置项都有默认值（当然，我们也可以添加配置文件，用以覆盖其默认值）。 这里以 .properties 文件为例，首先在 resources 下新建一个名为 applicatioon.properties（必须是这个名字）的文件。 输入内容为： server.port=8081 server.servlet.context-path=/api 并且启动 main 方法，这时程序请求地址则变成了：http://localhost:8081/api/hello 。 Spring Boot 支持 properties 和 yaml 两种格式的文件，文件名分别对应 application.properties 和 application.yml。 下面贴出 yaml 文件格式供大家参考： server: port: 8080 servlet: context-path: /api 可以看出 yaml 则 换行 + tab 隔开。这里需要注意的是冒号后面 必须空格，否则会报错。 日志 Spring Boot 直接使用 slf4j ，默认间接使用 logback 日志，因此，它支持直接在 .properties 和 .yml 文件中对日志的相关信息进行配置。 另外，Spring Boot 还支持控制台日志上色功能。 logging.level.root=INFO logging.level.xxx.yyy.zzz=DEBUG logging.pattern.console=${CONSOLE_LOG_PATTERN:\\ %clr(${LOG_LEVEL_PATTERN:%5p}) \\ %clr(|){faint} \\ %clr(%-40.40logger{39}){cyan} \\ %clr(:){faint} %m%n\\ ${LOG_EXCEPTION_CONVERSION_WORD:%wEx}} 有一点需要注意，如果是 .yml 文件格式，在设置 logging.pattern.console 时，其值必须用双引号括起来，形如：console=\"...\" 。 "},"Part-II/spring-boot/03-自动配置.html":{"url":"Part-II/spring-boot/03-自动配置.html","title":"Spring Boot 自动配置","keywords":"","body":"自动配置 SpringBoot 通过 自动配置 简化了大量的繁复的配置信息。 启动类 Application 中有两处特别之处： 注解：@SpringBootApplication run 方法：SpringApplication.run(...) @SpringBootApplication 注解至少等价于以下三个注解： @SpringBootConfiguration 该是来声明当前类是 SpringBoot 应用的配置类，一个项目中只能有一个。 因为该注解的存在，Spring 会再去『找』所有添加了 @Configuration 的类，做相应的操作。 @EnableAutoConfiguration 该注解的作用是告诉 Spring Boot 基于 .pom 文件中添加的的 starter 依赖，进行自动配置。 例如，我们引入了 spring-boot-starter-web，而这个启动器中帮我们添加了 tomcat、Spring MVC 的依赖。 SpringBoot 内部对大量的第三方库或 Spring 内部库进行了默认配置，这些配置是否生效，取决于我们是否引入了对应 starter 。 @ComponentScan 该注解提供了类似与 标签的作用。 通过 basePackageClasses 或者 basePackages 属性来指定要扫描的包。如果没有指定这些属性，那么将从声明这个注解的类所在的包开始，扫描包及子包。 因此，启动类需要放在一个比较前/浅的包目录中 。 spring-boot-autoconfigure.jar 中的 org.springframework.boot.autoconfigure 包下包含了各种框架/库的默认配置。 由 Spring 负责提供的 用于快速整合 XXX 框架/组件的自动配置快速整合包，通常的命名规则是：spring-boot-starter-xxx 。例如： spring-boot-starter-tomcat spring-boot-starter-thymleaf 这种由 Spring 提供的自动配置快速整合的包，其版本信息在 spring-boot-parent 中已定义，（除非是真有需要，否则）不需要指定版本信息。 由 XXX 框架/组件方负责提供的用于与 Spring 快速整合的包， 通常的命名规则是： xxx-spring-boot-starter 。例如： mybatis-spring-boot-starter druid-spring-boot-starter 这种由 XXX 方提供的自动配置快速整合包，需要指定版本信息。 "},"Part-II/spring-boot/04-spring-boot-jsp.html":{"url":"Part-II/spring-boot/04-spring-boot-jsp.html","title":"Spring Boot 中使用 JSP","keywords":"","body":"Spring Boot 项目中使用 JSP 想在 Spring Boot 中使用 JSP，需要满足一些特殊要求。 项目结构 Spring Boot 项目想要支持 JSP，其项目结构必须如下： spring-boot-jsp │── pom.xml └── src ├── main │ ├── java │ ├── resouces │ └── webapp │ └── WEB-INF │ └── jsp │ └── welcome.jsp └── test 在配置文件 application.properties 中进行配置： spring.mvc.view.prefix=/WEB-INF/jsp/ spring.mvc.view.suffix=.jsp spring.mvc.view.prefix 指明 jsp 文件在 webapp 下的哪个目录 spring.mvc.view.suffix 指明 jsp 以什么样的后缀结尾 引入依赖包 org.springframework.boot spring-boot-starter-web javax.servlet jstl org.apache.tomcat.embed tomcat-embed-jasper spring-boot-starter-web 包依赖了 spring-boot-starter-tomcat，因此，后者不再需要单独配置； jstl 是一个 JSP 的 jstl 标签库； tomcat-embed-jasper 主要用来支持 JSP 的解析和运行。 编写页面和后台 Time: ${time} Message: ${message} @Controller public class WelcomeController { @GetMapping(\"/\") public String welcome(Model model) { model.addAttribute(\"time\", new Date()); model.addAttribute(\"message\", \"hello world\"); return \"welcome\"; } } 运行方式一：Maven 命令运行 cmd 进入项目根路径下，执行： mvn clean spring-boot:run 补充：Idea 的 Maven 工具窗口中，有个 M 图标，通过点击它在弹出的窗口中可直接手动执行 maven 命令。 运行方式二：在 IDEA 中运行 如果像其他项目一样，直接在 IDEA 中通过 main 方法来启动项目，在访问测试的时候会出现 404 not found 。 这是因为 Spring Boot JSP 项目需要额外进行一个设置：选择 Edit Configurations 选项，打开 Configuration，为 Working directory 赋值为项目的根目录。 运行方式三：打 war 包部署运行 step 1：在 pom.xml 里设置打包格式为 war 。 war step 2：排除内嵌的 Tomcat 依赖，避免 jar 包冲突。 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-tomcat step 3：添加 Servlet 的支持 Spring Boot 项目必须实现 SpringBootServletInitializer 接口的 configure() 方法才能让外部容器运行 Spring Boot 项目。 在启动类同目录下创建 ServletInitializer 类： public class ServletInitializer extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { return application.sources(JspApplication.class); } } step 4：maven 命令打包 在项目根目录下执行： mvn clean package step 5：发布运行 将项目 target 目录下的 .war 包拷贝到 tomcat 的 webapps 目录下，运行 tomcat 的 bin 目录下的 startup.bat 启动 tomcat 。 在浏览器中访问即可。 "},"Part-II/spring-boot/05-thymeleaf基础.html":{"url":"Part-II/spring-boot/05-thymeleaf基础.html","title":"Spring Boot 中使用 Thymeleaf","keywords":"","body":"Thymeleaf Thymeleaf 简介 Thymeleaf 旨在提供一个优雅的、高度可维护的创建模板的方式。为了实现这一目标，Thymeleaf 建立在自然模板的概念上，将其逻辑注入到模板文件中，不会影响模板设计原型，从而改善了设计的沟通，弥合了设计和开发团队之间的差距。 Thymeleaf 从设计之初就遵循 Web 标准——特别是 HTML 5 标准，如果需要，Thymeleaf 允许创建完全符合 HTML 5 验证标准的模板。 Spring Boot 体系内推荐使用 Thymeleaf 作为前端页面模板，并且 Spring Boot 2.0 中默认使用 Thymeleaf 3.0，性能提升幅度很大。 与其他的模板引擎（JSP、Velocity、FreeMarker）相比较，它有如下三个极吸引人的特点： Thymeleaf 可以在浏览器查看页面的静态效果。 Thymeleaf 开箱即用的特性。它支持标准方言和 Spring 方言，可以直接套用模板实现 JSTL、OGNL 表达式效果。 Thymeleaf 方便与 SpringMVC 集成。 对比 Velocity、FreeMarker 与 Thymeleaf 打印出同一条消息： Velocity: $message FreeMarker: ${message} Thymeleaf: Hello World! 上面我们可以看出来 Thymeleaf 的作用域在 HTML 标签内，类似标签的一个属性来使用，这就是它的特点。 快速上手 pom.xml org.springframework.boot spring-boot-starter-thymeleaf application.properties spring.thymeleaf.cache=false logging.level.root=INFO logging.level.xxx.yyy.zzz=DEBUG logging.pattern.console=${CONSOLE_LOG_PATTERN:\\ %clr(${LOG_LEVEL_PATTERN:%5p}) \\ %clr(|){faint} \\ %clr(%-40.40logger{39}){cyan} \\ %clr(:){faint} \\ %m%n${LOG_EXCEPTION_CONVERSION_WORD:%wEx}} 关闭 Thymeleaf 的缓存。不然在开发过程中修改页面不会立即生效需要重启，生产可配置为 true 。 一个简单的页面 Hello Hello World 所有使用 Thymeleaf 的页面 必须 在 HTML 标签声明 Thymeleaf： 表明页面使用的是 Thymeleaf 语法。 Controller @Controller public class HelloController { @RequestMapping(\"/\") public String index(ModelMap map) { map.addAttribute(\"message\", \"http://www.baidu.com\"); return \"hello\"; } } 常用语法 赋值、字符串拼接 赋值和拼接： 我是默认值 我是默认值 字符串拼接还有另外一种简洁的写法（推荐）： 我是默认值 string.html 页面： ... text 我是默认值 我是默认值 我是默认值 后端传值： @RequestMapping(\"/string\") public String string(ModelMap map) { map.addAttribute(\"userName\", \"baidu\"); return \"string\"; } 条件判断 If/Unless Thymeleaf 中使用 th:if 和 th:unless 属性进行条件判断，在下面的例子中， 标签只有在 th:if 中条件成立时才显示： 示例： 163 baidu th:unless 与 th:if 恰好相反，只有表达式中的条件立，才会显示其内容。 页面 if.html： If/Unless 163 baidu 后端传值： @RequestMapping(\"/if\") public String ifunless(ModelMap map) { map.addAttribute(\"flag\", \"yes\"); return \"if\"; } for 循环 for 循环在我们项目中使用的频率太高，一般结合前端的表格来使用。 在后端定义一个列表，以键 users，传递到前端： @RequestMapping(\"/list\") public String list(ModelMap map) { User user1 = new User(\"大牛\",12,\"123456\"); User user2 = new User(\"小牛\",6,\"123563\"); User user3 = new User(\"纯洁的微笑\",66,\"666666\"); List list = new ArrayList(); list.add(user1); list.add(user2); list.add(user3); map.addAttribute(\"users\", list); return \"list\"; } list.html 进行数据展示： ... for 循环 neo 6 213 index iterStat 称作状态变量，属性有： 属性 | 说明 index | 当前迭代对象的 index （从 0 开始计算） count | 当前迭代对象的 index （从 1 开始计算） size | 被迭代对象的大小 current | 当前迭代变量 even/odd | 布尔值，当前循环是否是偶数/奇数（从 0 开始计算） first | 布尔值，当前循环是否是第一个 last | 布尔值，当前循环是否是最后一个 页面展示效果 for 循环 大牛 12 123456 0 小牛 6 123563 1 纯洁的微笑 66 666666 2 URL 处理 需要特别注意的是 Thymeleaf 对于 URL 的处理是通过语法 @{...} 来处理的。如果需要 Thymeleaf 对 URL 进行渲染，那么务必使用 th:href、th:src 等属性。 示例： link1 view 几点说明： 上例中 URL 最后的 (pageId=${pageId}) 表示将括号内的内容作为 URL 参数处理，该语法避免使用字符串拼接，大大提高了可读性； @{...} 表达式中可以通过 {pageId} 访问 Context 中的 pageId 变量； @{/order} 是 Context 相关的相对路径，在渲染时会自动添加上当前 Web 应用的 Context 名字，假设 context 名字为 app，那么结果应该是 /app/order 。 页面内容： ... URL link1 view 后端程序： @RequestMapping(\"/url\") public String url(ModelMap map) { map.addAttribute(\"type\", \"link\"); map.addAttribute(\"pageId\", \"springcloud/2017/09/11/\"); map.addAttribute(\"img\", \"http://www.baidu.com/assets/images/neo.jpg\"); return \"url\"; } 三目运算 三目运算是我们常用的功能之一，普遍应用在各个项目中。 例如： 说明： 表示如果 age 大于 30 则输入框中显示中年，否则显示青年。 三目运算符关键字： 关键字 | 说明 gt | great than（大于） ge | great equal（大于等于） eq | equal（等于） lt | less than（小于） le | less equal（小于等于） ne | not equal（不等于） 结合三目运算也可以将上面的 if else 改成这样： 百度 页面内容： ... EQ 百度 后端程序： @RequestMapping(\"/eq\") public String eq(ModelMap map) { map.addAttribute(\"name\", \"neo\"); map.addAttribute(\"age\", 30); map.addAttribute(\"flag\", \"yes\"); return \"eq\"; } 页面效果： EQ neo 青年 百度 单击 百度 链接会跳转到：http://www.baidu.com/ 地址。 switch 选择 switch/case 多用于多条件判断的场景下。 以性别举例： Example switch 她是一个姑娘... 这是一个爷们! 未知性别的一个家伙。 后端程序： @RequestMapping(\"/switch\") public String switchcase(ModelMap map) { map.addAttribute(\"sex\", \"woman\"); return \"switch\"; } 在浏览器中输入网址：http://localhost:8080/switch。 页面展示效果如下： 她是一个姑娘... 可以在后台改 sex 的值来查看结果。 『完』 "},"Part-II/spring-boot/06-spring-boot-mybatis.html":{"url":"Part-II/spring-boot/06-spring-boot-mybatis.html","title":"Spring Boot 集成 Mybatis","keywords":"","body":"pringBoot 整合 Mybatis 什么是 MyBatis-Spring-Boot-Starter mybatis-spring-boot-starter 是 MyBatis 帮助我们快速集成 SpringBoot 提供的一个组件包，使用这个组件可以做到以下几点： 构建独的应用 几乎可以零配置 需要很少的 XML 配置 mybatis-spring-boot-starter 依赖于 MyBatis-Spring 和 SpringBoot，最新版 1.3.2 需要 MyBatis-Spring 1.3 以上，SpringBoot 版本 1.5 以上。 注意 mybatis-spring-boot-starter 是 MyBatis 官方开发的 Starter，而不是 Spring Boot 官方开发的启动包。mybatis-spring-boot-starter 支持 XML 配置和注解配置两种。不过考虑到使用 mybatis-generator 生成 .xml 配置文件和 Example 对象的便捷性，优先考虑使用 xml 配置。 关键依赖包 mybatis-spring-boot-starter 的 pom 文件，现在最新版本是 2.1.0 。 org.mybatis.spring.boot mybatis-spring-boot-starter 2.1.0 application 配置 !FILENAME application.properties spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/scott\\ ?useUnicode=true\\ &characterEncoding=utf-8\\ &useSSL=true\\ &serverTimezone=UTC spring.datasource.username=root spring.datasource.password=123456 # jdbc-starter 中自带了一个连接池：HikariCP spring.datasource.hikari.idle-timeout=60000 spring.datasource.hikari.maximum-pool-size=30 spring.datasource.hikari.minimum-idle=10 mybatis.config-location=classpath:mybatis/mybatis-config.xml mybatis.mapper-locations=classpath:mybatis/mapper/*.xml logging.level.root=INFO logging.level.hemiao3000.gitee.io=DEBUG logging.pattern.console=${CONSOLE_LOG_PATTERN:\\ %clr(${LOG_LEVEL_PATTERN:%5p}) \\ %clr(|){faint} \\ %clr(%-40.40logger{39}){cyan} \\ %clr(:){faint} \\ %m%n${LOG_EXCEPTION_CONVERSION_WORD:%wEx}} 其中： 配置 说明 mybatis.config-locations 配置 mybatis-config.xml 路径，mybatis-config.xml 中配置 MyBatis 基础属性； mybatis.mapper-locations 配置 Mapper 对应的 XML 文件路径； mybatis.type-aliases-package 配置项目中实体类包路径； spring.datasource.* 数据源配置。 如果你需要使用 Druid 连接池，也可以使用 Druid 官方提供的启动器： com.alibaba druid-spring-boot-starter 1.1.10 而连接信息的配置与上面类似（四大连接属性不变），只不过在连接池特有属性上，方式略有不同： # 初始化连接数 spring.datasource.druid.initial-size=1 # 最小空闲连接 spring.datasource.druid.min-idle=1 # 最大活动连接 spring.datasource.druid.max-active=20 SpringBoot 启动时数据源会自动注入到 SqlSessionFactory 中，使用 SqlSessionFactory 构建 SqlSessionFactory，再自动注入到 Mapper 中，最后我们直接使用 Mapper 即可。 启动类 在启动类中添加对 Mapper 包扫描 @MapperScan，SpringBoot 启动的时候会自动加载包径下的 Mapper 。 @SpringBootApplication @MapperScan(\"com.xja.mapper\") public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 或者直接在 Mapper/DAO 类上面添加注解 @Mapper，建议使用上面那种，不然每个 mapper 加个注解也挺麻烦的。 如果使用的是 Idea，注入 DAO 时经常会报 could not autowire，Eclipse 却没有问题，其实代码是正确的，这是 Idea 的误报。可以选择降低 Autowired 检测的级别，不要提示就好。 在 File | Settings | Editor | Inspections 选项中使用搜索功能找到 Autowiring for Bean Class，将 Severity 的级别由之前的 error 改成 warning 即可。 "},"Part-II/spring-boot/07-spring-boot-jpa.html":{"url":"Part-II/spring-boot/07-spring-boot-jpa.html","title":"Spring Boot 集成 JPA","keywords":"","body":"Spring Data JPA 的基本使用 基本概念 JPA 由来 从理论上来说，Mybatis 和 Hibernate 并非同一类框架：Mybatis 是半自动 ORM 框架，而 Hibernate 是全自动的。 而从全自动 ORM 框架的角度来将，Hibernate 也非唯一的一个，跟它同类的竞争对手还有：TopLink、JDO 等（虽然市场占有率十分低） 。 不同的全自动（这里并不包括 Mybatis）之间，功能是是相似的，但是 API 接口的区别十分大。不便于项目在底层技术实现之间迁移。 JPA（Java Persistence API）是 Sun 官方提出的 Java 持久化 规范。它的出现主要是为了简化现有的持久化开发工作和整合 ORM 技术，提供统一的 API 接口，结束现在 Hibernate、TopLink、JDO 等 ORM 框架各自为营的局面。 注意：JPA 只是一套规范，不是一套产品。JPA 和 Hibernate、TopLink、JDO 之间的关系，就像 slf4j 和 log4j2、logback 之间的关系一样。 Spring Data JPA 一个项目直接（或间接）使用 Hibernate 有三种方式： 直接使用 Hibernate。 直接使用 JPA，间接使用 Hibernate； 通过 spring-data-jpa，将 JPA（和 Hibernate）整合进 Spring 项目，以一种特定的方式（sprig data）使用 JPA，从而间接使用 Hibernate 。 Spring Data JPA 是 Spring 基于 ORM 框架、JPA 规范的基础上封装的一套 JPA 应用框架。如果说，JPA 简化了 Hibernate 的使用，那么 spring-data-jpa 则是在这个基础上再一次简化了 hibernate，提高了开发效率。Spring Data JPA 让我们摆脱了 DAO 层的操作，基本上所有 CRUD 都可以依赖于它实现。 Spring Data JPA 其实就是要求在 Spirng Data 的体系下使用 JPA。Spring Data JPA 只是 Spring Data 体系中的一员。 快速上手 添加依赖 org.springframework.boot spring-boot-starter-data-jpa mysql mysql-connector-java 添加配置文件 spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://127.0.0.1:3306/scott\\ ?useUnicode=true\\ &characterEncoding=utf-8\\ &useSSL=true\\ &serverTimezone=UTC spring.datasource.username=root spring.datasource.password=123456 spring.jpa.show-sql=true spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5Dialect spring.jpa.properties.hibernate.format_sql=true spring.jpa.properties.hibernate.hbm2ddl.auto=update logging.level.root=INFO logging.level.hemiao3000.gitee.io=DEBUG logging.pattern.console=${CONSOLE_LOG_PATTERN:\\ %clr(${LOG_LEVEL_PATTERN:%5p}) \\ %clr(|){faint} \\ %clr(%-40.40logger{39}){cyan} \\ %clr(:){faint} \\ %m%n${LOG_EXCEPTION_CONVERSION_WORD:%wEx}} hibernate.hbm2ddl.auto 参数的作用主要用于：自动创建、更新、验证数据库表结构，有四个值。 值 说明 create 每次加载 Hibernate 时都会删除上一次生成的表，然后根据 model 类再重新来生成新表，哪怕两次没有任何改变也要这样执行，这就是导致数据库表数据丢失的一个重要原因。 create-drop 每次加载 Hibernate 时根据 model 类生成表，但是 sessionFactory 一关闭，表就自动删除。 update 最常用的属性，第一次加载 Hibernate 时根据 model 类会自动建⽴立起表的结构（前提是先建立好数据库），以后加载 Hibernate 时根据 model 类自动更新表结构，即使表结构改变了，但表中的行仍然存在，不会删除以前的行。要注意的是当部署到服务器后，表结构是不会被马上建立起来的，是要等应用第一次运行起来后才会。 validate 每次加载 Hibernate 时，验证创建数据库表结构，只会和数据库中的表进行比较，不会创建新表，但是会插入新值。 实体类 /* * DBMS - catalog - schema - table * Mysql - - database - table */ @Entity @Table(name=\"表名\", schema =\"数据库名\") public class User { @Id @GeneratedValue private Long id; @Column(nullable = false, unique = true) private String userName; @Column(nullable = false) private String passWord; @Column(nullable = false, unique = true) private String email; @Column(nullable = true, unique = true) private String nickName; @Column(nullable = false) private String regTime; // getter / settet ... } @Entity(name=\"EntityName\") 必须 用来标注一个数据库对应的实体，数据库中创建的表名默认和类名一致。其中，name 为可选,对应数据库中一个表，使用此注解标记 JavaBean 是一个 JPA 实体。 @Table(name=\"\", catalog=\"\", schema=\"\") 可选 用来标注一个数据库对应的实体，数据库中创建的表名默认和类名一致。通常和 @Entity 配合使用，只能标注在实体的 class 定义处，表示实体对应的数据库表的信息。 在数据库理论领域中，DBMS - Catalog - Schema - Table 是四级概念，但不是所有的数据库系统都支持这四级。MySql 就不支持其中的 catalog ，而 schema 就是 mysql 中的 database 。 @Id 必须 @Id 定义了映射到数据库表的主键的属性，一个实体只能有一个属性被映射为主键。 @GeneratedValue(strategy=GenerationType, generator=\"\") 可选 strategy：表示主键生成策略,有 AUTO、INDENTITY、SEQUENCE 和 TABLE 4 种。 generator：表示主键生成器的名称。 @Column(name=\"user_code\", nullable=false, length=32) 可选 @Column 描述了数据库表中该字段的详细定义，这对于根据 JPA 注解生成数据库表结构的工具。 name：表示数据库表中该字段的名称，默认情形属性名称一致; nullable：表示该字段是否允许为 null，默认为 true; unique：表示该字段是否是唯一标识，默认为 false; length：表示该字段的大小，仅对 String 类型的字段有效。 @Transient 可选 @Transient 表示该属性并非一个到数据库表的字段的映射，ORM 框架将忽略该属性。 @Enumerated 可选 使用枚举的时候，我们希望数据库中存储的是枚举对应的 String 类型，而不是枚举的索引值，需要在属性上面添加 @Enumerated(EnumType.STRING) 注解。 UUID 和 ASSIGNED 主键策略 通常 JPA【背后】是 Hibernate，而 Hibernate 除了和上述的一样的 identity、sequence 主键生成策略之外，还有 uuid 和 assigend 两种主键生成策略。 在 JPA 中使用 Hibernate 的 uuid 和 assigend 策略，需要【多】使用一个注解：@GenericGenerator 。 !FILENAME uuid @Id @GeneratedValue(generator = \"xxx\") @GenericGenerator(name = \"xxx\", strategy = \"uuid\") private String id; !FILENAME assigend @Id @GeneratedValue(generator = \"yyy\") @GenericGenerator(name = \"yyy\", strategy = \"assigned\") private Long id; Repository 构建 如果是直接使用 Hibernate 或 JPA，即便是最简单的查询操作，都是从获取核心对象 Session 开始。 由于我们是在 Spring Data 体系下使用 JPA，我们对于 JPA 的使用，就如同之前的 spring-data-redis（未来的 spring-data-elasticsearch）一样，继承 Spring Data 体系中的某个 Repository 接口，因此获得一套『现成』的增删改查一套方法。 创建的 Repository 只要继承 JpaRepository 即可，就会帮我们自动生成很多内置方法。 另外还有一个功能非常实用，可以根据方法名自动生产 SQL，比如 .findByUserName() 会自动生产一个以 userName 为参数的查询方法，比如 .findAll() 会自动查询表里面的所有数据等。 @Repository public interface UserRepository extends JpaRepository { User findByUserName(String userName); User findByUserNameOrEmail(String username, String email); } 我们只需要在对应的 Repository 中创建好方法，使用的时候直接将接口注入到类中调用即可。 JpaRepository 继承 PagingAndSortingRepository 和 QueryByExampleExecutor。PagingAndSortingRepository 又继承了 CrudRepository 。 CrudRepository 内置了我们最常用的增、删、改、查的方法。 PagingAndSortingRepository 类在 CrudRepository 基础上负责排序和分⻚，QueryByExampleExecutor 提供了很多示例的查询方法。 因此使用 JPA 操作数据库时，只需要构建的 Repository 继承了 JpaRepository，就会拥有了很多常用的数据库操作方法。 自定义查询 Spring Data JPA 可以根据接口方法名来实现数据库操作，主要的语法是 findXXBy、readAXXBy、 queryXXBy、countXXBy、getXXBy 后面跟属性名称，利用这个功能仅需要在定义的 Repository 中添加对应的方法名即可，使用时 Spring Boot 会自动帮我们实现，示例如下。 根据用户名查询用户： User findByUserName(String userName); 也可以加⼀一些关键字 And、or： User findByUserNameOrEmail(String username， String email); 修改、删除、统计也是类似语法： Long deleteById(Long id); Long countByUserName(String userName); 基本上 SQL 体系中的关键词都可以使用，如 LIKE 、IgnoreCase、OrderBy： List findByEmailLike(String email); User findByUserNameIgnoreCase(String userName); List findByUserNameOrderByEmailDesc(String email); 可以根据查询的条件不断地添加和拼接，Spring Boot 都可以正确解析和执行，其他使用示例例可以参考下表。 具体的关键字，使用方法和生产成 SQL 如下表所示 Keyword Sample JPQL snippet And findByLastnameAndFirstname … where x.lastname = ?1 and x.firstname = ?2 Or findByLastnameOrFirstname … where x.lastname = ?1 or x.firstname = ?2 Is, Equals findByFirstnameIs, findByFirstnameEquals … where x.firstname = ?1 Between findByStartDateBetween … where x.startDate between ?1 and ?2 LessThan findByAgeLessThan … where x.age LessThanEqual findByAgeLessThanEqual … where x.age GreaterThan findByAgeGreaterThan … where x.age > ?1 GreaterThanEqual findByAgeGreaterThanEqual … where x.age >= ?1 After findByStartDateAfter … where x.startDate > ?1 Before findByStartDateBefore … where x.startDate IsNull findByAgeIsNull … where x.age is null IsNotNull, NotNull findByAge(Is)NotNull … where x.age not null Like findByFirstnameLike … where x.firstname like ?1 NotLike findByFirstnameNotLike … where x.firstname not like ?1 StartingWith findByFirstnameStartingWith … where x.firstname like ?1 (parameter bound with appended %) EndingWith findByFirstnameEndingWith … where x.firstname like ?1 (parameter bound with prepended %) Containing findByFirstnameContaining … where x.firstname like ?1 (parameter bound wrapped in %) OrderBy findByAgeOrderByLastnameDesc … where x.age = ?1 order by x.lastname desc Not findByLastnameNot … where x.lastname <> ?1 In findByAgeIn(Collection ages) … where x.age in ?1 NotIn findByAgeNotIn(Collection age) … where x.age not in ?1 TRUE findByActiveTrue() … where x.active = true FALSE findByActiveFalse() … where x.active = false IgnoreCase findByFirstnameIgnoreCase … where UPPER(x.firstame) = UPPER(?1) JPA 高级查询： 自定义 SQL 查询 @Query 使用 Spring Data 大部分的 SQL 都可以根据方法名定义的方式来实现，但是由于某些原因必须使用自定义的 SQL 来查询，Spring Data 也可以完美支持。 在 SQL 的查询方法上面使用 @Query 注解，在注解内写 Hql 来查询内容。 @Query(\"select u from User u\") Page findALL(Pageable pageable); 当然如果感觉使用原生 SQL 更习惯，它也是支持的，需要再添加一个参数 nativeQuery = true 。 @Query(\"select * from user u where u.nick_name = ?1\", nativeQuery = true) Page findByNickName(String nickName, Pageable pageable); @Query 上面的 ?1 代表的是方法参数里面的顺序，如果有多个参数也可以按照这个方式添加 1、2、3....。除了按照这种方式传参外，还可以使用 @Param 来支持。 @Query(\"select u from User u where u.nickName = :xxx\") Page findByNickName(@Param(\"xxx\") String nickName, Pageable pageable); 如涉及到删除和修改需要加上 @Modifying，也可以根据需要添加 @Transactional 对事务的支持、操作超时设置等（以下仅作演示。@Transactional 注解应该用于 Service 层方法）。 @Transactional(timeout = 10) @Modifying @Query(\"update User set userName = ?1 where id = ?2\") int modifyById(String userName, Long id); @Transactional @Modifying @Query(\"delete from User where id = ?1\") void deleteById(Long id); 使用已命名的查询 除了使用 @Query 注解外，还可以预先定义好一些查询，并为其命名，然后再 Repository 中添加相同命名的方法。 定义命名的 Query： @Entity @NamedQueries({ @NamedQuery(name = \"DAO接口名.方法名\", query = \"HQL语句\"), @NamedQuery(name = \"User.findByPassWord\", query = \"select u from User u where u.passWord = ?1\"), @NamedQuery(name = \"User.findByNickName\", query = \"select u from User u where u.nickName = ?1\"), @namedQuery(name = \"...\", query = \"...\"), @namedQuery(name = \"...\", query = \"...\"), @namedQuery(name = \"...\", query = \"...\"), }) public class User { …… } 通过 @NamedQueries 注解可以定义多个命名 Query，@NamedQuery 的 name 属性定义了 Query 的名称，注意加上 . 作为前缀，query 属性定义查询语句。 定义对应的方法： List findByPassWord(String passWord); List findByNickName(String nickName); JPA 高级查询： 分页查询和限制查询 Spring Data JPA 已经帮我们内置了分页功能，在查询的方法中，需要传入参数 Pageable，当查询中有多个参数的时候 Pageable 建议 作为最后一个参数传入。 @Query(\"select u from User u\") Page findALL(Pageable pageable); Page findByNickName(String nickName, Pageable pageable); // Pageable pageable = PageRequest.of(0, 3); Pageable 是 Spring 封装的分页实现类，使用的时候需要传入页数、每页条数和排序规则，Page 是 Spring 封装的分页对象，封装了总页数、分页数据等。返回对象除使用 Page 外，还可以使用 Slice 作为返回值。 Slice findByNickNameAndEmail(String nickName, String email, Pageable pageable); Page 和 Slice 的区别如下: Page 接口继承自 Slice 接口，而 Slice 继承自 Iterable 接口。 Page 接口扩展了 Slice 接口，添加了获取总页数和元素总数量的方法，因此，返回 Page 接口时，必须执行两条 SQL，一条复杂查询分页数据，另一条负责统计数据数量。 返回 Slice 结果时，查询的 SQL 只会有查询分页数据这一条，不统计数据数量。 用途不一样：Slice 不需要知道总页数、总数据量，只需要知道是否有下一页、上一页，是否是首页、尾页等，比如前端滑动加载一页可用；而 Page 知道总页数、总数据量，可以用于展示具体的页数信息，比如后台分页查询。 实例： @Test public void testPageQuery() { int page=1, size=2; Sort sort = new Sort(Sort.Direction.DESC, \"id\"); Pageable pageable = PageRequest.of(page, size, sort); userRepository.findALL(pageable); userRepository.findByNickName(\"aa\", pageable); } Sort，控制分页数据的排序，可以选择升序和降序。 PageRequest，控制分页的辅助类，可以设置页码、每页的数据条数、排序等。 限制查询 有时候我们只需要查询前 N 个元素，或者只取前一个实体。 User findFirstByOrderByLastnameAsc(); User findTopByOrderByAgeDesc(); Page queryFirst10ByLastname(String lastname, Pageable pageable); List findFirst10ByLastname(String lastname, Sort sort); List findTop10ByLastname(String lastname, Pageable pageable); JPA 高级查询： 复杂查询 我们可以通过 AND 或者 OR 等连接词来不断拼接属性来构建多条件查询，但如果参数大于 6 个时，方法名就会变得非常的长，并且还不能解决动态多条件查询的场景。到这里就需要给大家介绍另外一个利器 JpaSpecificationExecutor 了。 JpaSpecificationExecutor 是 JPA 2.0 提供的 Criteria API 的使用封装，可以用于动态生成 Query 来满足我们业务中的各种复杂场景。Spring Data JPA 为我们提供了 JpaSpecificationExecutor 接口，只要简单实现 toPredicate 方法就可以实现复杂的查询。 我们来看一下 JpaSpecificationExecutor 的源码： public interface JpaSpecificationExecutor { // 根据 Specification 条件查询单个对象，注意的是，如果条件能查出来多个会报错 T findOne(@Nullable Specification spec); // 根据 Specification 条件查询 List 结果 List findAll(@Nullable Specification spec); // 根据 Specification 条件，分页查询 Page findAll(@Nullable Specification spec, Pageable pageable); // 根据 Specification 条件，带排序的查询结果 List findAll(@Nullable Specification spec, Sort sort); // 根据 Specification 条件，查询数量 long count(@Nullable Specification spec); } JpaSpecificationExecutor 的源码很简单，根据 Specification 的查询条件返回 List、Page 或者 count 数据。 在使用 JpaSpecificationExecutor 构建复杂查询场景之前，我们需要了解几个概念： 概念 说明 Root root 代表了可以查询和操作的实体对象的根，可以通过 get(\"属性名\") 来获取对应的值。 CriteriaQuery query 代表一个 specific 的顶层查询对象，它包含着查询的各个部分，比如 select、from、where、group by、order by 等。 CriteriaBuilder cb 来构建 CritiaQuery 的构建器器对象，其实就相当于条件或者是条件组合，并以 Predicate 的形式返回。 使用案例 首先定义一个 UserDetail 对象，作为演示的数据模型。 @Entity public class UserDetail { @Id @GeneratedValue private Long id; @Column(nullable = false, unique = true) private Long userId; private Integer age; private String realName; private String status; private String hobby; private String introduction; private String lastLoginIp; } 创建 UserDetail 对应的 Repository： public interface UserDetailRepository extends JpaSpecificationExecutor, JpaRepository { } 定义一个查询 Page\\ 的接口： public interface UserDetailService { public Page findByCondition(UserDetailParam detailParam, Pageable pageable); } 在 UserDetailServiceImpl 中，我们来演示 JpaSpecificationExecutor 的具体使用。 @Service public class UserDetailServiceImpl implements UserDetailService { @Autowired private UserDetailRepository userDetailRepository; @Override public Page findByCondition(Map params, Pageable pageable) { return userDetailRepository.findAll((root, query, cb) -> { List predicates = new ArrayList(); // equal 示例：“introduction = xxx” Predicate predicate1 = cb.equal(root.get(\"introduction\"), arg1); // like 示例：realName like ? Predicate predicate2 = cb.like(root.get(\"realName\"), \"%\" + arg2); // between 示例：age between (?, ?) Predicate predicate3 = cb.between(root.get(\"age\"), arg3, arg4); // greaterThan 大于等于示例 Predicate predicate4 = cb.greaterThan(root.get(\"age\"), arg5); // where A and B and (C or D) return cb.and( predicate1, predicate2, cb.or(predicate3, predicate4) ); }, pageable); } } 上面的示例是根据不同条件来动态查询 UserDetail 分页数据，UserDetailParam 是参数的封装，示例中使用了常用的大于、like、等于等示例，根据这个思路我们可以不断扩展完成更复杂的动态 SQL 查询。 使用时只需要将 UserDetailService 注入调用相关方法即可： @RunWith(SpringRunner.class) @SpringBootTest public class JpaSpecificationTests { @Autowreid private UserDetailService userDetailService; @Test public void testFindByCondition() { int page=0,size=10; Sort sort = new Sort(Sort.Direction.DESC, \"id\"); Pageable pageable = PageRequest.of(page, size, sort); UserDetailParam param = new UserDetailParam(); param.setIntroduction(\"程序员\"); param.setMinAge(10); param.setMaxAge(30); Page page1=userDetailService.findByCondition(param, pageable); for (UserDetail userDetail:page1){ System.out.println(\"userDetail: \"+userDetail.toString()); } } } JPA 高级查询： 多表查询 多表查询在 Spring Data JPA 中有两种实现方式，第一种是利用 Hibernate 的级联查询来实现，第二种是创建一个结果集的接口来接收连表查询后的结果，这里主要介绍第二种方式。 我们还是使用上面的 UserDetail 作为数据模型来使用，定义一个结果集的接口类，接口类的内容来自于用户表和用户详情表。 public interface UserInfo { String getUserName(); String getEmail(); String getAddress(); String getHobby(); } 在运行中 Spring 会给接口（UserInfo）自动生产一个代理类来接收返回的结果，代码中使用 getXXX() 的形式来获取。 在 UserDetailRepository 中添加查询的方法，返回类型设置为 UserInfo： @Query(\"select u.userName as userName, u.email as email, d.address as address, d.hobby as hobby from User u, UserDetail d where u.id = d.userId and d.hobby = ?1 \") List findUserInfo(String hobby); 特别注意这里的 SQL 是 HQL，需要写类的名和属性，这块很容易出错。 测试验证： @Slf4j @Test public void testUserInfo() { List userInfos=userDetailRepository.findUserInfo(\"钓鱼\"); for (UserInfo userInfo: userInfos) { log.info(\"userInfo: {}-{}-{}-{}\", userInfo.getUserName(), userInfo.getEmail(), userInfo.getHobby(), userInfo.getIntroduction()); } } 运行测试方法后返回： userInfo: aa-aa@126.com-钓鱼-程序员 证明关联查询成功，最后的返回结果来自于两个表，按照这个思路可以进行三个或者更多表的关联查询。 open session in view 启动类（或某个配置类）中加入 @Bean public OpenEntityManagerInViewFilter openEntityManagerInViewFilter() { return new OpenEntityManagerInViewFilter(); } 配置文件中加入 spring.jpa.open-in-view=true 。 『The End』 "},"Part-II/spring-boot/08-spring-boot-redis.html":{"url":"Part-II/spring-boot/08-spring-boot-redis.html","title":"Spring Boot 集成 Redis","keywords":"","body":"SpringBoot 中使用 Redis Redis 介绍 Redis 是一个 速度非常快的非关系数据库（Non-Relational Database） 它可以存储键（Key）与 5 种不同类型的值（Value）之间的映射（Mapping） 可以将存储在内存的键值对数据持久化到硬盘 可以使用复制特性来扩展读性能 还可以使用客户端分片来扩展写性能 为了满足高性能，Redis 采用内存（in-memory）数据集，根据使用场景，可以通过每隔一段时间转储数据集到磁盘，或者追加每条命令到日志来持久化。 持久化也可以被禁用，如果你只是需要一个功能丰富、网络化的内存缓存。 数据模型 Redis 数据模型不仅与关系数据库管理系统（RDBMS）不同，也不同于任何简单的 NoSQL 键-值数据存储。 Redis 数据类型类似于编程语言的基础数据类型，因此开发人员感觉很自然，每个数据类型都支持适用于其类型的操作，受支持的数据类型包括: 类型 说明 string 字符串 hash 哈希 list 列表 set 集合 zset sorted set:有序集合 关键优势 Redis 的优势包括它的速度、对富数据类型的支持、操作的原子性，以及通用性: # 优势 1 性能极高，它每秒可执行约 10，000 个 SET 以及约 100，000 个 GET 操作; 2 丰富的数据类型，Redis 对大多数开发人员已知的大多数据类型提供了原生支持，这使得各种问题得以轻松解决; 3 原子性，因为所有 Redis 操作都是原子性的，所以多个客户端会并发地访问一个 Redis 服务器，获取相同的更新值; 4 丰富的特性，Redis 是一个多效用工具，有非常多的应用场景，包括缓存、消息队列（Redis 原生支持发布/订阅）、短期应用程序数据（比如 Web 会话、Web 页面命中计数）等。 spring-boot-starter-data-redis Spring Boot 提供了对 Redis 集成的组件包：spring-boot-starter-data-redis，它依赖于 spring-data-redis 和 lettuce 。 另外，这里还有两个小细节： Spring Boot 1.x 时代，spring-data-redis 底层使用的是 Jedis；2.x 时代换成了 Lettuce 。 Lettuce 依赖于 commons-pool2 。 库 说明 Lettuce 一个可伸缩线程安全的 Redis 客户端，多个线程可以共享同一个 RedisConnection，它利用优秀 Netty NIO 框架来高效地管理多个连接。 Spring Data Spring 框架中的一个主要项目，目的是为了简化构建基于 Spring 框架应用的数据访问，包括非关系数据库、Map-Reduce 框架、云数据服务等，另外也包含对关系数据库的访问支持。 Spring Data Redis Spring Data 项目中的一个主要模块，实现了对 Redis 客户端 API 的高度封装，使对 Redis 的操作更加便捷。 可以用以下方式来表达它们之间的关系: Lettuce -> Spring Data Redis -> Spring Data -> spring-boot-starter-data-redis 快速上手 引入依赖包 org.springframework.boot spring-boot-starter-data-redis org.apache.commons commons-pool2 引入 commons-pool2 是因为 Lettuce 需要使用 commons-pool2 创建 Redis 连接池。 application 配置 # Redis 服务器地址 spring.redis.host=localhost # Redis 服务器连接端口 spring.redis.port=6379 # Redis 数据库索引(默认为 0) spring.redis.database=0 # Redis 服务器连接密码(默认为空) spring.redis.password= # 以下非必须，有默认值 # 连接池最大连接数(使用负值表示没有限制) 默认 8 spring.redis.lettuce.pool.max-active=8 # 连接池最大阻塞等待时间(使用负值表示没有限制) 默认 -1 spring.redis.lettuce.pool.max-wait=-1 # 连接池中的最大空闲连接 默认 8 spring.redis.lettuce.pool.max-idle=8 # 连接池中的最小空闲连接 默认 0 spring.redis.lettuce.pool.min-idle=0 测试使用 在单元测试中，注入 RedisTemplate 。String 是最常用的一种数据类型，普通的 key-value 存储都可以归为此类，value 其实不仅是 String 也可以是数字。 @RunWith(SpringRunner.class) @SpringBootTest public class TestRedisTemplate { @Autowired private RedisTemplate redisTemplate; @Test public void testString() { redisTemplate.opsForValue().set(\"hello\", \"world\"); Assert.assertEquals(\"world\", redisTemplate.opsForValue().get(\"hello\")); } } 在这个单元测试中，我们使用 redisTemplate 存储了一个字符串 \"world\" ，存储之后获取进行验证，多次进行 set 相同的 key，键对应的值会被覆盖。 Spring Data Redis 针对 api 进行了重新归类与封装，将同一类型的操作封装为 Operation 接口： 专有操作 说明 ValueOperations string 类型的数据操作 ListOperations list 类型的数据操作 SetOperations set 类型数据操作 ZSetOperations zset 类型数据操作 HashOperations map 类型的数据操作 @Autowired private RedisTemplate redisTemplate; @Test public void contextLoad() { assertNotNull(redisTemplate); ValueOperations operations1 = redisTemplate.opsForValue(); ListOperations operations2 = redisTemplate.opsForList(); SetOperations operations3 = redisTemplate.opsForSet(); ZSetOperations operations4 = redisTemplate.opsForZSet(); HashOperations operations5 = redisTemplate.opsForHash(); } 各类型实践 实体 @Slf4j @Test public void testObj() { ValueOperations operations = redisTemplate.opsForValue(); operations.set(\"id\", \"9527\"); operations.set(\"name\", \"tom\"); operations.set(\"age\", \"21\"); String name = operations.get(\"name\"); log.info(\"{}\", name); } 超时失效 Redis 在存入每一个数据的时候都可以设置一个超时间，过了这个时间就会自动删除数据。 新建一个 Student 对象，存入 Redis 的同时设置 100 毫秒后失效，设置一个线程暂停 1000 毫秒之后，判断数据是否存在并打印结果。 @Test public void testExpire() throws InterruptedException { Student user = new Student(\"tom\", 20); ValueOperations operations = redisTemplate.opsForValue(); operations.set(\"expire\", user, 100, TimeUnit.MILLISECONDS); Thread.sleep(1000); boolean exists = redisTemplate.hasKey(\"expire\"); if (exists) { System.out.println(\"exists is true\"); } else { System.out.println(\"exists is false\"); } } 输出结果: exists is false 从结果可以看出，Reids 中已经不存在 Student 对象了，此数据已经过期，同时我们在这个测试的方法中使用了 hasKey(\"expire\") 方法，可以判断 key 是否存在。 删除数据 有些时候，我们需要对过期的缓存进行删除，下面来测试此场景的使用。首先 set 一个字符串“ityouknow”，紧接着删除此 key 的值，再进行判断。 redisTemplate.delete(\"key\"); Hash（哈希） 一般我们存储一个键，很自然的就会使用 get/set 去存储，实际上这并不是很好的做法。Redis 存储一个 key 会有一个最小内存，不管你存的这个键多小，都不会低于这个内存，因此合理的使用 Hash 可以帮我们节省很多内存。 Hash Set 就在哈希表 Key 中的域（Field）的值设为 value。如果 Key 不存在，一个新的哈希表被创建并进行 HSET 操作;如果域（field）已经存在于哈希表中，旧值将被覆盖。 先来看 Redis 对 Pojo 的支持，新建一个 Student 对象（需要实现 Serializable 接口），放到缓存中，再取出来。 @Test public void testHash() { HashOperations hash = redisTemplate.opsForHash(); hash.put(\"tom\", \"name\", \"tom\"); hash.put(\"tom\", \"age\", \"20\"); String value = (String) hash.get(\"tom\", \"name\"); log.info(\"hash value : {}\", value); } 输出结果: hash value :tom 根据上面测试用例发现，Hash set 的时候需要传入三个参数，第一个为 key，第二个为 field，第三个为存储的值。一般情况下 Key 代表一组数据，field 为 key 相关的属性，而 value 就是属性对应的值。 List Redis List 的应用场景非常多，也是 Redis 最重要的数据结构之一。 使用 List 可以轻松的实现一个队列， List 典型的应用场景就是消息队列，可以利用 List 的 Push 操作，将任务存在 List 中，然后工作线程再用 POP 操作将任务取出进行执行。 @Test public void testList() { ListOperations list = redisTemplate.opsForList(); list.leftPush(\"list\", \"it\"); list.leftPush(\"list\", \"you\"); list.leftPush(\"list\", \"know\"); String value = (String)list.leftPop(\"list\"); log.info(\"list value : {}\", value.toString()); } 输出结果: list value :know 上面的例子我们从左侧插入一个 key 为 \"list\" 的队列，然后取出左侧最近的一条数据。其实 List 有很多 API 可以操作，比如从右侧进行插入队列，从右侧进行读取，或者通过方法 range 读取队列的一部分。接着上面的例子我们使用 range 来读取。 List values=list.range(\"list\", 0, 2); for (String v : values) { System.out.println(\"list range :\" + v); } 输出结果: list range :know list range :you list range :it range 后面的两个参数就是插入数据的位置，输入不同的参数就可以取出队列中对应的数据。 Redis List 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis 内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。 Set Redis Set 对外提供的功能与 List 类似，是一个列表的功能，特殊之处在于 Set 是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择，并且 Set 提供了判断某个成员是否在一个 Set 集合内的重要接口，这个也是 List 所不能提供的。 @Test public void testSet() { String key = \"set\"; SetOperations set = redisTemplate.opsForSet(); set.add(key, \"it\"); set.add(key, \"you\"); set.add(key, \"you\"); set.add(key, \"know\"); Set values = set.members(key); for (String v : values) { System.out.println(\"set value :\" + v); } } 输出结果: set value :it set value :know set value :you 通过上面的例子我们发现，输入了两个相同的值“you”，全部读取的时候只剩下了一条，说明 Set 对队列进行了自动的排重操作。 Redis 为集合提供了了求交集、并集、差集等操作，可以非常方便的使用。 测试 difference SetOperations set = redisTemplate.opsForSet(); String key1 = \"setMore1\"; String key2 = \"setMore2\"; set.add(key1, \"it\"); set.add(key1, \"you\"); set.add(key1, \"you\"); set.add(key1, \"know\"); set.add(key2, \"xx\"); set.add(key2, \"know\"); Set diffs = set.difference(key1, key2); for (String v : diffs) { System.out.println(\"diffs set value :\" + v); } 输出结果: diffs set value :it diffs set value :you 根据上面这个例子可以看出，ldifference() 函数会把 key1 中不同于 key2 的数据对比出来。 测试 unions SetOperations set = redisTemplate.opsForSet(); String key3 = \"setMore3\"; String key4 = \"setMore4\"; set.add(key3, \"it\"); set.add(key3, \"you\"); set.add(key3, \"xx\"); set.add(key4, \"aa\"); set.add(key4, \"bb\"); set.add(key4, \"know\"); Set unions = set.union(key3, key4); for (String v : unions) { log.info(\"unions value : {}\", v); } 输出结果: unions value : know unions value : you unions value : xx unions value : it unions value : bb unions value : aa 根据例子我们发现，unions 会取两个集合的合集，Set 还有其他很多类似的操作，非常方便我们对集合进行数据处理。 Set 的内部实现是一个 Value 永远为 null 的 HashMap，实际就是通过计算 Hash 的方式来快速排重，这也是 Set 能提供判断一个成员是否在集合内的原因 ZSet Redis Sorted Set 的使用场景与 Set 类似，区别是 Set 不是自动有序的，而 Sorted Set 可以通过用户额外提供一个优先级（Score）的参数来为成员排序，并且是插入有序，即自动排序。 在使用 Zset 的时候需要额外的输入一个参数 Score，Zset 会自动根据 Score 的值对集合进行排序，我们可以利用这个特性来做具有权重的队列，比如普通消息的 Score 为 1，重要消息的 Score 为 2，然后工作线程可以选择按 Score 的倒序来获取工作任务。 @Test public void testZset() { String key = \"zset\"; redisTemplate.delete(key); ZSetOperations zset = redisTemplate.opsForZSet(); zset.add(key, \"it\", 1); zset.add(key, \"you\", 6); zset.add(key, \"know\", 4); zset.add(key, \"neo\", 3); Set zsets = zset.range(key, 0, 3); for (String v : zsets) { log.info(\"zset value : {}\", v); } Set zsetB = zset.rangeByScore(key, 0, 3); for (String v : zsetB) { log.info(\"zsetB value : {}\", v); } } 输出结果: zset value : it zset value : neo zset value : know zset value : you zsetB value : it zsetB value : neo 通过上面的例子我们发现插入到 Zset 的数据会自动根据 Score 进行排序，根据这个特性我们可以做优先队列等各种常见的场景。 另外 Redis 还提供了 rangeByScore 这样的一个方法，可以只获取 Score 范围内排序后的数据。 Redis Sorted Set 的内部使用 HashMap 和跳跃表（SkipList）来保证数据的存储和有序，HashMap 里放的是成员到 Score 的映射，而跃表里存放的是所有的成员，排序依据是 HashMap 里存的 Score，使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。 Redis Repositories Spring Data Redis 从 1.7 开始提供 Redis Repositories ，可以无缝的转换并存储 domain objects，使用的数据类型为哈希（hash）。 Spring Data Redis 的 Repository 的基本实现为：CrudRepository 。 基础用法（Usage） 第一步：启用 Repository 功能 编写一个配置类（或直接利用 Spring Boot 的入口类），在其上标注 @EnableRedisRepositories，表示启用 Repository 功能。 第二步：注解需要缓存的实体 添加关键的两个注解 @RedisHash 和 @Id; @RedisHash(\"user\") public class User implements Serializable { private static final long serialVersionUID = 1L; @Id private Long id; private String userName; private String password; private String email; } 注解 说明 @RedisHash 表示将 User 类的对象都对于 Redis 中的名为 user 的 Set 中。 @Id 标注于对象的唯一性标识上。 如果将多个 User 对象通过 Repository 存储于 Redis 中，那么，它们每个的 key 分别是：*user: 。例如：user:1、user:2、user:3、... 获取它们每个对象的属性的命令为： hget user:1 userName Spring Data Redis 的默认映射规则： Simple Type String firstname = \"rand\" firstname = \"rand\" Complex Type Address adress = new Address(\"河南\", \"郑州\"); address.privince = \"河南\" address.city=\"郑州\" List of Simple Type List nicknames = [\"...\", \"...\", \"...\"] nicknames.[0] = \"dragon reborn\", nicknames.[1] = \"lews therin\" Map of Simple Type Map atts = { key1:val1, key2:val2 } atts.[key1] = \"val1\" atts.[key2] = \"val2\" List of Complex Type List\\ addresses = [ {...}, {...}, {...} ] addresses.[0].province = \"emond’s field\", addresses.[0].city = \"...\", addresses.[1].procinvce = \"...\", addresses.[1].city = \"…​ Map of Complex Type Map addresses = {key1: {}, key2: {}} addresses.[key1].city = \"emond’s field\", addresses.[key2].city = \"…​\" 第三步：创建一个 Repository 接口 自定的 Repository 接口必须继承 CrudRepository，才能“天生”具有存取数据的能力。 public interface UserRepository extends CrudRepository { } "},"Part-II/spring-boot/09-spring-session.html":{"url":"Part-II/spring-boot/09-spring-session.html","title":"Spring Boot 集成 spring-session","keywords":"","body":"Spring Session 实现 Session 共享 Session 共享问题 在微服务架构中，往往由多个微服务共同支撑前端请求，如果涉及到用户状态就需要考虑分布式 Session 管理问题。 比如用户登录请求分发在 服务器A ，用户购买请求分发到了服务器B ， 那么 服务器B 就必须可以获取到用户的登录信息，否则就会影响正常交易。 因此，在分布式架构或微服务架构下，必须保证一个应用服务器上保存 Session 后，其他应用服务器可以同步或共享这个 Session 。 目前主流的分布式 Session 管理有两种方案： Session 复制功能 部分 Web 服务器（例如，Tomcat）能够支持 Session 复制功能。用户可以通过修改 Web 服务器的配置文件，让 Web 服务器进行 Session 复制，保持每一个服务器节点的 Session 数据都能达到一致。 这种方案的局限性在于： 依赖于 Web 服务器。不是所有的 Web 服务器都提供这种功能。 每个 Web 服务器节点都会保存所有的 Session 对象，从而导致内存资源的浪费。 Session 集中存储 在单独的服务器（或服务器集群）上使用缓存技术集中管理所有的 Session 对象。所有的 Web 服务器都从这个存储介质中存取对应的 Session，实现 Session 共享。 Spring Session Spring Session 提供了一套创建和管理 Servlet HttpSession 的方案。它默认采用外置的 Redis 来存储 Session 数据，以此来解决 Session 共享的问题。 Spring 为 Spring Session 和 Redis 的集成提供了组件：spring-session-data-redis 。 快速集成 pom.xml org.springframework.boot spring-boot-starter-data-redis org.apache.commons commons-pool2 org.springframework.session spring-session-data-redis 注意：这个 spring-session-... 并不是 spring-session-core，虽然它引用到了 spring-session-core 。引入这个包的时候请注意一下。 配置文件 # Redis 配置 # Redis 数据库索引（默认为0） spring.redis.database=0 # Redis 服务器地址 spring.redis.host=localhost # Redis 服务器连接端口 spring.redis.port=6379 # Redis 服务器连接密码（默认为空） spring.redis.password= # 以下配置非本功能必须 # 连接池最大连接数（使用负值表示没有限制） spring.redis.lettuce.pool.max-active=8 spring.redis.lettuce.pool.max-wait=-1 spring.redis.lettuce.shutdown-timeout=100 spring.redis.lettuce.pool.max-idle=8 spring.redis.lettuce.pool.min-idle=0 配置类 @Configuration @EnableRedisHttpSession(maxInactiveIntervalInSeconds = 86400*30) public class SessionConfig { } maxInactiveIntervalInSeconds：设置 Session 失效时间，使用 Redis Session 之后，原 Spring Boot 中 的 server.session.timeout 属性不再生效。 至此，spring boot 的 session 共享功能配置结束。 验证 在 Web 层写两个方法进行验证。当然，偷懒一点，你可以将这里测试用的 @RestController 连通上面的 @Configuration 一起写在 spring boot 的启动类中。类似如下： @RestController @EnableRedisHttpSession(maxInactiveIntervalInSeconds = 86400 * 30) @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } @RequestMapping(value = \"/set\") public Map setSession(HttpServletRequest request) { Map map = new HashMap<>(); request.getSession().setAttribute(\"message\", request.getRequestURL()); request.getSession().setAttribute(\"hello\", \"world\"); map.put(\"sessionId\", request.getSession().getId()); map.put(\"request Url\", request.getRequestURL()); return map; } @RequestMapping(value = \"/get\") public Object getSession(HttpServletRequest request) { Map map = new HashMap<>(); map.put(\"sessionId\", request.getSession().getId()); map.put(\"message\", request.getSession().getAttribute(\"message\")); map.put(\"hello\", request.getSession().getAttribute(\"hello\")); return map; } } 复制一份本项目（或在 Idea 中启动两次，注意端口冲突问题），分别从两个 URL 中访问/触发 Session 的存取功能。 "},"Part-II/spring-boot/10-spring-cache.html":{"url":"Part-II/spring-boot/10-spring-cache.html","title":"Spring Boot 集成 spring-cache","keywords":"","body":"Spring Boot 中使用 Cache 缓存 基本概念 绝大多数的网站/系统，最先遇到性能瓶颈就是数据库，而且绝大多数的网站/系统的业务对数据库的操作都是读多写少。使用缓存做数据库的前置缓存，可以非常有效地降低数据库的压力，从而提升整个系统的响应效率和并发量。 大部分使用缓存的场景是基于数据库的缓存，这类缓存场景的逻辑往往是：如果缓存中存在数据，就从缓存中读取；如果缓存中不存在数据，就再从数据库中读取。 为了简化业务代码中的相关逻辑判断，Spring 在 3.1 版本引入了了基于注释驱动的 Spring Cache。它的原理是 Spring Cache 利用了 Spring AOP 的动态代理技术，在项目启动的时候动态生成它的代理类，在代理类中实现了对应的逻辑。 Spring Cache 它本质上不是一个具体的缓存实现方案，而是一个对缓存使用的抽象。简单来说，它相当于是 slf4j，它并不是真正干活的那个。 使用 Spring Cache 的好处： # 好处 1 提供基本的 Cache 抽象，方便切换各种底层 Cache； 2 通过注解 Cache 可以实现类似于事务一样，缓存逻辑透明的应用到我们的业务代码上，且只需要更少的代码就可以完成； 3 提供事务回滚时也自动回滚缓存； 4 支持比较复杂的缓存逻辑； Spring Boot 中 Cache 的使用 Spring Boot 提供了非常简单的解决方案，其中最核⼼的是三个注解： # 注解 1 @Cacheable 2 @CacheEvict 3 @CachePut spring-boot-starter-cache 是 Spring Boot 体系内提供使⽤用 Spring Cache 的 Starter 包。 org.springframework.boot spring-boot-starter-cache 它会进行缓存的自动化配置和识别，Spring Boot 为 Redis 自动配置了 RedisCacheConfiguration 等信息，spring-boot-starter-cache 中的注解也主要是使用了 Spring Cache 提供的支持。 整合 EHCache 初试 Spring Cache EhCache 是一个纯 Java 的进程内缓存框架，具有快速、精干等特点，Hibernate 中的默认 Cache 就是使用的 EhCache 。 @EnableCaching ... implements Serializable pom.xml net.sf.ehcache ehcache ehcache.xml @Cacheable @Cacheable 注解标注于查询方法上。被标注了该注解的方法的返回值，会被 Sprig Cache 存入缓存，并且在调用中先从缓存中获取。缓存中没有，才会执行该查询方法本身的逻辑（从数据库中查询）。 例如： @RequestMapping(\"/hello\") @Cacheable(value=\"helloCache\") public String hello(String name) { log.info(\"没有走缓存！\"); return \"hello \" + name; } 先后两次访问 http://localhost:8080/hello?name=ben 你会发现只有一个日志输出。 @Cacheable 支持如下几个参数： 参数 说明 value 缓存的名称。在 spring 配置文件中定义，必须指定⾄至少一个 key 缓存的 key，可以为空。如果指定，则要按照 SpEL 表达式编写；如果不指定，则缺省按照方法的所有参数进行组合。 condition 触发条件，只有满足条件的情况才会加入缓存，默认为空，既表示全部都加入缓存，支持 Spring EL 。 上述方法可以改造成： @RequestMapping(\"/condition\") @Cacheable(value=\"condition\", condition=\"#name.length() 在浏览器多次访问 http://localhost:8080/condition?name=justicando，会发现日志一次输出 没有缓存，这就是因为参数 name 不满足 length() 的要求（只有满足要求才会走缓存逻辑）。 总结： 当执行到一个被 @Cacheable 注解的方法时，Spring 首先检查 condition 条件是否满足; 如果不满足，执行方法，返回； 如果满足，在缓存空间中查找使用 key 存储的对象， 如果找到，将找到的结果返回， 如果没有找到，执行方法，将方法的返回值以 key-value 对象的方式存如缓存中，然后方法返回。 需要注意的是：当一个支持缓存的方法在对象内部被调用时是不不会触发缓存功能的。 @Cacheable 可以标注于类上。其效果等同于类下所有方法都标注了该注解。 用于 Repository 上 @Cacheable(cacheNames = \"cache\", key = \"#a0\") Hibernate: select account0_.id as id1_0_0_, account0_.amount as amount2_0_0_, account0_.name as name3_0_0_ from account account0_ where account0_.id=? INFO | com.softeem.CqrsDemo3ApplicationTests : Optional[Account{id=1, name='tommy', amount=1000.0}] Hibernate: select account0_.id as id1_0_0_, account0_.amount as amount2_0_0_, account0_.name as name3_0_0_ from account account0_ where account0_.id=? INFO | com.softeem.CqrsDemo3ApplicationTests : Optional[Account{id=1, name='tommy', amount=1000.0}] @CachePut @CachePut 与 @Cacheable 类似。相同点在于: 被标注了 @CachePut 的方法的返回的结果会被缓存。这和 @Cacheable 是一致的。 不同点在于： @CachePut 标注的方法没有从缓存中取数据的环节/功能 。 简单来说，@CachePut 标注的方法只会向缓存中存数据，而从不从缓存中取数据。 @CachePut 也是有 value、key、condition 三个属性，功能和使用方式和 @Cacheable 一致。 @CacheEvict @CacheEvict 注解标注于删除和修改方法上。 被标注了 @CacheEvict 注解的方法在执行结束后，Spring Cache 会删除该注解指定的缓存中的键值对。 @CacheEvict 可以指定的属性有 value、key、condition、allEntries 和 beforeInvocation，其中 value、key 和 condition 的语义与 @Cacheable 对应的属性类似。即 value 表示清除操作是发生在哪些 Cache 上的（对应 Cache 的名称）； key 表示需要清除的是哪个 key，如未指定则会使用默认策略生成的 key； condition 表示清除操作发生的条件。 allEntries 属性 allEntries 是 boolean 类型，表示是否需要清除缓存中的所有元素，默认为 false，表示不需要。当指定了 allEntries 为 true 时，Spring Cache 将忽略指定的 key，删除 value 指定的缓存中的所有键值对。 beforeInvocation 属性 清除操作默认是在对应方法成功执行之后触发的，那么这就导致这样的一个情况：方法如果因为抛出异常结束，而非正常结束，那么就不会触发清除操作 。 使用 beforeInvocation 可以改变触发清除操作的时间，当我们指定该属性值为 true 时，Spring 会在 调用该方法之前清除缓存中的指定元素。 @RequestMapping(\"/beforeInvocation\") @CacheEvict(value=\"usersCache\", allEntries=true, beforeInvocation=true) public void beforeInvocation() { throw new RuntimeException(\"test beforeInvocation\"); } SpEL 上下文数据 Spring Cache 提供了一些供我们使用的 SpEL 上下文数据，下表直接摘自 Spring 官方文档： @Caching 有时候我们可能组合多个 Cache 注解使用；比如用户新增成功后，我们要添加 id-user 键值对，添加 username-user 键值对，添加 email-user 键值对。此时就需要 @Caching 组合多个注解标签了。 @Caching( put = { @CachePut(value = \"user\", key = \"#user.id\"), @CachePut(value = \"user\", key = \"#user.username\"), @CachePut(value = \"user\", key = \"#user.email\") } ) public User save(User user) { ... } 从 @Caching 注解源码可以看出，除了 @Caching - @CachePut 这种组合使用之外，它也可以结合 @Cacheable 和 @CacheEvict 使用： @Caching( put = { @CachePut( ... ), @CachePut( ... ), @CachePut( ... ) } ) @Caching( cacheable = { @Cacheable( ... ), @Cacheable( ... ), @Cacheable( ... ) } ) @Caching( evict = { @CacheEvict( ... ), @CacheEvict( ... ), @CacheEvict( ... ) } ) "},"Part-II/spring-boot/11-spring-boot-quartz.html":{"url":"Part-II/spring-boot/11-spring-boot-quartz.html","title":"Spring Boot 集成 quartz","keywords":"","body":"SpringBoot 集成 Quartz 在项目开发中，经常需要定时任务来帮助我们来做一些内容，比如定时派息、跑批对账、业务监控等。 SpringBoot 体系中现在有两种方案可以选择： 第一种是 SpringBoot 内置的方式简单注解就可以使用 如果需要更复杂的应用场景可以使用 Quartz Quartz 目前是 Java 体系中最完善的定时方案。 SpringBoot 内置定时 pom 包配置 pom 包里面只需要引入 SpringBoot Starter 包即可，SpringBoot Starter 包中已经内置了定时的方法。 org.springframework.boot spring-boot-starter 启动类开启定时 在启动类上面加上 @EnableScheduling 即可开启定时: @Spring BootApplication @EnableScheduling public class Application { public static void main(String[] args) { SpringApplication.run(Application.class， args); } } 创建定时任务实现类 使用 SpringBoot 自带的定时非常的简单，只需要在方法上面添加 @Scheduled 注解即可。 定时任务1: @Component public class SchedulerTask { private int count=0; @Scheduled(cron=\"*/6 * * * * ?\") private void process(){ System.out.println(\"this is scheduler task runing \" + (count++)); } } 设置 process() 每隔六秒执行一次，并统计执行的次数。 我们还有另外的一种方案来设置，固定时间周期执行方法。 定时任务2: @Component public class Scheduler2Task { private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\"HH:mm:ss\"); @Scheduled(fixedRate = 6000) public void reportCurrentTime() { System.out.println(\"现在时间:\" + dateFormat.format(new Date())); } } 启动项目之后，就会在控制台看到打印的结果。 结果如下: this is scheduler 现在时间:09:44:17 this is scheduler 现在时间:09:44:23 this is scheduler 现在时间:09:44:29 this is scheduler 现在时间:09:44:35 task runing 0 task runing 1 task runing 2 task runing 3 说明两个方法都按照固定 6 秒的频率来执行。 参数说明 @Scheduled 参数可以接受两种定时的设置，一种是我们常用的 cron=\"*/6 * * * * ?\"，一种是 fixedRate = 6000，两种都可表示固定周期执行定时任务。 fixedRate 说明 @Scheduled(fixedRate = 6000):上一次开始执行时间点之后 6 秒再执行。 @Scheduled(fixedDelay = 6000):上一次执行完毕时间点之后 6 秒再执行。 @Scheduled(initialDelay=1000， fixedRate=6000):第一次延迟 1 秒后执行，之后按 fixedRate 的规则每 6 秒执行一次。 cron 说明 cron 一共有七位，最后一位是年，SpringBoot 定时方案中只需要设置六位即可: 第一位，表示秒，取值 0 ~ 59; 第二位，表示分，取值 0 ~ 59; 第三位，表示小时，取值 0 ~ 23; 第四位，日期天/日，取值 1 ~ 31; 第五位，日期月份，取值 1~12; 第六位，星期，取值 1 ~ 7，星期一，星期二...，注，不是第 1 周、第 2 周的意思，另外，1 表示星期天，2 表示星期一; 第七位，年份，可以留空，取值 1970 ~ 2099。 cron 中，还有一些特殊的符号，含义如下: (*) 星号 可以理解为每的意思，每秒、每分、每天、每月、每年 ... 。 (?) 问号 问号只能出现在日期和星期这两个位置，表示这个位置的值不确定，每天 3 点执行，因此第六位星期的位置，是不需要关注的，就是不确定的值;同时，日期和星期是两个相互排斥的元素，通过问号来表明不指定值，比如 1 月 10 日是星期一，如果在星期的位置另指定星期二，就前后冲突矛矛盾了。 (-) 减号 表达一个范围，如在小时字段中使用“10 ~ 12”，则表示从 10 到 12 点，即 10、11、12。 (,) 逗号 表达一个列表值，如在星期字段中使用“1、2、4”，则表示星期一、星期二、星期四。 (/) 斜杠 如 x/y，x 是开始值，y 是步长，比如在第一位(秒)，0/15 就是从 0 秒开始，每隔 15 秒执行一次，最后就是 0、15、30、45、60，另 */y，等同于 0/y 。 下面列举几个常用的例子子。 实例 说明 0 0 3 * * ? 每天 3 点执行 0 5 3 * * ? 每天 3 点 5 分执行 0 5 3 ? * * 每天 3 点 5 分执行，与上面作用相同 0 5/10 3 * * ? 每天 3 点的 5 分、15 分、25 分、35 分、45 分、55 分这几个时间点执行 0 10 3 ? * 1 每周星期天，3 点 10 分执行，注，1 表示星期天 0 10 3 ? * 1#3 每个月的第三个星期，星期天执行，# 号只能出现在星期的位置 Quartz Quartz 是一个开源的作业调度框架，它完全由 Java 写成，提供了巨大的灵活性而不牺牲简单性。 当定时任务愈加复杂时，使用 Spring 注解 @Schedule 已经不能满足业务需要。 Quartz 的优点: 丰富的 Job 操作 API; 支持多种配置; SpringBoot 无缝集成; 支持久化; 支持集群; Quartz 还支持开源，是一个功能丰富的开源作业调度库，可以集成到几乎任何 Java 应用程序中。 Quartz 体系结构 Quartz 有 4 个核心概念：Job(任务)、JobDetail(任务信息)、Trigger(触发器)和 Scheduler(调度器)。 Job 是一个接口，只定义一个方法 execute(JobExecutionContext context)，在实现接口的 execute 方法中编写所需要定时执行的 Job(任务)，JobExecutionContext 类提供了调度应用的一些信息; Job 运行时的信息保存在 JobDataMap 实例中。 JobDetail Quartz 每次调度 Job 时，都重新创建一个 Job 实例，因此它不接受一个 Job 的实例，相反它接收一个 Job 实现类(JobDetail，描述 Job 的实现类及其他相关的静态信息，如 Job 名字、描述、关联监听器等信息)，以便运行时通过 newInstance() 的反射机制实例化 Job。 Trigger 是一个类，描述触发 Job 执行的时间触发规则，主要有 SimpleTrigger 和 CronTrigger 这两个子类。当且仅当需调度一次或者以固定时间间隔周期执行调度，SimpleTrigger 是最适合的选择;而 CronTrigger 则可以通过 Cron 表达式定义出各种复杂时间规则的调度方案:如工作日周一到周五的 15:00 ~ 16:00 执行调度等。 Scheduler 调度器就相当于一个容器，装载着任务和触发器，该类是一个接口，代表一个 Quartz 的独立运行容器，Trigger 和 JobDetail 可以注册到 Scheduler 中，两者在 Scheduler 中拥有各自的组及名称，组及名称是 Scheduler 查找定位容器中某一对象的依据，Trigger 的组及名称必须唯一，JobDetail 的组和名称也必须唯一(但可以和 Trigger 的组和名称相同，因为它们是不同类型的)。Scheduler 定义了多个接口方法，允许外部通过组及名称访问和控制容器中 Trigger 和 JobDetail。 四者其关系如下图所示: Job 为作业的接口，为任务调度的对象; JobDetail 用来描述 Job 的实现类及其他相关的静态信息; Trigger 做为作业的定时管理工具，一个 Trigger 只能对应一个作业实例，而而一个作业实例可对应多个触发器; Scheduler 做为定时任务容器器，是 Quartz 最上层的东西，它提携了所有触发器和作业，使它们协调工作，每个 Scheduler 都存有 JobDetail 和 Trigger 的注册，一个 Scheduler 中可以注册多个 JobDetail 和多个 Trigger。 SpringBoot 和 Quartz SpringBoot 2.0 提供了 spring-boot-starter-quartz 组件集成 Quartz，让我们在项目中使用 Quartz 变得简单。 配置 pom.xml 添加 spring-boot-starter-quartz 组件: org.springframework.boot spring-boot-starter-quartz 简单示例 配置完成之后先来做一个最简单的示例，使用 Quartz 定时输出 Hello World 。 首先定义一个 Job 需要继承 QuartzJobBean，示例中 Job 定义一个变量 Name，用于在定时执行的时候传入。 public class SampleJob extends QuartzJobBean { private String name; public void setName(String name) { this.name = name; } @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException { System.out.println(String.format(\"Hello %s!\"， this.name)); } } 接下来构建 JobDetail，并且构建时传入 name 属性的值，构建 JobTrigger 和 scheduleBuilder，最后使用 Scheduler 启动定时任务。 @Configuration public class SampleScheduler { @Bean public JobDetail sampleJobDetail() { return JobBuilder .newJob(SampleJob.class) .withIdentity(\"sampleJob\") .usingJobData(\"name\"， \"World\") .storeDurably() .build(); } @Bean public Trigger sampleJobTrigger() { SimpleScheduleBuilder scheduleBuilder = SimpleScheduleBuilder .simpleSchedule() .withIntervalInSeconds(2) .repeatForever(); return TriggerBuilder.newTrigger() .forJob(sampleJobDetail()) .withIdentity(\"sampleTrigger\") .withSchedule(scheduleBuilder) .build(); } } JobBuilder 无构造函数，只能通过 JobBuilder 的静态方法 newJob(Class jobClass) 生成 JobBuilder 实例。 withIdentity 方法可以传入两个参数 withIdentity(String name，String group) 来定义 TriggerKey，也可以不设置，像上文示例中会自动生成一个独一无二的 TriggerKey 用来区分不同的 Trigger。 启动项目后每隔两秒输出:Hello World! Hello World! Hello World! Hello World! ... CronSchedule 示例 CronSchedule 可以设置更灵活的使用方式，定时设置可以参考上面的 cron 表达式。 首先定义两个 Job: public class ScheduledJob implements Job { @Override public void execute(JobExecutionContext context) throws JobExecutionException { System.out.println(\"schedule job1 is running ...\"); } } ScheduledJob2 和 ScheduledJob 代码基本一致。 按照使用 Quartz 的逻辑，构建 jobDetail、CronTrigger，最后使用 scheduler 关联 jobDetail 和 CronTrigger。scheduleJob1 设置每间隔 6 秒执行一次。 private void scheduleJob1(Scheduler scheduler) throws SchedulerException{ JobDetail jobDetail = JobBuilder .newJob(ScheduledJob.class) .withIdentity(\"job1\"， \"group1\") .build(); CronScheduleBuilder scheduleBuilder = CronScheduleBuilder .cronSchedule(\"0/6 * * * * ?\"); CronTrigger cronTrigger = TriggerBuilder .newTrigger() .withIdentity(\"trigger1\"， \"group1\") .withSchedule(scheduleBuilder) .build(); scheduler.scheduleJob(jobDetail，cronTrigger); } CronScheduleBuilder.cronSchedule(\"0/6 ?\")，按照 cron 表达式设置定时任务的执行周期。 ScheduleJob2 的内容和 ScheduleJob1 基本一致，时间设置为间隔 12 秒执行一次。 使用 Scheduler 启动两个定时任务。 public void scheduleJobs() throws SchedulerException { Scheduler scheduler = schedulerFactoryBean.getScheduler(); scheduleJob1(scheduler); scheduleJob2(scheduler); } 何时触发定时任务 我们有两种方案来触发 CronSchedule 定时任务，一种是启动时调用 scheduleJobs() 来启动定时任务，另外一种方案使用 SpringBoot 自带的 Scheduled 在特定时间触发启动。 第一种方方案，启动时触发定时任务: @Component public class MyStartupRunner implements CommandLineRunner { @Autowired public CronSchedulerJob scheduleJobs; @Override public void run(String... args) throws Exception { scheduleJobs.scheduleJobs(); System.out.println(\">>>> 定时任务开始执行 定时一个 Runner，继承 CommandLineRunner 并重新 run 方法，在 run 方方法中调用 scheduleJobs() 来启动定时任务。 第二种方案，特定时间启动定时任务: @Configuration @EnableScheduling @Component public class SchedulerListener { @Autowired public CronSchedulerJob scheduleJobs; @Scheduled(cron=\"0 30 11 25 11 ?\") public void schedule() throws SchedulerException { scheduleJobs.scheduleJobs(); } } 启动项目后每隔 6 秒输出 job1 内容，每隔 12 秒输出 job2 内容，再加上面示例每两秒输出的 Hello World，输出内容如下: Hello World! Hello World! Hello World! schedule job1 is running ... Hello World! Hello World! Hello World! schedule job1 is running ... schedule job2 is running ... ... 一般情况下，建议使用第一种方案来启动定时任务;第二种方案设置固定日期时，需要考虑重复启动定时任务的情况，重复启动定时任务会报错。 注意，两种启动方案，在项目中选择一种使用即可，否则会导致重复启动定时任务而报错。 "},"Part-II/spring-boot/12-spring-boot-mail.html":{"url":"Part-II/spring-boot/12-spring-boot-mail.html","title":"Spring Boot 开发邮件系统","keywords":"","body":"使用 Spring Boot 开发邮件系统 邮件发送流程 发信人在用户代理上编辑邮件，并写清楚收件人的邮箱地址; 用户代理根据发信人编辑的信息，生成一封符合邮件格式的邮件; 用户代理把邮件发送到发信人的邮件服务器上，邮件服务器上面有一个缓冲队列列，发送到邮件服务器上面的邮件都会加入到缓冲队列中，等待邮件服务器上的 SMTP 客户端进行行发送; 发信人的邮件服务器使用 SMTP 协议把这封邮件发送到收件人的邮件服务器上; 收件人的邮件服务器收到邮件后，把这封邮件放到收件人在这个服务器上的信箱中; 收件人使用用户代理来收取邮件，首先用户代理使用 POP3 协议来连接收件人人所在的邮件服务器，身份验证成功后，用户代理就可以把邮件服务器上面的收件人人邮箱里面的邮件读取出来，并展示给收件人。 这就是邮件发送的一个完整流程。 简单来说，邮件的接收发送类似 Git 中的 push 和 pull，是分开的两个操作。并且 push 和 pull 使用的是不同的协议：push 使用的是 SMTP 协议；pull 使用的是 POP3 协议。 简单使用 最早期的时候使用 JavaMail 的相关 API 来开发，需要自己去封装消息体，代码量比较庞大;后来 Spring 推出了 JavaMailSender 来简化邮件发送过程，JavaMailSender 提供了强大的邮件发送功能，可支持各种类型的邮件发送。 现在 Spring Boot 在 JavaMailSender 的基础上又进行了封装，就有了现在的 spring-boot-starter-mail，让邮件发送流程更加简洁和完善。 pom 包配置 org.springframework.boot spring-boot-starter-mail 配置文件 在 application.properties 中添加邮箱配置，不同的邮箱参数稍有不同，下面面列举几个常用邮箱配置。 163 邮箱配置 spring.mail.host=smtp.163.com // 邮箱服务器器地址 spring.mail.username=xxx@oo.com // 用用户名 spring.mail.password=xxx // 密码 spring.mail.default-encoding=UTF-8 // 超时时间，可选 spring.mail.properties.mail.smtp.connectiontimeout=5000 spring.mail.properties.mail.smtp.timeout=3000 spring.mail.properties.mail.smtp.writetimeout=5000 126 邮箱配置 spring.mail.host=smtp.126.com spring.mail.username=xxx@126.com spring.mail.password=xxx spring.mail.default-encoding=UTF-8 QQ 邮箱配置如下: spring.mail.host=smtp.qq.com spring.mail.username=xxx@qq.com spring.mail.password=xxx spring.mail.default-encoding=UTF-8 注意:测试时需要将 spring.mail.username 和 spring.mail.password 改成自自己邮箱对应的登录名和密码，这里的密码不是邮箱的登录密码，是开启 POP3 之后设置的客户端授权密码。 这里以 126 邮件举例，有两个地方需要在邮箱中设置。 开启 POP 3 / SMTP 服务、IMAP / SMTP 服务 图片下方会有 SMTP 等相关信息的配置提示。 开通设置客户端授权密码 设置客户端授权密码一般需求手机验证码验证。 文本邮件发送 Spring 已经帮我们内置了 JavaMailSender，直接在项目中引用即可，封装一个 MailService 类来实现普通的邮件发送方法。 @Component public class MailServiceImpl implements MailService { private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private JavaMailSender mailSender; @Value(\"${spring.mail.username}\") private String from; @Override public void sendSimpleMail(String to, String subject, String content) { SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(from); message.setTo(to); message.setSubject(subject); message.setText(content); try { mailSender.send(message); logger.info(\"简单邮件已经发送。\"); } catch (Exception e) { logger.error(\"发送简单邮件时发生生异常!\", e); } } } 文本邮件抄送使用:message.copyTo(copyTo) 来实现。 from，即为邮件发送者，一般设置在配置文件中 to，邮件接收者，此参数可以为数组，同时发送多人 subject，邮件主题 content，邮件的主体 邮件发送者 from 一般采用固定的形式写到配置文件中。 编写 test 类进行测试 @RunWith(SpringRunner.class) @Spring BootTest public class MailServiceTest { @Autowired private MailService MailService; @Test public void testSimpleMail() throws Exception { mailService.sendSimpleMail(\"hemiao3000@126.com\", \"这是一封简单邮件\", \"大家好，这是我的第一封邮件!\"); } } 稍微等待几秒，就可以在邮箱中找到此邮件内容了。 富文本邮件 在日常使用的过程中,我们通常在邮件中加入图片或者附件来丰富邮件的内容。 发送 HTML 格式邮件 邮件发送支持以 HTML 语法去构建自定义的邮件格式,Spring Boot 支持使用用 HTML 发送邮件。 我们在 MailService 中添加支持 HTML 邮件发送的方法: public void sendHtmlMail(String to, String subject, String content) { MimeMessage message = mailSender.createMimeMessage(); try { // true 表示需要创建一一个 multipart message MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); mailSender.send(message); logger.info(\"html邮件发送成功\"); } catch (MessagingException e) { logger.error(\"发送html邮件时发生生异常!\", e); } } 富文本邮件抄送使用:helper.addCc(cc) 来实现。 和文本邮件发送代码对比,富文本邮件发送使用 MimeMessageHelper 类,该类支持发送复杂邮件模板,支持文本、附件、HTML、图片等。 在测试类中构建 HTML 内容,测试发送: @Test public void testHtmlMail() throws Exception { String content = \"\\n\" + \"\\n\" + \"hello world ! 这是一一封html邮件!\\n\" + \"\\n\" + \"\"; mailService.sendHtmlMail(\"hemiao3000@126.com\",\"这是一封HTML邮件\", content); } 代码中拼接出的 HTML 的 String 字符串交给 MimeMessageHelper 来处理理,最后由邮件客户端负责渲染显示内容。 发送带附件的邮件 在 MailService 添加 sendAttachmentsMail 方法,发送带附件的邮件主要是使用 FileSystemResource 对文件进行封装,再添加到 MimeMessageHelper 中。 public void sendAttachmentsMail ( String to, String subject, String content, String filePath) { MimeMessage message = mailSender.createMimeMessage(); try { MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); FileSystemResource file = new FileSystemResource(new File(filePath)); String fileName = file.getFilename(); helper.addAttachment(fileName, file); // helper.addAttachment(\"test\"+fileName, file); mailSender.send(message); logger.info(\"带附件的邮件已经发送。\"); } catch (MessagingException e) { logger.error(\"发送带附件的邮件时发生生异常!\", e); } } 添加多个附件可以使用多条 helper.addAttachment(fileName, file) 。 在测试类中添加测试方法: @Test public void sendAttachmentsMail() { String filePath = \"e:\\\\temp\\\\fastdfs-client-java-5.0.0.jar\"; mailService.sendAttachmentsMail(\"hemiao3000@126.com\", \"主题:带附件的邮件\", \"有附件,请查收!\", filePath); } 附件可以是图片、压缩包、Word 等任何文件,但是邮件厂商一般都会对附件大小有限制,太大的附件建议使用网盘上传后,在邮件中给出链接。 发送带静态资源的邮件 邮件中的静态资源一般指图片,在 MailService 中添加 sendInlineResourceMail 方法: public void sendInlineResourceMail( String to, String subject, String content, String rscPath, String rscId) { MimeMessage message = mailSender.createMimeMessage(); try { MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); FileSystemResource res = new FileSystemResource(new File(rscPath)); helper.addInline(rscId, res); mailSender.send(message); logger.info(\"嵌入静态资源的邮件已经发送。\"); } catch (MessagingException e) { logger.error(\"发送嵌入静态资源的邮件时发生异常!\", e); } } 在测试类中添加测试方法: @Test public void sendInlineResourceMail() { String rscId = \"neo006\"; String content = \"这是有图片片的邮件:\"; String imgPath = \"e:\\\\temp\\\\weixin.jpg\"; mailService.sendInlineResourceMail(\"hemiao3000@126.com\", \"主题:这是有图片的邮件\", content, imgPath, rscId); } 添加多个图片可以使用多条 和 helper.addInline(rscId, res) 来实现。 "},"Part-II/spring-boot/13-spring-boot-swagger.html":{"url":"Part-II/spring-boot/13-spring-boot-swagger.html","title":"Spring Boot 中使用 Swagger","keywords":"","body":"Swagger 什么是 Swagger Swagger 是一系列 RESTful API 的工具，通过 Swagger 可以获得项目的⼀种交互式文档，客户端 SDK 的⾃ 动生成等功能。 Swagger 的目标是为 REST APIs 定义一个标准的、与语⾔言无关的接口，使人和计算机在看不到源码或者看不到文档或者不能通过网络流量检测的情况下，能发现和理解各种服务的功能。当服务通过 Swagger 定义，消费者就能与远程的服务互动通过少量的实现逻辑。 Swagger（丝袜哥）是世界上最流行的 API 表达工具。 快速上手 使用 Spring Boot 集成 Swagger 的理念是，使⽤用注解来标记出需要在 API 文档中展示的信息，Swagger 会根据项目中标记的注解来生成对应的 API 文档。Swagger 被号称世界上最流行的 API 工具，它提供了 API 管理的全套解决方案，API 文档管理需要考虑的因素基本都包含，这里将讲解最常用的定制内容。 Spring Boot 集成 Swagger 2.X 很简单，需要引入依赖并做基础配置即可。 io.springfox springfox-swagger2 2.8.0 io.springfox springfox-swagger-ui 2.8.0 创建 SwaggerConfig 配置类 @Configuration @EnableSwagger2 public class SwaggerConfig { } 在 SwaggerConfig 的类上添加两个注解： 注解 说明 @Configuration 启动时加载此类 @EnableSwagger2 表示此项目启用 Swagger API 文档功能 在 SwaggerConfig 中添加两个方法：（其中一个方法是为另一个方法作辅助的准备工作） @Bean public Docket api() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() // 此处自行修改为自己的 Controller 包路径。 .apis(RequestHandlerSelectors.basePackage(\"xxx.yyy.zzz\")) .paths(PathSelectors.any()) .build(); } 此方法使用 @Bean，在启动时初始化，返回实例 Docket（Swagger API 摘要对象），这里需要注意的是 .apis(RequestHandlerSelectors.basePackage(\"xxx.yyy.zzz\")) 指定需要扫描的包路路径，只有此路径下的 Controller 类才会自动生成 Swagger API 文档。 private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(\"XXX 项目接口文挡\") .description(\"XXX Project Swagger2 UserService Interface\") .termsOfServiceUrl(\"http://www.163.com\") .version(\"1.0\") .build(); } 这块配置相对重要一些，主要配置页面展示的基本信息包括，标题、描述、版本、服务条款等，查看 ApiInfo 类的源码还会发现支持 license 等更多的配置。 配置完成之后启动项目，在浏览器中输入网址 http://localhost:8080/swagger-ui.html，即可看到上面的配置信息，效果如下： Swagger 常用注解 Swagger 通过注解表明该接口会生成文档，包括接口名、请求方法、参数、返回信息等，常用注解内容如下： 作用范围 API 使⽤用位置 协议集描述 @Api 用于 Controller 类上 协议描述 @ApiOperation 用在 Controller 的方法上 非对象参数集 @ApiImplicitParams 用在 Controller 的方法上 非对象参数描述 @ApiImplicitParam 用在 @ApiImplicitParams 的方法里边 响应集 @ApiResponses 用在 Controller 的方法上 响应信息参数 @ApiResponse 用在 @ApiResponses 里边 描述返回对象的意义 @ApiModel 用在返回对象类上 对象属性 @ApiModelProperty 用在出入参数对象的字段上 例如： @Api(value = \"用户服务\", description = \"用户操作 API\") @RestController @RequestMapping(\"/user\") public class UserController { @ApiOperation(value = \"获取用户信息\", notes = \"根据id在取用户信息\", produces = \"application/json\", response = Result.class) @ApiImplicitParams({ @ApiImplicitParam(name = \"id\", value = \"用户Id\", required = true, dataType = \"int\", paramType = \"path\") }) @GetMapping(value = \"/{id}\") public Result getUser(@PathVariable int id) { System.out.println(id); return new Result(ResultCode.OK, new DomainUser()); } } "},"Part-II/middleware/nosql/redis/01-简介.html":{"url":"Part-II/middleware/nosql/redis/01-简介.html","title":"Redis 简介","keywords":"","body":"﻿Redis 简介 Redis 是目前使用最广泛的缓存中间件，相比 Memcached，Redis 支持更多的数据结构和更丰富的数据操作，而且 Redis 还有着丰富而成熟的集群方案和使用场景。 Redis 是一个速度非常快的非关系数据库（Non-Relational Database），它可以存储键（Key）与 5 种不同类型的值（Value）之间的映射（Mapping），可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展写性能。 为了满足高性能，Redis 采用内存（in-memory）数据集，根据使用场景，可以采用两种不同方式来实现数据持久化： 每隔一段时间转存储数据集到磁盘。 追加每条命令到日志中。 持久化也可以被禁用，如果你只是需要一个功能丰富的内存缓存。 数据模型 Redis 数据模型不仅仅与关系数据库管理系统（RDBMS）不同，也不同于任何简单的 NoSQL 键-值数据存储系统。 Redis 数据类型类似于编程语言的基础数据类型，因此开发人员感觉很自然，每个数据类型都支持适『用于其类型的操作』，以最大限度发挥每种数据类型的特性。 受支持的数据类型包括： string（字符串） hash（哈希） list（列表） set（集合） zset（sorted set：有序集合） 关键优势 Redis 的优势包括它的速度、对富数据类型的支持、操作的原子性，以及通用性： 性能极高，它每秒可执行约 100,000 个 SET 以及约 100,000 个 GET 操作； 丰富的数据类型，Redis 对大多数开发人员已知的多数数据类型提供了原生支持，这使得各种问题得以轻松解决； 原子性，因为所有 Redis 操作都是原子性的，所以多个客户端会并发地访问一个 Redis 服务器器，获取相同的更新值； 丰富的特性，Redis 是一个多效用工具，有非常多的应用场景，包括缓存、消息队列（Redis 原生支持发布/订阅）、短期应用程序数据据（比如 Web 会话）等。 Redis 的『快』的原因： 是对内存的较为简单的数据进行读写操作。 Redis 是 C 语言实现的，它的底层实现原理是基于 IO 多路复用技术。这个实现方案本身就是先进/高级/高效的。 Redis 的工作是基于单线程的，从而节省了多线程形式下线程切换的开销。 一次只运行一条命令，每条命令天生就是一个独立的事务。 拒绝使用长/慢命令，Redis 对外提供的每条命令都很高效快速。 其实并不是单线程 有些操作使用独立线程，其它的线程是去干其它的事情，和执行命令的工作线程无关 最后是事实也证明了其作者的最初分析思路是正确的：Redis 的单机性能的瓶颈是网络速度和网卡性能，而非 CPU 。 Redis 的通用命令 Redis 的常用的基础命令有： 命令 说明 ping PING 命令来测试客户端与 Redis 的连接是否正常。连接正常时会收到回复 PONG set / get 使用 set 和 get 可以向 redis 设置数据、获取数据。 del 删除指定 key 的内容。 Keys * 查看当前库中所有的 key 值 一个 Redis 实例可以包括多个数据库。不过，一个 redis 实例最多可提供 16 个数据库，而且固定了以下标从 0 到 15 作为数据库名。客户端默认连接第 0 号数据库。 可以通过 select 命令来当前数据库： select N 如果选择一个不存在数据库则会报错。 Redis 单机多实例（了解） 如果需要启动两个 Redis 实例，你可以这么干： 在 Redis 解压目录下创建两个文件夹，例如：6379 和 16379 。 将 redis.windows.conf 文件复制进这两个文件夹，并将 16379 中的配置文件中的 port 6379 改为 port 16379。 在这两个文件夹中，分别启动两个命令行，执行 ../redis-server.exe redis.windows.conf 命令。 未来，在使用 redis-cli.exe 连接 Redis 服务端的时候，就需要明确指定连接端口号。 持久化（了解） Redis 的高性能是由于其将所有数据都存储在了内存中，为了使 Redis 在重启之后仍能保证数据不丢失，需要将数据从内存中同步到硬盘中，这一过程就是持久化。 Redis支持两种方式的持久化，一种是 RDB 方式，一种是 AOF 方式。 RDB 方式 RDB 方式是 Redis 的默认持久化方式。 它是通过快照（snapshotting）完成的，当符合一定条件时 Redis 会自动将内存中的数据进行快照并持久化到硬盘。简单来说，就是直接将内存中的数据直接保存到硬盘上。 在 redis.windows.conf 配置文件中默认有此下配置： save 900 1 save 300 10 save 60 10000 save 开头的一行就是持久化配置，可以配置多个条件（每行配置一个条件），每个条件之间是『或』的关系，save 900 1 表示 900 秒钟（15 分钟）内至少 1 个键被更改则进行快照，save 300 10 表示 300 秒（5 分钟）内至少 10 个键被更改则进行快照。 Redis 启动后会读取 RDB 快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将记录一千万个字符串类型键、大小为 1GB 的快照文件载入到内存中需要花费 20～30 秒钟。 但是 RDB 方式实现持久化有个问题啊：一旦 Redis 异常（突然）退出，就会丢失最后一次快照以后更改的所有数据。因此在使用 RDB 方式时，需要根据实际情况，调整配置中的参数，以便将数据的遗失控制在可接受范围内。 AOF 方式 默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过配置文件中的 appendonly 参数开启： appendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof，可以通过 appendfilename 参数修改：appendfilename appendonly.aof "},"Part-II/middleware/nosql/redis/02-通用命令.html":{"url":"Part-II/middleware/nosql/redis/02-通用命令.html","title":"Redis 通用命令","keywords":"","body":"通用命令 keys 命令 > keys * # 遍历所有的 key # keys 命令一般不在生产环境中使用（因为生产环境中键值对极多） dbsize 命令 > dbsize # 计算 key 的总数 exists 命令 语法：exists > exists # 检测 key 是否存在（存在则返回1，不存在返回0） del 命令 语法：del [ ...] > del # 删除指定的键值对 expire 命令 语法： expire > expire # key 在 seconds 秒后过期 > ttl # 查询 key 的剩余过期时间（返回 -1 表示没有过期设置；返回 -2 表示过期删除） > persist key # 去掉 key 的过期设置 type 命令 语法：type > type # 返回 key 的类型 "},"Part-II/middleware/nosql/redis/03-字符串命令.html":{"url":"Part-II/middleware/nosql/redis/03-字符串命令.html","title":"Redis 字符串命令","keywords":"","body":"字符串命令 Redis 中的键（key）都是字符串，但是值可以有多种类型（常见五种）。 字符串类型的值（Value）最大不能超过 512M（已经足够大了）。 一般情况下，考虑到并发、流量等问题，通常字符串类型的值最大也只是 百K 级别。 主要命令： 命令 语法 get get set set del del Set 命令 Set 命令用于设置某个键值对的值（String），具体是哪个简直对由参数 key 决定。 如果键值对中已有值，Set 就覆写旧值，且无视旧类型（即，赋完值后为 String 型）。 语法 set 返回值 在 Redis 2.6.12 以前版本， Set 命令总是返回 OK 。 从 Redis 2.6.12 版本开始， Set 在设置操作成功完成时，才返回 OK 。 实例 首先，我们在 redis 中创建一个 key 并设置值。 对不存在的键进行设置 redis 127.0.0.1:6379> SET key \"value\" OK redis 127.0.0.1:6379> GET key \"value\" 对已存在的键进行设置 redis 127.0.0.1:6379> SET key \"new-value\" OK redis 127.0.0.1:6379> GET key \"new-value\" set 一个不存在的 key ，就是新增一个键值对；set 一个已存在的 key ，就是更新这个键值对。 带参数的 Set 命令 > set # 无论 key 是否存在，都进行设置 > set NX # key 不存在，才设置；等同于 setnx # 真正意义上的“新增”操作，因为要求之前是必须没有的。 > set XX # key 存在，才设置 # 真正意义上的“更新”操作，因为要求之前是必须有的。 Get Get 命令用于获取某个键值对的值（String），具体是哪个键值对由参数 key 决定。 如果键值对不存在，则返回 nil 。 如果键值对的值部分并非字符串类型，则返回一个错误。 语法 get 返回值 返回 key 对应的值，如果不存在时，则返回 nil。 如果 key 对应的值不是字符串类型，则返回一个错误。简而言之，告诉你 get 命令用错地方了。 实例 对不存在的 key 或字符串类型 key 进行 Get redis> GET db (nil) redis> SET db redis OK redis> GET db \"redis\" 对不是字符串类型的 key 进行 GET redis> DEL db (integer) 1 在 redis 中添加一个 list 类型的键值对 redis> LPUSH db redis mongodb mysql (integer) 3 redis> GET db (error) ERR Operation against a key holding the wrong kind of value del 命令 del 命令用于删除某个键值对。 如果 key 代表的键值对不存在，则该操作无任何效果。 实际上 del 命令是一个通用命令，各种类型结构都有这个命令。 语法 del 返回值 被删除的键值对的数量。 实例 首先，我们在 redis 中创建一个 key 并设置值 。 redis 127.0.0.1:6379> SET w3ckey redis OK 现在我们删除已创建的 key 。 redis 127.0.0.1:6379> DEL w3ckey (integer) 1 案例： 计数器：记录网站每个用户个人主页的访问量 缓存：缓存视频的基本信息（视频本身在 MySQL 中） 分布式 id 生成 次要命令 incr decr incrby decrby 前提要求，value 必须是数值型字符串 incr key 对应的 val 自增 1 。 如果 键值对 不存在，那么会新增该 键值对 其值会先被初始化为 0 ，然后再执行 incr 操作 语法 incr 返回值 执行完 Incr 命令之后，键值对 的值。 实例 redis> SET page_view 20 OK redis> INCR page_view (integer) 21 redis> GET page_view # 数字值在 Redis 中以字符串的形式保存 \"21\" decr 命令 decr 命令将某个 键值对 的 数值型字符串值 减一。 如果 键值对 不存在，那么会新建该键值对，并将其值初始化为 0 ，然后再执行 decr 操作。 语法 decr 返回值 新值，即减 1 之后的值 实例 对存在的数字值 key 进行 decr redis> SET failure_times 10 OK redis> DECR failure_times (integer) 9 对不存在的 key 值进行 decr redis> EXISTS count (integer) 0 redis> DECR count (integer) -1 对存在但不是数值的 key 进行 Decr redis> SET company YOUR_CODE_SUCKS.LLC OK redis> DECR company (error) ERR value is not an integer or out of range incrby 命令 incrby 命令用于将某个 键值对 中的 数字型字符串值 加上指定的增量值。 如果 键值对 不存在，那么会新建键值对，并将其值初始化为 0 ，然后再执行 incrby 命令。 语法 incrby 返回值 新值。即，增加指定增量之后的值。 实例 key 存在且是数字值 redis> SET rank 50 OK redis> INCRBY rank 20 (integer) 70 redis> GET rank \"70\" key 不存在时 redis> EXISTS counter (integer) 0 redis> INCRBY counter 30 (integer) 30 redis> GET counter \"30\" key 不是数字值时 redis> SET book \"long long ago...\" OK redis> INCRBY book 200 (error) ERR value is not an integer or out of range decrby 命令 decrby 命令用于将某个键值对的值减去指定的减量值，具体是哪个键值对由参数 key 决定。 要求键值对的值必须是数字型字符串。 如果键值对不存在，那么将新建键值对，将其值初始化为 0 ，然后再执行 Decrby 操作。 如果键值对额值不是 String 类型，或不是数字型 String 类型，那么返回一个错误。 语法 decrby 返回值 新值。即，减去指定量之后的值。 实例 对已存在的 key 进行 DECRBY redis> SET count 100 OK redis> DECRBY count 20 (integer) 80 对不存在的 key 进行DECRBY redis> EXISTS pages (integer) 0 redis> DECRBY pages 10 (integer) -10 其他命令 mget > mget ... # 批量获得 key 对应的值 # 原子操作，O(n) 复杂度 mset > mset ... # 批量设置键值对 getset > getset # 为键值对设置一个新值，于此同时返回原来的值 append > append # 将 val 追加到键值对的值后 strlen > strlen # 返回字符串的长度 incrbyfloat > incrbyfloat # 键值对的值自增，val为浮点型字符串 # 并没有浮点自减命令，但是可以传入一个负数实现自检减功能 getrange > getrange > # 获得指定范围区间中的值，包括 setrange > setrange > # 为值的指定区间赋值 "},"Part-II/middleware/nosql/redis/04-哈希命令.html":{"url":"Part-II/middleware/nosql/redis/04-哈希命令.html","title":"Redis 哈希命令","keywords":"","body":"哈希命令 Hash 结构与 字符串 有一定的相似性。 在 Hash 结构中，键值对的值又分为两个部分：field 和 value 。例如： key：users:1:info field: id，value: ... field: name，value: ... field: age，value: ... field: address，value: ... field: email，value: ... Hash 类型的价值在于，在 Redis 中存储了一个对象的信息后，可以单独更新该对象的某个属性的值，而不需要：取出-更新-序列化-存入 。 注意，与数据库中的列不同，Hash 结构中不强求两个键值对中必须有同样数量/名称的 field hset 命令 hset 命令用于向某个 HashTable 中添加新的键值对（ field - value ）。至于是哪个哈希表则取决与参数 key 。 注意，这里有两层键值对。 首先，整个 Redis 中的数据内容就是一对一对键值对（ key - hashtable ），其中，每个键值对的值部分都是一个 HashTable（HashTable 是 HashMap 的“高级”版本） 其次，HashTable 中存放的又是一对一对键值对（ filed - value ）。 如果 哈希表 不存在，这个哈希表会被创建，并添加至 Redis 中，然后再进行 Hset 操作。 如果 将要添加进哈希表中的 键值对 已经存在，则该 键值对 的旧值将被覆盖。 语法 Hset key field value 返回值 如果 field-value 是哈希表中的一个新建键值对，并且值设置成功，返回 1 。 如果在哈希表中 field - value 字段已经存在，则旧值被新值覆盖，返回 0 。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" OK redis 127.0.0.1:6379> HGET myhash field1 \"foo\" redis 127.0.0.1:6379> HSET website google \"www.g.cn\" # 设置一个新域 (integer) 1 redis 127.0.0.1:6379>HSET website google \"www.google.com\" # 覆盖一个旧域 (integer) 0 hsetnx Hsetnx 命令用于向某个哈希表中添加新的 field - value ，具体是哪个 HashTable 取决于参数 key 。 这里要求 filed - value 原本不存在于该 HashTable 中 。 如果 filed - value 不存在，则这个 filed - value 将被添加到 HashTable 中。 如果 filed - value 已经存在于哈希表中，操作无效。 如果 HashTable 不存在，一个新哈希表将被创建，并执行 HSETNX 命令。 语法 hsetnx 返回值 设置成功，返回 1 。 如果给定 filed - value 已经存在，则没有操作被执行，返回 0 。 实例 redis 127.0.0.1:6379> HSETNX myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HSETNX myhash field1 \"bar\" (integer) 0 redis 127.0.0.1:6379> HGET myhash field1 \"foo\" redis 127.0.0.1:6379> HSETNX nosql key-value-store redis (integer) 1 redis 127.0.0.1:6379> HSETNX nosql key-value-store redis # 操作无效，field 已存在 (integer) 0 Hmset Hmset 命令用于同时将多个 field - value 设置到某个哈希表中，至于具体是哪个哈希表则取决于参数 key 。 如果 field - value 在 HashTable 中已存在，此命令会覆盖其旧值。 如果 HashTable 不存在，会创建一个空HashTable，再执行 Hmset 操作。 语法 Hmset key field1 value1 [ field2 value2 ... ] 返回值 如果命令执行成功，返回 OK 。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" field2 \"bar\" OK redis 127.0.0.1:6379> HGET myhash field1 \"foo\" redis 127.0.0.1:6379> HMGET myhash field2 \"bar\" Hdel Hdel 命令用于从某个 HashTable 中删除一个或多个 filed - value，具体从哪个HashTable中删除，取决于参数 key，具体删除那一个/些个 filed - value 取决于参数 filed1 ...。 不存在的 filed - value 将被忽略。 语法 Hdel key field1 [ field2 ... ] 返回值 被成功删除 field - value 的数量，不包括被忽略的 filed - value 。 实例： redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HDEL myhash field1 (integer) 1 redis 127.0.0.1:6379> HDEL myhash field2 (integer) 0 Hexists Hexists 命令用于查看某个HashTable中是否存在某个 filed - values 。 语法 Hexists key field 返回值 如果哈希表含有给定 field - value，返回 1 。 如果哈希表不含有给定 field - value，返回 0 。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HEXISTS myhash field1 (integer) 1 redis 127.0.0.1:6379> HEXISTS myhash field2 (integer) 0 Hget Hget 命令用于返回某个哈希表中某个 field - value 的值。 语法 Hget key field 返回值 返回给定 filed - value 的值。如果给定的 HashTable 或 field - value 不存在，则返回 nil 。 实例 字段存在 redis> HSET site redis redis.com (integer) 1 redis> HGET site redis \"redis.com\" 字段不存在 redis> HGET site mysql (nil) Hgetall Hgetall 命令用于返回某个哈希表中，所有的 field - value 。 在返回值里，紧跟每个 field 之后是 value，所以返回值的长度是哈希表大小的两倍。 语法 Hgetall key 返回值 以列表形式返回哈希表的 field - value。 若 HashTable 不存在，返回空列表。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HSET myhash field2 \"bar\" (integer) 1 redis 127.0.0.1:6379> HGETALL myhash 1) \"field1\" 2) \"Hello\" 3) \"field2\" 4) \"World\" Hkeys Hkeys 命令用于获取某个哈希表中的所有字段名。 语法 Hkeys key 返回值 包含哈希表中所有 field 的列表。 当 HashTable 不存在时，返回一个空列表。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HSET myhash field2 \"bar\" (integer) 1 redis 127.0.0.1:6379> HKEYS myhash 1) \"field1\" 2) \"field2\" Hlen 命令 Hlen 命令用于获取哈希表中 field 的数量，也就是 HashTable 的容量。 语法 Hlen key 返回值 哈希表中 field 的数量。 当 HashTable 不存在时，返回 0 。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HSET myhash field2 \"bar\" (integer) 1 redis 127.0.0.1:6379> HLEN myhash (integer) 2 Hmget Hmget 命令用于返回HashTable中，一个或多个给定 field - value 值。 如果指定的 field - value 不存在，那么返回一个 nil 值。 语法 Hmget key field [ field ... ] 返回值 一个包含多个给定 field 关联值的表，表值的排列顺序和指定字段的请求顺序一样。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HSET myhash field2 \"bar\" (integer) 1 redis 127.0.0.1:6379> HMGET myhash field1 field2 nofield 1) \"foo\" 2) \"bar\" 3) (nil) Hvals 命令 作用 Hvals 命令返回某个 HashTable 所有 field - value 的值。 语法 Hvals key 返回值 一个包含 HashTable 中所有值的表。 当 HashTable 不存在时，返回一个空表。 实例 redis 127.0.0.1:6379> HSET myhash field1 \"foo\" (integer) 1 redis 127.0.0.1:6379> HSET myhash field2 \"bar\" (integer) 1 redis 127.0.0.1:6379> HVALS myhash 1) \"foo\" 2) \"bar\" 空哈希表/不存在的key redis 127.0.0.1:6379> EXISTS not_exists (integer) 0 redis 127.0.0.1:6379> HVALS not_exists (empty list or set) Hincrby Hincrby 命令用于为某个 HashTable 中的某个 field - value 加上指定增量值。 增量也可以为负数，相当于对指定 field - value 进行减法操作。 如果哈希表不存在，一个新的哈希表被创建并执行 Hincrby 命令。 如果指定的 filed - value 不存在，那么在执行命令前，filed - vaue 被初始化为 0 。 对一个非数字型字符串的执行 Hincrby 命令将造成一个错误。 语法 Hincrby key field number 返回值 执行 Hincrby 命令之后，哈希表中 filed-value 的新值。 实例 redis 127.0.0.1:6379> HSET myhash field1 20 (integer) 1 redis 127.0.0.1:6379> HINCRBY myhash field 1 (integer) 21 redis 127.0.0.1:6379> HINCRBY myhash field -1 (integer) 20 Hincrbyfloat 作用 Hincrbyfloat 命令用于为某个 HashTable 中的某个 field - value 加上指定浮点数增量值。 如果指定的 filed - value 不存在，那么在执行命令前，字段的值被初始化为 0 。 语法 Hincrbyfloat key field number 返回值 执行 Hincrbyfloat 命令之后，哈希表中 filed - value 的新值。 实例 redis 127.0.0.1:6379> HSET myhash field 20.50 (integer) 1 redis 127.0.0.1:6379> HINCRBYFLOAT mykey field 0.1 Hexists\"20.60\" "},"Part-II/middleware/nosql/redis/05-链表命令.html":{"url":"Part-II/middleware/nosql/redis/05-链表命令.html","title":"Redis 链表命令","keywords":"","body":"链表命令 Lpush 命令 增 删 改 查 lpush lpop lset lrange linsert rpop lindex lrem llen ltrim 作用 Lpush 命令将一个或多个值插入到某个列表头部（左侧），具体是哪个链表由参数 key 决定。 如果链表不存在，一个空列表会被创建，而后再执行 Lpush 操作。 当 key 对应的类型不是列表类型时，返回一个错误。 注意：在 Redis 2.4 版本以前的 Lpush 命令，都只接受单个 value 值。 语法 Lpush key value [ value ... ] 返回值 执行 Lpush 命令后，列表的长度。 实例 redis 127.0.0.1:6379> LPUSH 9527 10 (integer) 1 redis 127.0.0.1:6379> LPUSH 9527 20 (integer) 2 redis 127.0.0.1:6379> LRANGE 9527 0 -1 1) \"10\" 2) \"20\" Rpush 命令 作用 Rpush 命令用于将一个或多个值插入到某个列表的尾部(最右边)，具体是哪个列表由参数 key 决定。 如果列表不存在，一个空列表会被创建，然后再执行 Rpush 操作。 当 key 对应的类型不是列表类型时，返回一个错误。 注意：在 Redis 2.4 版本以前的 RPUSH 命令，都只接受单个 value 值。 语法 Rpush key value [value ... ] 返回值 执行 Rpush 操作后，列表的长度。 实例 redis 127.0.0.1:6379> RPUSH 9528 \"hello\" (integer) 1 redis 127.0.0.1:6379> RPUSH 9528 \"world\" (integer) 2 redis 127.0.0.1:6379> RPUSH 9528 \"goodbye\" (integer) 3 redis 127.0.0.1:6379> LRANGE 9528 0 -1 1) \"hello\" 2) \"world\" 3) \"goodbye\" Lindex 命令 作用 Lindex 命令用于通过索引获取某个列表中的元素，具体是哪个列表由参数 key 决定。 索引都是从头向尾（从左到右）的方向算，从 0 开始。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 语法 Lindex key index 返回值 列表中下标所指定的位置的值。 如果指定索引值不在列表的区间范围内，返回 nil 。 实例 redis 127.0.0.1:6379> LPUSH list_1 \"World\" (integer) 1 redis 127.0.0.1:6379> LPUSH list_1 \"Hello\" (integer) 2 redis 127.0.0.1:6379> LINDEX list_1 0 \"Hello\" redis 127.0.0.1:6379> LINDEX list_1 -1 \"World\" redis 127.0.0.1:6379> LINDEX list_1 3 # index不在 mylist 的区间范围内 (nil) Llen 命令 作用 Llen 命令用于返回某个列表的长度。 如果列表不存在，则返回 0 。 如果 key 对应的不是列表类型，则返回一个错误。 语法 Llen key 返回值 列表的长度。 实例 redis 127.0.0.1:6379> RPUSH list1 \"foo\" (integer) 1 redis 127.0.0.1:6379> RPUSH list1 \"bar\" (integer) 2 redis 127.0.0.1:6379> LLEN list1 (integer) 2 Lpop 命令 作用 Lpop 命令用于移除，并返回某个列表的第一个元素（最左侧的元素）。 语法 Lpop key 返回值 列表的第一个元素。 当列表不存在时，返回 nil 。 实例 redis 127.0.0.1:6379> RPUSH list1 \"foo\" (integer) 1 redis 127.0.0.1:6379> RPUSH list1 \"bar\" (integer) 2 redis 127.0.0.1:6379> LPOP list1 \"foo\" Rpop 命令 作用 Rpop 命令用于移除，并返回某个列表的最后一个元素（最右侧的元素）。 语法 RPOP key 返回值 列表的最后一个元素。 当列表不存在时，返回 nil 。 实例 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 1 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 2 redis 127.0.0.1:6379> RPUSH mylist \"foo\" (integer) 3 redis 127.0.0.1:6379> RPUSH mylist \"bar\" (integer) 4 redis 127.0.0.1:6379> RPOP mylist OK redis 127.0.0.1:6379> LRANGE mylist 0 -1 1) \"hello\" 2) \"hello\" 3) \"foo\" Linsert 命令 作用 Linsert 命令用于在某个列表的元素（锚点元素）前或者后插入元素。 当列表不存在时，被视为空列表，不执行任何操作。 如果 key 对应的不是列表类型，返回一个错误。 当指定的锚点元素不存在于列表中时，不执行任何操作。 语法 Linsert key before | after pivot value 返回值 如果命令执行成功，返回插入操作完成之后，列表的长度。 如果没有找到指定元素 ，返回 -1 。 如果类表不存在或为空列表，返回 0 。 实例 redis 127.0.0.1:6379> RPUSH list1 \"foo\" (integer) 1 redis 127.0.0.1:6379> RPUSH list1 \"bar\" (integer) 2 redis 127.0.0.1:6379> LINSERT list1 BEFORE \"bar\" \"Yes\" (integer) 3 redis 127.0.0.1:6379> LRANGE mylist 0 -1 1) \"foo\" 2) \"Yes\" 3) \"bar\" Lpushx 命令 作用 Lpushx 将一个或多个值插入到已存在的某个列表头部（最左侧），列表不存在时操作无效。 与 Lpush 不同的是，在 Lpushx ”预期列表存在，如果不存在不会新建列表，而 Lpush 会新建列表。 语法 Lpushx key value [ value ... ] 返回值 Lpushx 命令执行之后，列表的长度。 实例 redis 127.0.0.1:6379> LPUSH list1 \"foo\" (integer) 1 redis 127.0.0.1:6379> LPUSHX list1 \"bar\" (integer) 2 redis 127.0.0.1:6379> LPUSHX list2 \"bar\" (integer) 0 redis 127.0.0.1:6379> LRANGE list1 0 -1 1) \"foo\" 2) \"bar\" Rpushx 命令 作用 Rpushx 命令用于将一个或多个值插入到某个已存在的列表尾部(最右边)。 如果列表不存在，则操作无效，并不会新建列表。 语法 Rpushx key value [ value ... ] 返回值 执行 Rpushx 操作后，列表的长度。 实例 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 1 redis 127.0.0.1:6379> RPUSH mylist \"foo\" (integer) 2 redis 127.0.0.1:6379> RPUSHX mylist2 \"bar\" (integer) 0 redis 127.0.0.1:6379> LRANGE mylist 0 -1 1) \"hello\" 2) \"foo\" Lrange 命令 作用 Lrange 返回某个列表中指定区间内的元素，区间以参数 start 和 end 指定。其中 0 表示列表的第一个元素， 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 语法 Lrange key start end 返回值 一个列表，包含指定区间内的元素。 实例 redis 127.0.0.1:6379> LPUSH list1 \"foo\" (integer) 1 redis 127.0.0.1:6379> LPUSH list1 \"bar\" (integer) 2 redis 127.0.0.1:6379> LPUSHX list1 \"bar\" (integer) 0 redis 127.0.0.1:6379> LRANGE list1 0 -1 1) \"foo\" 2) \"bar\" 3) \"bar\" Lrem 命令 作用 Lrem 根据参数 count 的值，移除某个列表中与参数 value 相等的元素。 count 的值可以是以下几种： count > 0 : 从表头开始向表尾搜索，移除与 VALUE 相等的元素，数量为 count 。 count count 的绝对值。 count = 0 : 移除表中所有与 VALUE 相等的值。 语法 Lrem key count value 返回值 被移除元素的数量。 列表不存在时返回 0 。 实例 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 1 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 2 redis 127.0.0.1:6379> RPUSH mylist \"foo\" (integer) 3 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 4 redis 127.0.0.1:6379> LREM mylist -2 \"hello\" (integer) 2 Lset 命令 作用 Lset 通过索引参数 index 来设置某个列表上的元素的值。 当索引参数超出范围，或对一个空列表进行 LSET 时，返回一个错误。 语法 Lset key index value 返回值 操作成功返回 ok ，否则返回错误信息。 实例 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 1 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 2 redis 127.0.0.1:6379> RPUSH mylist \"foo\" (integer) 3 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 4 redis 127.0.0.1:6379> LSET mylist 0 \"bar\" OK redis 127.0.0.1:6379> LRANGE mylist 0 -1 1: \"bar\" 2) \"hello\" 3) \"foo\" 4) \"hello\" Ltrim 命令 作用 Ltrim 对一个列表进行裁剪（trim），就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 下标 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。start 和 stop 包含在区间范围内。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 语法 Ltrim key start stop 返回值 命令执行成功时，返回 ok 。 实例 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 1 redis 127.0.0.1:6379> RPUSH mylist \"hello\" (integer) 2 redis 127.0.0.1:6379> RPUSH mylist \"foo\" (integer) 3 redis 127.0.0.1:6379> RPUSH mylist \"bar\" (integer) 4 redis 127.0.0.1:6379> LTRIM mylist 1 -1 OK redis 127.0.0.1:6379> LRANGE mylist 0 -1 1) \"hello\" 2) \"foo\" 3) \"bar\" "},"Part-II/middleware/nosql/redis/06-集合命令.html":{"url":"Part-II/middleware/nosql/redis/06-集合命令.html","title":"Redis 集合命令","keywords":"","body":"集合命令 特点： 无序 无重复 集合间操作 集合内 API sadd srem scard sismember srandmember smembers spop 集合间 API sdiff sinter sunion Sadd 命令 作用 Sadd 命令将一个或多个成员元素加入到某个集合中，已经存在于集合的成员元素将被忽略。 假如集合不存在，则创建一个新的集合，而后再执行 Sadd 操作。 当 key 对应的并非集合类型时，返回一个错误。 注意：在 Redis 2.4 版本以前， SADD 只接受单个成员值。 语法 Sadd key value [ value ... ] 返回值 被添加到集合中的新元素的数量，不包括被忽略的元素。 实例 redis 127.0.0.1:6379> SADD myset \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset \"foo\" (integer) 1 redis 127.0.0.1:6379> SADD myset \"hello\" (integer) 0 redis 127.0.0.1:6379> SMEMBERS myset 1) \"hello\" 2) \"foo\" Scard 命令 作用 Scard 命令返回某个集合中元素的数量。 语法 SCARD key 返回值 集合中元素数量。 当集合 key 不存在时，返回 0 。 实例 redis 127.0.0.1:6379> SADD myset \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset \"foo\" (integer) 1 redis 127.0.0.1:6379> SADD myset \"hello\" (integer) 0 redis 127.0.0.1:6379> SCARD myset (integer) 2 Sismember 命令 作用 Sismember 命令判断成员元素是否是某个集合的成员。 语法 Sismember key value 返回值 如果成员元素是集合的成员，返回 1 。 如果成员元素不是集合的成员，或集合不存在，返回 0 。 实例 redis 127.0.0.1:6379> SADD myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SISMEMBER myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SISMEMBER myset1 \"world\" (integer) 0 Smembers 命令 作用 Smembers 命令返回某个集合中的所有的成员。 如果集合不存在，则视其为一个空集合。 语法 Smembers key 返回值 集合中的所有成员。 实例 redis 127.0.0.1:6379> SADD myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"world\" (integer) 1 redis 127.0.0.1:6379> SMEMBERS myset1 1) \"World\" 2) \"Hello\" Srandmember 命令 作用 Srandmember 命令用于从某个集合中返回一个或多个随机元素。 从 Redis 2.6 版本开始， Srandmember 命令接受可选的 count 参数： 如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count 大于等于集合基数，那么返回整个集合。 如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。 返回的元素并不会从集合中移除。 语法 Srandmember key [ count ] 返回值 如果没有 count 参数，返回一个元素； 如果提供了 count 参数，那么返回一个数组；如果集合为空，返回空数组。 如果集合为空，返回 nil 。 实例 redis 127.0.0.1:6379> SADD myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"world\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SRANDMEMBER myset1 \"bar\" redis 127.0.0.1:6379> SRANDMEMBER myset1 2 1) \"Hello\" 2) \"world\" Smove 命令 作用 Smove 命令将指定成员 member 元素从 source 集合移动到 destination 集合。 SMOVE 是原子性操作。 如果 source 集合不存在或不包含指定的 member 元素，则 SMOVE 命令不执行任何操作，仅返回 0 。 否则， member 元素从 source 集合中被移除，并添加到 destination 集合中去。 当 destination 集合已经包含 member 元素时， SMOVE 命令只是简单地将 source 集合中的 member 元素删除。 当 source 或 destination 不是集合类型时，返回一个错误。 语法 SMOVE source destination member 返回值 如果成员元素被成功移除，返回 1 。 如果成员元素不是 source 集合的成员，并且没有任何操作对 destination 集合执行，那么返回 0 。 实例 redis 127.0.0.1:6379> SADD myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"world\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SADD myset2 \"foo\" (integer) 1 redis 127.0.0.1:6379> SMOVE myset1 myset2 \"bar\" (integer) 1 redis 127.0.0.1:6379> SMEMBERS myset1 1) \"World\" 2) \"Hello\" redis 127.0.0.1:6379> SMEMBERS myset2 1) \"foo\" 2) \"bar\" Spop 命令 作用 Spop 命令用于 随机 移除，并返回集合中的一个元素。 语法 Spop key 返回值 被移除的随机元素。 当集合不存在或是空集时，返回 nil 。 实例 redis 127.0.0.1:6379> SADD myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"world\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SPOP myset1 \"bar\" redis 127.0.0.1:6379> SMEMBERS myset1 1) \"Hello\" 2) \"world\" Srem 命令 作用 Srem 命令用于移除集合中的一个或多个成员元素，不存在的成员元素会被忽略。 当 key 对应的不是集合类型时，返回一个错误。 在 Redis 2.4 版本以前， SREM 只接受单个成员值。 语法 Srem key member [ member ... ] 返回值 被成功（实际）移除的元素的数量，不包括被忽略的元素。 实例 redis 127.0.0.1:6379> SADD myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"world\" (integer) 1 redis 127.0.0.1:6379> SADD myset1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SREM myset1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SREM myset1 \"foo\" (integer) 0 redis 127.0.0.1:6379> SMEMBERS myset1 1) \"bar\" 2) \"world\" Sdiff 命令 作用 Sdiff 命令返回给定的多个集合之间的差集。对于不存在的集合将视为空集。 语法 Sdiff first_key other_key1 .... other_keyN 返回值 包含差集成员的列表。 实例 redis 127.0.0.1:6379> SADD set1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"foo\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"world\" (integer) 1 # “看” 集合1中的3项数据，有哪几项不在集合2中 redis 127.0.0.1:6379> SDIFF myset myset2 1) \"foo\" 2) \"bar\" Sdiffstore 命令 作用 Sinterstore 命令求给定的多个集合之间的差集，并将结果存储在指定的集合中。 如果目标集合已经存在，则将其覆盖。 语法 Sdiffstore destination_key key1 ... keyN 返回值 结果集中的元素数量。 实例 redis 127.0.0.1:6379> SADD set1 \"aaa\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"bbb\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"ccc\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"aaa\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"ddd\" (integer) 1 # “看” 集合1中的3项数据，有哪几项不在集合2中。并将不在其中的这些项存在集合3中 redis 127.0.0.1:6379> SDIFFSTORE set3 set1 set2 (integer) 2 redis 127.0.0.1:6379> SMEMBERS set3 1) \"bbb\" 2) \"ccc\" Sinter 命令 作用 Sinter 命令返回给定的多个集合之间的交集。对于不存在的集合将视为空集。 语法 Sinter first_key other_key1 .... other_keyN 返回值 包含交集成员的列表。 实例 redis 127.0.0.1:6379> SADD set1 \"aaa\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"bbb\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"ccc\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"aaa\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"ddd\" (integer) 1 # “看”集合1中的3项数据，有哪几项在集合2中 redis 127.0.0.1:6379> SINTER set1 set2 1) \"aaa\" Sinterstore 命令 作用 Sinterstore 命令求给定集合之间的交集，并将结果存储在指定的集合中。 如果指定的集合已经存在，则将其覆盖。 语法 Sinterstore destination_key key key1 ... keyn 返回值 交集成员的列表。 实例 redis 127.0.0.1:6379> SADD set1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"foo\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"world\" (integer) 1 # “看”集合1中的3项数据，有哪几项在集合2中，并将这些数据存在集合3中 redis 127.0.0.1:6379> SINTERSTORE set3 set1 set2 (integer) 1 redis 127.0.0.1:6379> SMEMBERS set 1) \"hello\" Sunion 命令 作用 Sunion 命令返回给定集合的并集。不存在的集合被视为空集。 语法 Sunion key key1 ... keyN 返回值 并集成员的列表。 实例 redis 127.0.0.1:6379> SADD set1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"world\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"bar\" (integer) 1 redis 127.0.0.1:6379> SUNION set1 set2 1) \"bar\" 2) \"world\" 3) \"hello\" 4) \"foo\" Sunionstore 命令 作用 Sunionstore 命令求给定集合的并集，并将结果存储在指定的集合 destination 中。 语法 Sunionstore destination key key1 ... keyN 返回值 结果集中的元素数量。 实例 redis 127.0.0.1:6379> SADD set1 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"world\" (integer) 1 redis 127.0.0.1:6379> SADD set1 \"bar\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"hello\" (integer) 1 redis 127.0.0.1:6379> SADD set2 \"bar\" (integer) 1 redis 127.0.0.1:6379> SUNIONSTORE set3 set1 set2 (integer) 1 redis 127.0.0.1:6379> SMEMBERS set3 1) \"bar\" 2) \"world\" 3) \"hello\" 4) \"foo\" "},"Part-II/middleware/nosql/redis/07-有序集合命令.html":{"url":"Part-II/middleware/nosql/redis/07-有序集合命令.html","title":"Redis 有序集合命令","keywords":"","body":"有序集合命令 和 哈希 有点类似，有序集合中的键值对的值中，也是有两个部分：score 和 value 。 score 的值决定了与之对应的 value 的顺序 zadd zrem zscore zincrby zcard zrange zrangebyscore zcount zremrangebyrank zremrangebyscore Zadd 命令 作用 Zadd 命令用于将一个或多个成员元素及其分数值加入到某个有序集当中。 如果某个成员已经是有序集的成员，那么更新这个成员的分数值。（有序集合内部会重新调整成员元素的位置，来保证这个集合的有序性）。 分数值可以是整数值或双精度浮点数。 如果有序集合不存在，则创建一个空的有序集并执行 Zadd 操作。 当 key 所对应的并非有序集类型时，返回一个错误。 注意： 在 Redis 2.4 版本以前， Zadd 每次只能添加一个元素。 语法 Zadd key score value [scoren value ... ] 返回值 被成功添加的新成员的数量，不包括那些被更新的、已经存在的成员。 实例 redis 127.0.0.1:6379> ZADD set1 1 \"hello\" (integer) 1 redis 127.0.0.1:6379> ZADD set1 1 \"foo\" (integer) 1 redis 127.0.0.1:6379> ZADD set1 2 \"world\" 3 \"bar\" (integer) 2 redis 127.0.0.1:6379> ZRANGE set1 0 -1 WITHSCORES 1) \"hello\" 2) \"1\" 3) \"foo\" 4) \"1\" 5) \"world\" 6) \"2\" 7) \"bar\" 8) \"3\" Zcard 命令 作用 Zcard 命令用于计算某个集合中元素的数量。 语法 Zcard key 返回值 当集合存在时，返回有序集的基数。 当集合不存在时，返回 0 。 实例 redis 127.0.0.1:6379> ZADD myset 1 \"hello\" (integer) 1 redis 127.0.0.1:6379> ZADD myset 1 \"foo\" (integer) 1 redis 127.0.0.1:6379> ZADD myset 2 \"world\" 3 \"bar\" (integer) 2 redis 127.0.0.1:6379> ZCARD myzset (integer) 4 Zcount 命令 作用 Zcount 命令用于计算某有序集合中指定分数区间的成员数量。 语法 Zcount key min max 返回值 分数值在 min 和 max 之间的成员的数量。 实例 redis 127.0.0.1:6379> ZADD myzset 1 \"hello\" (integer) 1 redis 127.0.0.1:6379> ZADD myzset 1 \"foo\" (integer) 1 redis 127.0.0.1:6379> ZADD myzset 2 \"world\" 3 \"bar\" (integer) 2 redis 127.0.0.1:6379> ZCOUNT myzset 1 3 (integer) 4 Zincrby 命令 作用 Zincrby 命令对某有序集合中指定成员的分数加上增量 increment 可以通过传递一个负数值 increment ，让分数减去相应的值，比如 ZINCRBY key -5 member ，就是让 member 的 score 值减去 5 。 当有序集合不存在，或有序集合中不存在指定分数时， Zincrby 等同于 Zadd 。 当 key 对应的不是有序集时，返回一个错误。 分数值可以是整数值或双精度浮点数。 语法 Zincrby key increment member 返回值 member 成员的新分数值，以字符串形式表示。 实例 redis 127.0.0.1:6379> ZADD myzset 1 \"hello\" (integer) 1 redis 127.0.0.1:6379> ZADD myzset 1 \"foo\" (integer) 1 redis 127.0.0.1:6379> ZINCRBY myzset 2 \"hello\" (integer) 3 redis 127.0.0.1:6379> ZRANGE myzset 0 -1 WITHSCORES 1) \"foo\" 2) \"2\" 3) \"hello\" 4) \"3\" Zrem 命令 作用 Zrem 命令用于移除某个有序集中的一个或多个成员，不存在的成员将被忽略。 如果 key 对应的并非是有序集类型，则返回一个错误。 注意： 在 Redis 2.4 版本以前， ZREM 每次只能删除一个元素。 语法 Zrem key member 实例 测试数据 redis 127.0.0.1:6379> ZRANGE page_rank 0 -1 WITHSCORES 1) \"bing.com\" 2) \"8\" 3) \"baidu.com\" 4) \"9\" 5) \"google.com\" 6) \"10\" 移除单个元素 redis 127.0.0.1:6379> ZREM page_rank google.com (integer) 1 redis 127.0.0.1:6379> ZRANGE page_rank 0 -1 WITHSCORES 1) \"bing.com\" 2) \"8\" 3) \"baidu.com\" 4) \"9\" 移除多个元素 redis 127.0.0.1:6379> ZREM page_rank baidu.com bing.com (integer) 2 redis 127.0.0.1:6379> ZRANGE page_rank 0 -1 WITHSCORES (empty list or set) 移除不存在元素 redis 127.0.0.1:6379> ZREM page_rank non-exists-element (integer) 0 Zremrangebylex 命令 作用 Zremrangebylex 命令用于移除某个有序集合中给定的字典区间的所有成员。 语法 Zremrangebylex key min max 返回值 被成功（实际）移除的成员的数量，不包括被忽略的成员。 实例 redis 127.0.0.1:6379> ZADD myzset 0 aaaa 0 b 0 c 0 d 0 e (integer) 5 redis 127.0.0.1:6379> ZADD myzset 0 foo 0 zap 0 zip 0 ALPHA 0 alpha (integer) 5 redis 127.0.0.1:6379> ZRANGE myzset 0 -1 1) \"ALPHA\" 2) \"aaaa\" 3) \"alpha\" 4) \"b\" 5) \"c\" 6) \"d\" 7) \"e\" 8) \"foo\" 9) \"zap\" 10) \"zip\" redis 127.0.0.1:6379> ZREMRANGEBYLEX myzset [alpha [omega (integer) 6 redis 127.0.0.1:6379> ZRANGE myzset 0 -1 1) \"ALPHA\" 2) \"aaaa\" 3) \"zap\" 4) \"zip\" Zremrangebyrank 命令 作用 Zremrangebyrank 命令用于移除某个有序集中，指定排名(rank)区间内的所有成员。 语法 Zremrangebyrank key start stop 返回值 被移除成员的数量。 实例 redis 127.0.0.1:6379> ZADD salary 2000 jack (integer) 1 redis 127.0.0.1:6379> ZADD salary 5000 tom (integer) 1 redis 127.0.0.1:6379> ZADD salary 3500 peter (integer) 1 redis 127.0.0.1:6379> ZREMRANGEBYRANK salary 0 1 # 移除下标 0 至 1 区间内的成员 (integer) 2 redis 127.0.0.1:6379> ZRANGE salary 0 -1 WITHSCORES # 有序集只剩下一个成员 1) \"tom\" 2) \"5000\" Zremrangebyscor 命令 作用 ZremrangebyscorZrangebylex e 命令用于移除某个有序集中，指定分数（score）区间内的所有成员。 语法 Zremrangebyscore key min max 返回值 被移除成员的数量。 实例 redis 127.0.0.1:6379> ZRANGE salary 0 -1 WITHSCORES # 显示有序集内所有成员及其 score 值 1) \"tom\" 2) \"2000\" 3) \"peter\" 4) \"3500\" 5) \"jack\" 6) \"5000\" redis 127.0.0.1:6379> ZREMRANGEBYSCORE salary 1500 3500 # 移除所有薪水在 1500 到 3500 内的员工 (integer) 2 redis> ZRANGE salary 0 -1 WITHSCORES # 剩下的有序集成员 1) \"jack\" 2) \"5000\" Zrange 命令 作用 Zrange 返回某有序集中，指定区间内的成员。 如果需要逆序显示，请使用 Zrevrange 命令。 语法 Zrange key start stop [ WITHSCORES ] 返回值 指定区间内，带有分数值(可选)的有序集成员的列表。 实例 显示整个有序集成员 redis 127.0.0.1:6379> ZRANGE salary 0 -1 WITHSCORES 1) \"jack\" 2) \"3500\" 3) \"tom\" 4) \"5000\" 5) \"boss\" 6) \"10086\" 显示有序集下标区间 1 至 2 的成员 redis 127.0.0.1:6379> ZRANGE salary 1 2 WITHSCORES 1) \"tom\" 2) \"5000\" 3) \"boss\" 4) \"10086\" 测试 end 下标超出最大下标时的情况 redis 127.0.0.1:6379> ZRANGE salary 0 200000 WITHSCORES 1) \"jack\" 2) \"3500\" 3) \"tom\" 4) \"5000\" 5) \"boss\" 6) \"10086\" 测试当给定区间不存在于有序集时的情况 redis > ZRANGE salary 200000 3000000 WITHSCORES (empty list or set) Zrangebylex 命令 作用 Zrangebylex 通过字典区间返回某个有序集合的成员。 语法 Zrangebylex key min max [LIMIT offset count] 返回值 指定区间内的元素列表。 实例 redis 127.0.0.1:6379> ZADD myzset 0 a 0 b 0 c 0 d 0 e 0 f 0 g (integer) 7 redis 127.0.0.1:6379> ZRANGEBYLEX myzset - [c 1) \"a\" 2) \"b\" 3) \"c\" redis 127.0.0.1:6379> ZRANGEBYLEX myzset - (c 1) \"a\" 2) \"b\" redis 127.0.0.1:6379> ZRANGEBYLEX myzset [aaa (g 1) \"b\" 2) \"c\" 3) \"d\" 4) \"e\" 5) \"f\" Zrangebyscore 命令 作用 Zrangebyscore 返回某有序集合中指定分数区间的成员列表。有序集成员按分数值递增(从小到大)次序排列。 具有相同分数值的成员按字典序来排列(该属性是有序集提供的，不需要额外的计算)。 默认情况下，区间的取值使用闭区间 (小于等于或大于等于)，你也可以通过给参数前增加 ( 符号来使用可选的开区间 (小于或大于)。 语法 Zrangebyscore key min max [ WITHSCORES ] [ LIMIT offset count ] 返回值 指定区间内，带有分数值(可选)的有序集成员的列表。 实例 测试数据 redis 127.0.0.1:6379> ZADD salary 2500 jack (integer) 0 redis 127.0.0.1:6379> ZADD salary 5000 tom (integer) 0 redis 127.0.0.1:6379> ZADD salary 12000 peter (integer) 0 显示整个有序集 redis 127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf 1) \"jack\" 2) \"tom\" 3) \"peter\" 显示整个有序集及成员的 score 值 redis 127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf WITHSCORES 1) \"jack\" 2) \"2500\" 3) \"tom\" 4) \"5000\" 5) \"peter\" 6) \"12000\" 显示工资 redis 127.0.0.1:6379> ZRANGEBYSCORE salary -inf 5000 WITHSCORES 1) \"jack\" 2) \"2500\" 3) \"tom\" 4) \"5000\" 显示工资大于 5000 小于等于 400000 的成员 redis 127.0.0.1:6379> ZRANGEBYSCORE salary (5000 400000 1) \"peter\" Zrank 命令 作用 Zrank 返回有序集中指定成员的排名。其中有序集成员按分数值递增(从小到大)顺序排列。 语法 ZRANK key member 返回值 如果成员是有序集的成员，返回 member 的排名。 如果成员不是有序集的成员，返回 nil 。 实例 显示所有成员及其 score 值 redis 127.0.0.1:6379> ZRANGE salary 0 -1 WITHSCORES 1) \"peter\" 2) \"3500\" 3) \"tom\" 4) \"4000\" 5) \"jack\" 6) \"5000\" 显示 tom 的薪水排名，第二 redis 127.0.0.1:6379> ZRANK salary tom (integer) 1 Zrevrank 命令 作用 Zrevrank 命令返回有序集中成员的排名。其中有序集成员按分数值降序排序。 使用 Zrank 命令可以获得成员按分数值升序排序。 语法 Zrevrank key member 返回值 如果成员是有序集的成员，返回成员的排名。 如果成员不是有序集的成员，返回 nil 。 实例 redis 127.0.0.1:6379> ZRANGE salary 0 -1 WITHSCORES # 测试数据 1) \"jack\" 2) \"2000\" 3) \"peter\" 4) \"3500\" 5) \"tom\" 6) \"5000\" redis 127.0.0.1:6379> ZREVRANK salary peter # peter 的工资排第二 (integer) 1 redis 127.0.0.1:6379> ZREVRANK salary tom # tom 的工资最高 (integer) 0 Zscore 命令 命令 Zscore 命令返回有序集中，成员的分数值。 如果成员元素不是有序集的成员，或有序集合不存在，返回 nil 。 语法 Zscore key member 返回值 成员的分数值，以字符串形式表示。 实例 redis 127.0.0.1:6379> ZRANGE salary 0 -1 WITHSCORES # 测试数据 1) \"tom\" 2) \"2000\" 3) \"peter\" 4) \"3500\" 5) \"jack\" 6) \"5000\" redis 127.0.0.1:6379> ZSCORE salary peter # 注意返回值是字符串 \"3500\" "},"Part-II/middleware/nosql/redis/08-spring-redis.html":{"url":"Part-II/middleware/nosql/redis/08-spring-redis.html","title":"Spring 整合 Redis","keywords":"","body":"Spring 与 Redis 整合 pom 文件 2.1.14.RELEASE 1.8.18.RELEASE 2.9.1 redis.clients jedis ${jedis.version} org.springframework.data spring-data-redis ${spring-data-redis.version} spring-data-redis 2.x 在配置上有大量的变化，有部分 1.x 中的配置属性被标注为过期，此处不深究。 与 spring 整合的配置 redis.host=127.0.0.1 redis.port=6379 redis.pass=123456 redis.maxIdle=200 redis.maxActive=1024 redis.maxWait=10000 redis.testOnBorrow=true --> --> --> 上述配置中被注解的部分内容涉及到一个较高级的问题：spring-data-redis 的序列化策略。这里简单说下： spring-data-redis 默认采用的序列化策略有两种，一种是 String 的序列化策略，一种是 JDK 的序列化策略。 StringRedisTemplate 和 StringRedisSerializer: StringRedisTemplate 默认采用的是 String 的序列化策略，即保存的 key 和 value 都是采用此策略序列化保存的。 Key 或者 value 为字符串的场景，根据指定的 charset 对数据的字节序列编码成 String，是 new String(bytes, charset) 和 string.getBytes(charset) 的直接封装。是最轻量级和高效的策略。 RedisTemplate 和 JdkSerializationRedisSerializer: RedisTemplate 默认采用的是 JDK 的序列化策略，保存的 key 和 value 都是采用此策略序列化保存的。 POJO 对象的存取场景，使用 JDK 本身序列化机制，将 pojo 类通过 ObjectInputStream / ObjectOutputStream 进行序列化操作，最终redis-server 中将存储字节序列。是目前最常用的序列化策略。 RedisTemplate 和 StringRedisTemplate 不可混用 就是因为 默认的 序列化策略的不同，即使是同一个 key 用不同的 Template 去序列化，结果是不同的。所以根据 key 去删除数据的时候就出现了删除失败的问题。 存 取/删 成功与否 StringRedisTemplate StringRedisTemplate 成功 RedisTemplate RedisTemplate 成功 StringRedisTemplate RedisTemplate 失败 RedisTemplate SpringRedisTemplate 失败 除非，你为两者指定相同的序列化器，即指定同样一种序列化策略。 代码验证 public static void main(String[] args) { ClassPathXmlApplicationContext container = new ClassPathXmlApplicationContext(\"spring-redis.xml\"); @SuppressWarnings(\"unchecked\") RedisTemplate template = container.getBean(RedisTemplate.class); ValueOperations ops1 = template.opsForValue(); HashOperations ops2 = template.opsForHash(); System.out.println(ops1.get(\"hello\")); ops1.set(\"hello\", \"world\"); System.out.println(ops1.get(\"hello\")); ops2.put(\"user:1\", \"name\", \"tom\"); ops2.put(\"user:1\", \"age\", 20); ops2.put(\"user:2\", \"name\", \"jerry\"); ops2.put(\"user:2\", \"age\", 19); container.close(); } "},"Part-II/middleware/message-queue/":{"url":"Part-II/middleware/message-queue/","title":"消息队列","keywords":"","body":"消息队列 消息队列功能介绍 分布式消息队列可以提供应用解耦、流量削峰、消息分发等功能，已经成为大型互联网服务架构里标配的中间件。 应用解耦 复杂的应用里会存在多个子系统，如果各个子系统之间的耦合性太高，整体系统的可用性就会大幅降低。多个低错误率的子系统强耦合在一起，得到的是一个高错误率的整体系统。 通过消息队列，可以将强耦合的 A - B 子系统，改造成 A - 消息队列 - B。当 B 子系统发生故障时（需要几分钟时间来修复），A 子系统需要 B 子系统所处理的信息/数据/内容被存储在了消息队列中，当 B 系统恢复后，B 系统可以补充处理消息队列中的相关请求。在整个过程中，A 子系统（或者说，A 系统的用户）感知不到 B 子系统发生过几分钟的故障。 流量削峰 使用消息队列进行流量削峰，很多时候不是因为能力不够，而是处于经济性的考虑。 对于觉得大多数系统，一年之中最忙碌的往往至少某个时间段（例如电商的双 11）。甚至，一天之中，最忙碌的也只是某个时间段（例如美团饿了么）。 假设，一个系统的流量最高峰也不过一万 QPS，而平时只有一千左右。这种情况下，只需要用个普通性能的服务器（支持以前 QPS），然后加个消息队列作为高峰期的缓冲，无须花费大笔资金部署支持上万 QPS 的服务器。 消息分发 在大数据时代，数据对很多公司来说就是金矿，公司需要产生的数据进行多角度多层次的『充分』的利用。简单来说，你不知道现在整个系统中有哪些子系统对你产生的数据『感兴趣』；你更不清楚未来在整个系统中有哪些子系统对你所产生的数据『感兴趣』。 这个时候有个消息队列就非常重要。数据的产生放（你）只需要把数据写入一个消息队列中，其他各方（子系统）根据仔细的需要决定订阅这些数据。 JMS 规范 JMS 即 Java 消息服务（Java Message Service）应用程序接口，是一个 Java 平台中关于面向消息中间件的 API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java 消息服务是一个与具体平台无关的 API，绝大多数消息中间件提供商都对 JMS 提供支持。 ActiveMQ 是 JMS 的最常见的实现。 基本概念 消息传送模型 点对点（Point to Point）模型 使用 队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者所使用，未被消费的消息在消息队列中保留，直到被消费或超时。 发布/订阅（Pub/Sub）模型 使用 主题（Topic）作为消息通信载体，类似于广播模式，发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息被广播之后才订阅的用户是收不到该消息的。 基本组件 JMS 的基本组件有： Broker（消息代理） 表示消息队列服务器实体，接收客户端连接，提供消息通信的核心服务。 Producer（消息生产者） 业务的发起方，负责生产消息并传递给 Broker 。 Consumer（消息消费者） 业务的处理方，负责从 Broker 获取消息并进行业务逻辑处理。 Topic（主题） 在发布/订阅模式下消息的统一汇集地，不同的生产者向 Topic 发送消息，由 Broker 分发给不同的订阅者，实现消息的广播。 Queue（队列） 在点对点模式下特定生产者向特定队列发送消息，消费者订阅特定队列接收消息并进行业务逻辑处理。 Message（消息） 根据不同的通信协议的固定格式进行编码的数据包，封装业务数据，实现消息的传输。 消息存储 在 JMS 规范中对消息的发送方式有两种： 消息存储 说明 持久化 用于看重 可靠性 场景。 不允许消息丢失。 可接受一定的吞吐量损耗。 非持久化 用于看重 性能 场景。 允许一定概率的消息丢失。 补充说明，由于 JMS 规范本身的原因，实现 JMS 规范的消息队列的吞吐量都比较一般（比如 ActiveMQ）。因此，真正对吞吐量有要求有期望有要求的场景下，也轮不到 ActiveMQ 这样 JMS 消息中间件。因此，JMS 的非持久化/非持久化对性能的影响实际上对于 ActiveMQ 技术选型影响不大。 另外，持久化消息是 JMS 2.0 规范中新增的特性，在 JMS 1.1 规范中消息全部都是非持久化消息。 持久化消息发送到消息服务器后，如果当前消息的消费者并没有运行，则该消息继续存在，只有等到消息被处理并被消费者确认之后，消息才会被从消息服务器中删除。 AMQP 规范 AMQP，即 Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。 RabbitMQ 是 AMQP 最常见的实现。 AMQP 在 JMS 的概念的基础上，主要多出来【路由】和【绑定】的概念。 Exchange（交换器，上图中的 X）：用来接收消息生产者发送的消息，并将这些消息路由给服务器中的队列。 Binding（绑定）：用于交换器和消息队列之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则。 出了上述两个【新】概念，AMQP 中还引入了其它的概念，比如： Channel（信道）：多路复用连接中的一条独立的双向数据流通道。信道是建立在真是的 TCP 连接内的虚拟连接。不管是发布消息、订阅队列还是接收消息，这些动作都是通过连接中的某个信道完成的。 Virtual Host（虚拟主机）：一批交换机、队列（及其之间绑定关系）的逻辑『总称』。某个交换机和队列必定属于某个虚拟主机，而 Rabbit MQ 中可以由多个虚拟主机。Rabbit MQ 默认的 vhost 是 / 。 各个消息队列中间件的缺点 ActiveMQ 性能是硬伤。 ActiveMQ 有一种内嵌运行模式看似很有特色，但是有其它的消息队列专注于此：ZeroMQ 。甚至有些 java 库都能实现类似的功能。 RabbitMQ 对消息堆积的支持不友好（它认为消息堆积现象是一种不正常的现象，应该避免发生，而非发生后再靠消息队列来解决）。 性能够应付企业级应用，但不足以应付互联网项目。 Erlang 语言偏小众，不方便二次开发。 RocketMQ 没有显著优点，就是最大的缺点。没有指标垫底，同样也没有指标独占鳌头。样样都老二也是很尴尬。 作为国内开源项目，国外使用较少，因此看起来声势不大。 Kafka 理论上，有消息丢失的可能。（据说，新版本已经解决了该问题） 采用异步+批处理的方式，提升了性能的同时，也带来了消息处理的延迟。 总结 ActiveMQ 基本上不太可能用到。 企业级项目如果仅专注于消息队列本身的功能，则可以使用 RabbitMQ 。毕竟，资料多，够简单，路由灵活。 互联网项目 RocketMQ 和 Kafka 二选一。在意延迟（响应速度）的项目选用 RocketMQ；追求极致吞吐量的选择 Kafka 。 "},"Part-II/middleware/message-queue/activemq/01-简介.html":{"url":"Part-II/middleware/message-queue/activemq/01-简介.html","title":"ActiveMQ 基本概念","keywords":"","body":"ActiveMQ ActiveMQ 是由 Apache 出品的一款开源消息中间件，旨在为应用程序提供高效、可扩展、稳定、安全的企业级消息通信。 因为 ActiveMQ 是完整实现了 JMS 1.1，所以从 Java 使用者的角度来看，其基本概念与 JMS 1.1 规范是一致的。 连接器 ActiveMQ Broker 的主要作用是为客户端应用提供一种通信机制，为此 ActiveMQ 提供了一种连接支持，并用 连接器（Connector）来描述它。 为了交换信息，消息 生产者 和 消费者（统称为客户端）都需要连接到消息代理服务器，这种客户端和消息代理服务器之间的通信就是通过传输连接器完成的。 很多情况下，用户连接消息代理服务器的需求侧重点不同，有的更关注性能，有的更侧重安全性，因此，ActiveMQ 提供了一系列（不同）的连接协议来选择，来覆盖这些使用场景 VM 允许客户端和消息服务器直接在 VM 内部通信，采用的不是 Socket 连接，而是直接的虚拟机本地方法调用，从而避免网络传输开销。 应用场景仅限于服务器和客户端在同一个 JVM 中。 这种情况也就是所谓的 内嵌式 ActiveMQ，并没有启动外部的 ActiveMQ 服务器。本质上还是方法同步调用，但是代码的形式『长得』和发消息一样。 TCP 客户端通过 TCP 连接到远程的消息服务器。 毫无疑问，这种情况下，你需要单独启动 ActiveMQ 消息服务器。 ActiveMQ 还支持一些高级的协议，比如： failover failover 是一种重新连接的机制，工作于上面介绍连接协议的上层，用于建立可靠的传输。 其配置语法允许指定任意多个复合的 URI，它会自动选择其中的一个 URI 来尝试建立连接，如果该连接没有成功，则会继续选择其它的 URI 进行尝试。 其配置语法：failover:(tcp://localhost:61616,tcp://192.168.x.xxx:61616) 消息存储 持久化消息是 JMS 2.0 规范中新增的特性，对于 JMS 2.0 所要求的持久化消息，ActiveMQ 存储它的方式有三种： 存储到内存 将所有要持久化的消息都放到内存中。注意，需要设置消息服务器的 JVM 和内存大小。 存储到文件 AMQ：5.3 以前版本的默认存储方式。 KahaDB：从 5.3 版本开始的默认使用的存储方式。比 AMQ 存储方式具有更好的可靠性和可恢复性。 LevelDB：5.6 版本推出的新的存储方式。其持久化性能要好于 KahaDB。在可预见的未来的某个版本中将会替代 KahaDB 成为默认的使用方式。 存储到数据库 JDBC：基于 JDBC 的方式将消息存储与数据库。（虽然可以结合使用缓存写入技术，但是）很显然，这种方式存储性能最低。 "},"Part-II/middleware/message-queue/activemq/02-java-activemq.html":{"url":"Part-II/middleware/message-queue/activemq/02-java-activemq.html","title":"ActiveMQ 原生 API","keywords":"","body":"Java 访问 ActiveMQ 在 JMS 规范中传递消息的方式有两种： 点对点 模型的 队列 方式； 发布/订阅 模型的 主题 方式。 由于不太可能直接通过 Java 代码访问操作 ActiveMQ，（更多的是通过整合 Spring 后，通过 Spring 操作访问 ActiveMQ），因此以下仅以主题方式传递为例。 启动 ActiveMQ 略 引入依赖 org.apache.activemq activemq-all ${activemq.version} com.fasterxml.jackson.core jackson-databind ${jackson.version} 消息生产者 !FILENAME 消费者/消息订阅者 import org.apache.activemq.*; import javax.jms.*; public class TopicSubscriber { // 默认用户名 private static final String USERNAME = ActiveMQConnection.DEFAULT_USER; // 默认密码 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD; // 默认连接地址。记得要启动ActiveMQ 服务器 private static final String BROKER_URL = ActiveMQConnection.DEFAULT_BROKER_URL; // Topic 的名称 private static final String TOPIC_NAME = \"activemq-topic\"; public static void main(String[] args) throws Exception { // 创建连接工厂 ConnectionFactory factory = new ActiveMQConnectionFactory(USERNAME, PASSWORD, BROKER_URL); // 创建连接 Connection connection = factory.createConnection(); // 开启连接。不要忘记这一步。 connection.start(); // 创建会话，不需要事务，自动确认。事务和消息确认机制后续专项讲解。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 创建主题。 Topic testTopic = session.createTopic(TOPIC_NAME); // 消息消费者1。 MessageConsumer consumer1 = session.createConsumer(testTopic); // 注册消息监听器。即注册接收消息后所执行的代码。 consumer1.setMessageListener(message -> { try { System.out.println(\"消费者1收到消息：\" + ((TextMessage) message).getText()); } catch (JMSException e) { e.printStackTrace(); } }); // 消息消费者2。 MessageConsumer consumer2 = session.createConsumer(testTopic); // 注册消息监听器。即注册接收消息后所执行的代码。 consumer2.setMessageListener(message -> { try { System.out.println(\"消费者2收到消息：\" + ((TextMessage) message).getText()); } catch (JMSException e) { e.printStackTrace(); } }); // 让主线程休眠 30s，使消息消费者对象 Thread.sleep(30 * 1000); // 关闭资源 session.close(); connection.close(); } } !FILENAME 生产者/消息发布者 import org.apache.activemq.*; import javax.jms.*; public class TopicProducer { // 默认用户名 private static final String USERNAME = ActiveMQConnection.DEFAULT_USER; // 默认密码 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD; // 默认连接地址。记得要启动ActiveMQ 服务器 private static final String BROKER_URL = ActiveMQConnection.DEFAULT_BROKER_URL; // Topic 的名称 private static final String TOPIC_NAME = \"activemq-topic\"; public static void main(String[] args) throws Exception { // 创建连接工厂 ConnectionFactory factory = new ActiveMQConnectionFactory(USERNAME, PASSWORD, BROKER_URL); // 创建连接 Connection connection = factory.createConnection(); // 开启连接。不要忘记这一步。 connection.start(); // 创建会话，不需要事务，自动确认。事务和消息确认机制后续专项讲解。 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 创建主题。 Topic testTopic = session.createTopic(TOPIC_NAME); // 消息生产者。 MessageProducer producer = session.createProducer(testTopic); for (int i = 0; i 运行 先运行消费者/订阅者，后运行生产者/发布者。 如果反过来的话，消息先发布出去，但没有任何订阅者在运行，则将看不到消息被消费。 "},"Part-II/middleware/message-queue/activemq/03-spring-activemq.html":{"url":"Part-II/middleware/message-queue/activemq/03-spring-activemq.html","title":"Spring 整合 ActiveMQ","keywords":"","body":" 在实际项目中，如果使用原生的 ActiveMQ API 开发显得十分啰嗦，这中间 创建连接工厂、创建连接 之类的代码完全可以抽出来由框架统一做。 实话实说，Spring 整合 ActiveMQ 的相关配置也比较啰嗦... Spring Boot 整合 ActiveMQ 倒是十分简洁。 启动 ActiveMQ 略。 或者使用 内嵌 ActiveMQ 。只需要修改连接协议，使用 vm 开头即可。 引入依赖 !FILENAME pom.xml org.apache.activemq activemq-all ${activemq.version} com.fasterxml.jackson.core jackson-databind ${jackson.version} org.apache.activemq activemq-pool ${activemq.version} org.springframework spring-jms ${spring.version} 前两个包和 Java 访问 ActiveMQ 中所引入的是一样的，后两个包是 Spring 整合 ActiveMQ 所需要的『多』出来的。 spring-activemq.xml !FILENAME part-1 ... part-1 中配置了 ActiveMQ 的连接工厂，由于连接、会话、消息生产者的创建会消耗大量系统资源，为此这里使用了连接池和缓存来复用这些资源。这也是为什么在 pom 的依赖中会『多出来』一个 activemq-pool 。 !FILENAME part-2 ... ... part-2 中配置了 Spring 整合 ActiveMQ 后，我们在代码中所要使用的核心对象：JmsTemplate 。 在后续的代码中，消息的生产者/发布者就是直接通过 JsmTemplate 发送消息。 !FILENAME part-3 ... ... part-3 是以队列为信息载体的点对点模式下的队列的相关配置。它配置了: 定义了一个消息队列：spring-queue 定义了一个队列的监听者，即消息的消费者。这个类是需要我们编码自定义的。具体代码的相关写法看后续内容。 定义了一个用于 spring-jms 整合的队列容器。这是配置出来给 s pring 整合 jms 的，我们的编码工作不涉及到它。 !FILENAME part-4 ... ... part-4 这部分和 part-3 看起来很类似。很明显，它配置了： 定义了一个主题：spring-topic 定义了两个主题监听者，即，两个消费者/订阅者。毫无疑问，这两个类也是需要我们编码自定义的。 定义了两个主题容器。同样，这是为 spring 整合 jms 用的。与我们自己的编码无关。 定义队列消费者 !FILENAME QueueListener public class QueueListener implements MessageListener { private static final Logger log = LoggerFactory.getLogger(QueueListener.class); @Override public void onMessage(Message message) { if (!(message instanceof TextMessage)) { throw new IllegalArgumentException(\"只支持 Text 消息\"); } TextMessage textMessage = (TextMessage) message; try { String messageStr = textMessage.getText(); log.info(\"QueueListener 收到了消息: {}\", messageStr); } catch (JMSException e) { e.printStackTrace(); } } } 定义主题订阅者 Topic2Listener 和 Topic1Listener 一样。 !FILENAME Topic1Listener public class Topic1Listener implements MessageListener { private static final Logger log = LoggerFactory.getLogger(Topic1Listener.class); @Override public void onMessage(Message message) { if (!(message instanceof TextMessage)) { throw new IllegalArgumentException(\"只支持 Text 消息\"); } TextMessage textMessage = (TextMessage) message; try { String messageStr = textMessage.getText(); log.info(\"Topic1Listener 收到了消息: {}\", messageStr); } catch (JMSException e) { e.printStackTrace(); } } } 消息生产者发送消息 public static void main(String[] args) throws InterruptedException { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"spring-activemq.xml\"); JmsTemplate template = context.getBean(JmsTemplate.class); Queue queue = context.getBean(Queue.class); Topic topic = context.getBean(Topic.class); template.send(topic, session -> session.createTextMessage(\"发给 Topic 的消息\")); template.send(queue, session -> session.createTextMessage(\"发给 Queue 的消息\")); Thread.sleep(3*1000); context.close(); } "},"Part-II/middleware/message-queue/activemq/04-spring-boot-activemq.html":{"url":"Part-II/middleware/message-queue/activemq/04-spring-boot-activemq.html","title":"Spring Boot 整合 ActiveMQ","keywords":"","body":"SpringBoot 中使用 ActiveMQ ActiveMQ 介绍 ActiveMQ 是 Apache 软件基金下的一个开源软件，它遵循 JMS 1.1 规范，为企业消息传递提供高可用、出色性能、可扩展、稳定和安全保障的服务。 ActiveMQ 实现了 JMS 规范，并在此之上提供大量额外的特性。ActiveMQ 支持 队列 和 订阅 两种模式的消息发送方式。 Spring Boot 提供了 ActiveMQ 组件 spring-boot-starter-activemq，用来支持 ActiveMQ 在 Spring Boot 体系内使用。 添加依赖 主要添加组件：spring-boot-starter-activemq 。 org.springframework.boot spring-boot-starter-activemq 配置文件 在 application.properties 中添加配置。 # 基于内存的 ActiveMQ，在开发/调试阶段建议使用这种方式 spring.activemq.in-memory=true # 不使用连接池 spring.activemq.pool.enabled=false # 独立安装的 ActiveMQ，在生产环境推荐使用这种 # spring.activemq.broker-url=tcp://192.168.0.1:61616 # spring.activemq.user=admin # spring.activemq.password=admin 队列(Queue) 队列发送的消息，只能被一个消费者接收。 创建队列 @Configuration public class MqConfig { @Bean public Queue queue() { return new ActiveMQQueue(\"ben.queue\"); } } 使用 @Configuration 注解在项目启动时，定义了一个队列 queue 命名为：ben.queue 。 消息生产者 创建一个消息的生产者: @Component public class Producer { @Autowired private JmsMessagingTemplate jmsMessagingTemplate; @Autowired private Queue queue; public void sendQueue(String msg) { System.out.println(\"send queue msg :\" + msg); jmsMessagingTemplate.convertAndSend(queue, msg); } } JmsMessagingTemplate 是 Spring 提供发送消息的工具类，使用 JmsMessagingTemplate 和创建好的 queue 对消息进行发送。 消息消费者 @Component public class Consumer { @JmsListener(destination = \"ben.queue\") public void receiveQueue(String text) { System.out.println(\"Consumer queue msg : \" + text); } } 使用注解 @JmsListener(destination = \"ben.queue\")，表示此方法监控了名为 ben.queue 的队列。当队列 ben.queue 中有消息发送时会触发此方法的执行，text 为消息内容。 测试 创建 SampleActiveMqTests 测试类，注入入创建好的消息生生产者。 @RunWith(SpringRunner.class) @SpringBootTest public class SampleActiveMqTests { @Autowired private Producer producer; @Rule public OutputCapture outputCapture = new OutputCapture(); } OutputCapture 是 Spring Boot 提供的一个测试类，它能捕获 System.out 和 System.err 的输出，我们可以利用这个特性来判断程序中的输出是否执行。 @Test public void sendSimpleQueueMessage() throws InterruptedException { producer.sendQueue(\"Test queue message\"); Thread.sleep(1000L); assertTrue(outputCapture.toString().contains(\"Test queue\")); } 创建测试方式，使用 producer 发送消息，为了保证容器可以接收到消息，让测试方法等待 1 秒，最后使用 outputCapture 判断是否执行成功。 测试多消费者 上面的案例只是一个生产者一个消费者，我们在模拟一个生产者和多个消费者队列的执行情况。我们复制上面的消费者 Consumer 重新命名为 Consumer2，并且将输出内容加上 2 的关键字，如下: @Component public class Consumer2 { @JmsListener(destination = \"ben.queue\") public void receiveQueue(String text) { System.out.println(\"Consumer2 queue msg : \"+text); } } 在刚才的测试类中添加一个 send100QueueMessage() 方法，模式发送 100 条消息时，两个消费者是如何消费消息的。 @Test public void send100QueueMessage() throws InterruptedException { for (int i = 0; i 控制台输出结果: Consumer queue msg : Test queue message0 Consumer2 queue msg : Test queue message1 Consumer queue msg : Test queue message2 Consumer2 queue msg : Test queue message3 ... 根据控制台输出的消息可以看出，当有多个消费者监听一个队列时，消费者会自动均衡负载的接收消息，并且每个消息只能有一个消费者所接收。 注意：控制台输出 javax.jms.JMSException: peer (vm://localhost#1) stopped. 报错信息可以忽略，这是 Info 级别的错误，是 ActiveMQ 的一个 bug。 广播（Topic） 广播发送的消息，可以被多个消费者接收。 实现广播模式需要修改如下配置： # 默认值为 false，表示 queue 模式 spring.jms.pub-sub-domain=true 创建 Topic @Configuration public class MqConfig { @Bean public Topic topic() { return new ActiveMQTopic(\"ben.topic\"); } } 使用 @Configuration 注解在项目启动时，定义了一个广播 Topic 命名为：ben.topic。 消息生产者 创建一个消息的生产者: @Slf4j @Component public class Producer { @Autowired private JmsMessagingTemplate jmsMessagingTemplate; @Autowired private Topic topic; public void sendTopic(String msg) { log.info(\"send topic msg : {}\", msg); jmsMessagingTemplate.convertAndSend(topic, msg); } } 和上面的生产者对比只是 convertAndSend() 方法传入的第一个参数变成了 Topic 。 消息消费者 @Slf4j @Component public class Consumer { @JmsListener(destination = \"ben.topic\") public void receiveTopic(String text) { log.info(\"Consumer topic msg : {}\", text); } } 消费者也没有变化，只是监听的名改为上面的 ben.topic，因为模拟多个消费者，复制一份 Consumer 命名为 Consumer2，代码相同在输出中标明来自 Consumer2 。 测试 创建 SampleActiveMqTests 测试类，注入创建好的消息生产者。 @Test public void sendSimpleTopicMessage() throws InterruptedException { producer.sendTopic(\"Test Topic message\"); Thread.sleep(1000L); } 测试方法执行成功后，会看到控制台输出信息，如下: send topic msg : Test Topic message Consumer topic msg : Test Topic message Consumer2 topic msg : Test Topic message 可以看出两个消费者都收到了发送的消息，从而验证广播（Topic）是一个发送者多个消费者的模式。 同时支持队列（Queue）和广播（Topic） Spring Boot 集成 ActiveMQ 的项目默认只支持队列或者广播中的一种，通过配置项 spring.jms.pub-sub-domain 的值来控制，true 为广播模式，false 为队列模式，默认情况下支持队列模式。 如果需要在同一项目中既支持队列模式也支持广播模式，可以通过 DefaultJmsListenerContainerFactory 创建自定义的 JmsListenerContainerFactory 实例，之后在 @JmsListener 注解中通过 containerFactory 属性引用它。 分别创建两个自定义的 JmsListenerContainerFactory 实例，通过 pubSubDomain 来控制是支持队列模式还是广播模式。 @Configuration @EnableJms public class ActiveMQConfig { @Bean(\"queueListenerFactory\") public JmsListenerContainerFactory queueListenerFactory(ConnectionFactory connectionFactory) { DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setPubSubDomain(false); return factory; } @Bean(\"topicListenerFactory\") public JmsListenerContainerFactory topicListenerFactory(ConnectionFactory connectionFactory) { DefaultJmsListenerContainerFactory factory = new DefaultJmsListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setPubSubDomain(true); return factory; } } 然后在消费者接收的方法中，指明使用 containerFactory 接收消息。 @Slf4j @Component public class Consumer { @JmsListener(destination = \"ben.queue\", containerFactory = \"queueListenerFactory\") public void receiveQueue(String text) { log.info(\"Consumer queue msg : {}\", text); } @JmsListener(destination = \"ben.topic\", containerFactory = \"topicListenerFactory\") public void receiveTopic(String text) { log.info(\"Consumer topic msg : {}\", text); } } 改造完成之后，再次执行队列和广播的测试方法，就会发现项目同时支持了两种类型的消息收发。 "},"Part-II/middleware/message-queue/rabbitmq/01-路由-虚拟主机.html":{"url":"Part-II/middleware/message-queue/rabbitmq/01-路由-虚拟主机.html","title":"RabbitMQ 中的路由和虚拟主机","keywords":"","body":"RabbitMQ 中的路由和虚拟主机 路由 RabbitMQ 是一个由 Erlang 语言开发的基于 AMQP 标准的开源实现。起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。 由于 Rabbit MQ 遵守/实现的是 AMQP 标准，而 AMQP 规范相较于 JMS 规范『多』了 Exchange 和 Binding 两个角色。消息的生产者需要把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器上的消息应该被发送到哪个队列中。 不同类型的交换器分发消息（至队列）的策略也不同，目前交换器有 4 种类型，除 Headers 类型功能有重复且性能较差，需要了解掌握的有：Direct、Fanout、Topic 。 类型 说明 Direct 其类型的行为是 先匹配、再投送，即在绑定时设定一个 routing_key，消息的 routing_key 与之匹配时，才会被交换器投送到所绑定的队列中去。 Topic 按规则转发消息（最灵活）。 Headers 设置 header attribute 参数类型的交换机。 Fanout 转发消息到所有绑定队列。 Direct 交换器 Direct 类型是 RabbitMQ 默认的交换机类型（也是最简单的模式）：根据 key 全文匹配去寻找队列。 以上图为例： X 和 Q1 的 binding key 是 orange； X 和 Q2 有 2 个 binding key，分别是 black 和 green 。 当 P 发送至 X 的消息中的路由键与这 3 个 binding key 中的某一个对应上时，那么消息就被路由器『转交』到了对应的队列（交给了 队列1，从而 消费者1 收到了消息）。 如果消息种的路由键（routing key）和 Binding 中的绑定键（binding key）一致，交换器就将消息发送到对应的队列中。路由键与队列名称要完全匹配。 相当于 SQL 中的 = 规则。 Topic 交换器 Topic 类型交换机相当于是 Direct 类型的升级版：它允许使用通配符。 Topic 类型的交换机对于 Binding Key 的设置有一定的要求： 以上图为例： P 发送到 X 的消息的 binding key 符合 xxx.orange.xxx 规则，那么，该消息会被 X 转交给 Q1 。 P 发送到 X 的消息的 binding key 符合 xxx.xxx.rabbit 规则，那么，该消息会被 X 转交给 Q2 。 P 发送到 X 的消息的 binding key 符合 lazy.xxx.xxx.xxx.... 规则，那么，该消息会被 X 转交给 Q2 。 Fanout 交换器 Fanout 就是消息广播，完全不考虑 key 的情况，交换器 X 将它收到的所有消息发送给所有与之绑定的消息队列（无一例外）。 Fantout 交换器不处理路由键（有也当作没看见），只是简单地将队列绑定到交换器，发送到交换器的每条消息都会被转发到与该交换器绑定的所有队列中。 相当于子网广播，子网内的每个主机都获得了一份复制的消息。 通过 Fanout 交换器转发消息是最快的。 Headers 交换器 Headers 类型交换器是早期的一种交换器，其工作机制与上述三者完全不一样，而且性能最低。所以现在基本不再使用。 Default 交换器 Default 交换器是一种特殊的 Direct 交换器。当你手动创建一个队列时，后台会自动将这个队列绑定到一个名称为空的 Direct 交换器上，绑定建与队列名称同名。 虚拟主机 虚拟主机（Virtual Host，在 RabbitMQ 中称作 vhost）是 AMQP 规范中的一个基本概念，客户端在连接消息服务器时必须指定一个虚拟主机。 虚拟主机本质上就是一个缩小版的 RabbitMQ 服务器，其内部有自己的队列、交换器、绑定等。 RabbitMQ │ │── 虚拟主机-1 │ │── Queue │ │── Exchange │ └── Binding │ │── 虚拟主机-2 │ │── Queue │ │── Exchange │ └── Binding │ └── 虚拟主机-3 │── Queue │── Exchange └── Binding 比较特别的是，RabbitMQ 中的权限控制是以 vhost 为单位的。也就是说，消息客户端在访问时不能把 vhost-A 中的 Exchange 绑定到 vhost-B 中的 Queue 上。 如果一个 RabbitMQ 服务器被多个应用共用，此时就可以让每一个应用使用一个 vhost，而不用担心相互之间的干扰。 RabbitMQ 中有一个默认的 vhost，它的名字/值是 /，用户名和密码都是 guest 。 RabbitMQ 提供了 rabbitmqclt 工具管理 vhost： # 创建虚拟主机 test rabbitmqctl add_vhost test # 删除虚拟主机 test rabbitmqctl delete_vhost test # 查询当前 RabbitMQ 中所有的虚拟主机 rabbitmqctl list_vhosts "},"Part-II/middleware/message-queue/rabbitmq/02-spring-boot-rabbitmq.html":{"url":"Part-II/middleware/message-queue/rabbitmq/02-spring-boot-rabbitmq.html","title":"Spring Boot 整合 RabbitMQ","keywords":"","body":"Spring Boot 整合 RabbitMQ Spring Boot 提供了 spring-boot-starter-amqp 组件对实现了 AMQP 协议的消息队列（RabbitMQ）的快速整合。 pom.xml org.springframework.boot spring-boot-starter-amqp 配置文件 配置 rabbitmq 的安装地址、端口以及账户信息： spring.application.name=spring-rabbitmq-demo spring.rabbitmq.host=127.0.0.1 spring.rabbitmq.port=5672 spring.rabbitmq.username=guest spring.rabbitmq.password=guest logging.level.root=INFO logging.level.hemiao3000.gitee.io=DEBUG logging.pattern.console=${CONSOLE_LOG_PATTERN:\\ %clr([%15.15t]){faint} \\ %clr(${LOG_LEVEL_PATTERN:%5p}) \\ %clr(|){faint} \\ %clr(%-40.40logger{39}){cyan} \\ %clr(:){faint} %m%n\\ ${LOG_EXCEPTION_CONVERSION_WORD:%wEx}} 简单示例 官方文档称使用下述注解时，需要先使用 @EnableRabbit 注解标注于配置类上，以表示使用 RabbitMQ 的注解功能。不过，经测试，不使用它似乎也可行。稳妥起见的话还是用上。 定义队列 !FILENAME RabbitMQConfig.java // import org.springframework.amqp.core.Queue; @Configuration public class RabbitMQConfig { @Bean public Queue queue() { return new Queue(\"hello\"); } } 定义消息接收者/消费者 !FILENAME HelloReceiver.java @Slf4j @Component @RabbitListener(queues = \"hello\") public class HelloReceiver { @RabbitHandler public void process(String hello) { log.info(\"Receiver : {}\", hello); } } 注意使用注解 @RabbitListener 的 queues 属性指明队列名称，@RabbitHandler 为具体接收的方法。 发送消息（测试并验证） @Autowired private RabbitTemplate rabbitTemplate; @Test public void send() throws InterruptedException { String context = \"hello \" + new Date(); log.info(\"Sender : {}\", context); rabbitTemplate.convertAndSend(\"hello\", context); Thread.sleep(1000l); } 这是一个最简单的案例。上述的代码种，并未明确涉及到 Exchange 的概念，因为这里使用到的是 Default Exchange 。 Default Exchange 的投递规则是：以 Queue Name 作为 Binding Key。因此，我们在代码中，使用 hello 作为 Binding Key 时，消息最终被投递到了 hello 队列。 创建 Exchange、Queue 和 Binding 虽然可以，但是还是不建议在代码中去创建 Exchange、Queue 和 Binding。通常还是在 RabbitMQ 中把这些东西都建好，然后再在代码中访问/操作。 其实，这很类似于 Hibernate/JPA 的建表功能。虽然有这种功能存在，但是使用的机会和场景并不多。通常都是现在数据库中把表建好之后直接使用。除非是测试环境中的临时表，才会用到这种功能。 创建 Exchange @Bean public Exchange exchange() { // return new TopicExchange(\"test-exchange-1\"); return new TopicExchange(\"test-exchange-1\", true, false); } 参数说明： 参数 说明 name 字符串值，exchange 的名称。 durable 布尔值，表示该 exchage 是否持久化。 持久化意味着当 RabbitMQ 重启后，该 exchange 是否会恢复/仍存在。 autoDelete 布尔值，表示当该 exchange 没“人”（queue）用时，是否会被自动删除。 不指定 durable 和 autoDelete 时，默认为 true 和 false 。表示持久化、不用自动删除。 补充，这背后调用的是原生 API 中的 Channel 的 .exchangeDeclare() 方法。 创建 Queue @Bean public Queue queue() { // return new Queue(\"test-queue-1\"); return new Queue(\"test-queue-1\", true, false, false); } 参数说明： 参数 说明 name 字符串值，exchange 的名称。 durable 布尔值，表示该 queue 是否持久化。 持久化意味着当 RabbitMQ 重启后，该 queue 是否会恢复/仍存在。另外，需要注意的是，queue 的持久化不等于其中的消息也会被持久化。 exclusive 布尔值，表示该 queue 是否排它式使用。排它式使用意味着仅声明他的连接可见/可用，其它连接不可见/不可用。 autoDelete 布尔值，表示当该 queue 没“人”（connection）用时，是否会被自动删除。 不指定 durable、exclusive 和 autoDelete 时，默认为 true、 false 和 false 。表示持久化、非排它、不用自动删除。 补充，这背后调用的是原生 API 中的 Channel 的 .queueDeclare() 方法。 创建 Binding @Bean public Binding binding() { return BindingBuilder .bind(queue()) .to(exchange()) .with(\"*.orange.*\") .noargs(); } 发送消息 spring-rabbit 提供了 RabbitTemplate 来简化原生 API 的消息发送方法。 （最简单的情况下），你可以直接要求 Spring 给你注入一个 RabbitTemplate，通过它来发送消息： @Autowired private RabbitTemplate rabbitTemplate; @Test public void demo() { rabbitTemplate.convertAndSend(\"queue-demo-1\", \"hello world\"); } .convertAndSend() 方法的第一个参数是 routing-key，第二个参数是你所要发送的消息。 在没有明确指定 Exchange 的情况下，该消息发送给了 RabbitMQ 的 default-exchange。该 exchage 以队列名作为 routing-key 。 也就是说，上述代码中的 routing-key 是 queue-demo-1，那么该消息最终是发送给 queue-demo-1 队列。 .convertAndSend() 方法是 .send() 方法的包装/简化。.send() 方法的调用相对比较繁琐。 接收/消费消息（PUSH 型） 接收/消费消息的方式有两种：Push 型和 Pull 型。 Push 型表示由 RabbitMQ Broker 负责将消息推送给消费者。消费者在一开始指定/配置监听哪个队列的消息后，就无需考虑其它。当该队列收到消息后，消费者的指定方法就会被触发执行。 PUSH 消费的配置非常简单，对你的消费者类标注 @RabbitListener 注解，为你的消费方法标注 @RabbitHandler 注解即可。当然，前提是消费者类要托管给 Spring： @Component @RabbitListener(queues = \"queue-demo-1\") public class Consumer1 { private static final Logger log = LoggerFactory.getLogger(Consumer1.class); @RabbitHandler public void process(String message) { log.info(\"Consumer 1: {}\", message); } } 甚至，你可以直接将 @RabbitListener 标注在方法上，此时，不需要配套使用 @RabbitHandler 注解。 对象的支持 Spring Boot 已经完美支持对象的发送和接收，不需要额外的配置。不过，需要注意的是所传递的对象需要实现 Serializable 接口。 !声明队列 @Bean public Queue departmentQueue() { return new Queue(\"department\"); } @Autowired private RabbitTemplate rabbitTemplate; @Test public void demo() { Department department = new Department(10L, \"测试\", \"武汉\"); rabbitTemplate.convertAndSend(\"department\", department); } @Component @RabbitListener(queues = \"department\") public class DepartmentReceiver { private static final Logger log = LoggerFactory.getLogger(DepartmentReceiver.class); @RabbitHandler public void process(Department department) { log.info(\"Receiver : {}\", department); } } Topic Exchange Topic 是 RabbitMQ 中最灵活的一种方式，可以根据 routing_key 自由地绑定不同的队列。 考虑到环境中残留的之前的相关信息对测试的影响，如果发现测试代码的执行结果【莫名其妙】，记得在 RabbitMQ 的web 管理系统中将相关内容清除干净，构造一个纯净的测试环境测试。 首先对 Topic 规则配置： /* 两个 Queue */ @Bean public Queue queue1() { return new Queue(\"Q1\"); } @Bean public Queue queue2() { return new Queue(\"Q2\"); } /* 一个 Exchange */ @Bean public Exchange exchange() { return new TopicExchange(\"testTopic\"); } /* 三个 Binding：关联 Exchange 和 Queue */ @Bean public Binding binding1() { return BindingBuilder .bind(queue1()) .to(exchange()) .with(\"*.orange.*\") .noargs(); } @Bean public Binding binding21() { return BindingBuilder .bind(queue2()) .to(exchange()) .with(\"*.*.rabbit\") .noargs(); } @Bean public Binding binding22() { return BindingBuilder .bind(queue2()) .to(exchange()) .with(\"lazy.#\") .noargs(); } 创建两个消费者： @Component @RabbitListener(queues = \"Q1\") public class C1 { private static final Logger log = LoggerFactory.getLogger(C1.class); @RabbitHandler public void process(String message) { log.info(\"C1: {}\", message); } } @Component @RabbitListener(queues = \"Q2\") public class C2 { private static final Logger log = LoggerFactory.getLogger(C2.class); @RabbitHandler public void process(String message) { log.info(\"C2: {}\", message); } } 测试：（这里偷了个懒，没有去创建发送者类，直接在 Junit 中使用了 AmqpTemplate 发送消息）。 @Autowired private AmqpTemplate rabbitTemplate; @Test public void demo1() throws InterruptedException { rabbitTemplate.convertAndSend(\"testTopic\", \"hello.orange\", \"hello orange\"); rabbitTemplate.convertAndSend(\"testTopic\", \"hello.orange.world\", \"hello orange world\"); rabbitTemplate.convertAndSend(\"testTopic\", \"hello.world.rabbit\", \"hello world rabbit\"); rabbitTemplate.convertAndSend(\"testTopic\", \"lazy\", \"lazy\"); rabbitTemplate.convertAndSend(\"testTopic\", \"lazy.good\", \"good\"); rabbitTemplate.convertAndSend(\"testTopic\", \"lazy.good.bye\", \"goodbye\"); Thread.sleep(1000L); } Fanout Exchange @Bean public Queue green() { return new Queue(\"green\"); } @Bean public Queue red() { return new Queue(\"red\"); } @Bean public Queue orange() { return new Queue(\"orange\"); } @Bean public FanoutExchange exchange() { return new FanoutExchange(\"testFanout\"); } @Bean public Binding binging1() { return BindingBuilder.bind(green()).to(exchange()); } @Bean public Binding binging2() { return BindingBuilder.bind(red()).to(exchange()); } @Bean public Binding binging3() { return BindingBuilder.bind(orange()).to(exchange()); } @Test public void demo2() throws InterruptedException { rabbitTemplate.convertAndSend(\"testFanout\", \"\", \"green\"); rabbitTemplate.convertAndSend(\"testFanout\", \"\", \"red\"); rabbitTemplate.convertAndSend(\"testFanout\", \"\", \"orange\"); Thread.sleep(1000L); } Customer-A、Customer-B、Customer-C 都会收到这三条消息，即，控制台会打印出 9 条日志。 接收/消费消息（PULL 型） PULL 型消费意味着需要消费者主动从 RabbitMQ Broker 上【取】消息。 PULL 型消费不依靠 @RabbitListener 和 @RabbitHandler 注解。而是需要在代码中手动调用 .receiveAndConvert() 方法。 .receiveAndConvert() 方法是 .receive() 方法的简化版。 @Test public void demo5() { rabbitTemplate.convertAndSend(\"queue-demo-1\", \"hello world\"); } @Test public void demo4() { log.info(\"{}\", rabbitTemplate.receiveAndConvert(\"queue-demo-1\")); } 发送者确认 发送者如何知道自己所发送的消费成功抵达了 RabbitMQ Broker 中的 Exchange 中，乃至成功抵达了 RabbitMQ Broker 中的 Queue 中？ 生产者确认 你可以为 RabbitTemplate 注册两个回调函数，当消息没有成功抵达 Queue 或者 Exchange 时，这两个回调函数会被调用。你（消费生产者）自然就知道消息发生失败了。 # 确认消息已发送到交换机（Exchange） spring.rabbitmq.publisher-confirms=true # 确认消息已发送到队列（Queue） spring.rabbitmq.publisher-returns=true 虽然可以不样，但是通常这两个属性都是同步开关保持一致的。 在之前的代码中，是 spring-rabbit 帮我们创建 ConnectionFactory，再进一步创建 RabbitTemplate，并注入到我们的代码中进而被我们使用。 现在由于需要对 RabbitTemplate 进行设置，因此，我们需要自己创建并设置 RabbitTemplate。（不过，还是需要 spring-rabbit 帮我们创建 Connection Factory，并注入） @Bean public RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory) { RabbitTemplate rabbitTemplate = new RabbitTemplate(); rabbitTemplate.setConnectionFactory(connectionFactory); // 设置开启 Mandatory，才能触发回调函数，无论消息推送结果怎么样都强制调用回调函数 rabbitTemplate.setMandatory(true); // 关键就是以下两句 rabbitTemplate.setConfirmCallback( ... ); rabbitTemplate.setReturnCallback( ... ); return rabbitTemplate; } 你可以使用 lamda 表达式来简化下列匿名实现类。 rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() { @Override public void confirm(CorrelationData correlationData, boolean ack, java.lang.String cause) { if (ack) { log.info(\"消息已发送至 Exchange\"); } else { log.info(\"消息未能发送到 Exchange。{}\", cause); } } }); rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() { @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) { log.info(\"ReturnCallback 消息：{}\", message); log.info(\"ReturnCallback 回应码：{}\", replyCode); log.info(\"ReturnCallback 回应信息：{}\", replyText); log.info(\"ReturnCallback 交换机：{}\", exchange); log.info(\"ReturnCallback 路由键：{}\", routingKey); } }); 你可以向不存在的 Exchange 和 Queue 发送消息已验证效果。 消费端的确认与拒绝 默认情况下，RabbitMQ 启用的是消费端自动（auto）回复。即，当消费端收到消息，就会给 RabbitMQ Broker 作出回复，表示已收到。 只有在消费端回复 RabbitMQ Broker 之后，RabbitMQ Broker 才会将该消息从消息队列中移除。 回复的行为除了有 AUTO 之外，还有 NONE 和 MANUAL 。 NONE 表示不回复，即，RabbitMQ Broker 永远不可能知道消费者端到底有没有收到消息。RabbitMQ Broker 发出 MANUAL 则意味着需要在消费者端手动发送回复信息。在消费者回复前，该消息在消费端未回复前在 RabbitMQ Brocker 上一直处于Unacked 状态。 启用消费端的确认功能需要打开配置开关： spring.rabbitmq.listener.simple.acknowledge-mode=manual spring.rabbitmq.listener.direct.acknowledge-mode=manual 于此同时，消息消费者的处理方法需要改造成以下形式： @Component @RabbitListener(queues = \"queue-demo-1\") public class Consumer2 { @RabbitHandler public void process(String message, Channel channel, @Header(AmqpHeaders.DELIVERY_TAG) long tag) { ... } } 确认消息 确认消息使用 channel 的 .basicAck() 方法： channel.basicAck(tag, false); basicAck 方法需要传递两个参数： deliveryTag（唯一标识 ID）：当一个消费者向 RabbitMQ 注册后，会建立起一个 Channel ，RabbitMQ 会用 basic.deliver 方法向消费者推送消息，这个方法携带了一个 delivery tag， 它代表了 RabbitMQ 向该 Channel 投递的这条消息的唯一标识 ID，是一个单调递增的正整数，delivery tag 的范围仅限于 Channel 。 multiple：为了减少网络流量，手动确认可以被批处理，当该参数为 true 时，则可以一次性确认 delivery_tag 小于等于传入值的所有消息。 拒绝消息 拒绝消息使用 channel 的 .basicReject() 方法： channel.basicReject(tag, false); basicReject 方法也需要传力两个参数： deliveryTag（唯一标识 ID）：同上。 requeue（重入标识）：标识该消息是否需要 RabbitMQ Broker 重新入队。（有可能的话，会被该队列的其它消费者消费）。 另外，拒绝的方法还有 .basicNack()，表示批量拒绝。 "},"Part-I/99-webmagic爬虫.html":{"url":"Part-I/99-webmagic爬虫.html","title":"WebMagic 爬虫","keywords":"","body":"Web Magic 爬虫框架 使用 Web Magic 时，如果使用的是较低版本的 JDK，会导致一些 https:// 网页无法爬取，所以确保你安装的是 JDK 8，并且使用的是 JDK 8 的编译标准。 pom.xml us.codecraft webmagic-core 0.7.3 us.codecraft webmagic-extension 0.7.3 maven 项目的默认编译级别是 JDK 5，为了『告诉』maven 使用 JDK 8 的标准进行编译（前提是你安装的 JDK 确实是 8 ），需要加入两个 maven 环境变量： UTF-8 1.8 1.8 ... webmagic 使用了 log4j2 日志框架，如果你使用的是其他的日志框架，那记得将它排除掉： org.slf4j slf4j-log4j12 或者干脆就使用 log4j2 日志框架。在 classpath 下提供 log4j2 的配置文件： !FILENAME log4j.properties log4j.rootLogger=WARN, stdout log4j.logger.xxx.yyy.zzz=WARN, stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%20t %5p | %m%n 一个简单的例子 !FILENAME ExamplePageProcessor.java import us.codecraft.webmagic.Page; import us.codecraft.webmagic.Site; import us.codecraft.webmagic.Spider; import us.codecraft.webmagic.pipeline.ConsolePipeline; import us.codecraft.webmagic.processor.PageProcessor; import us.codecraft.webmagic.selector.Selectable; public class ExamplePageProcessor implements PageProcessor { // 抓取网站的相关配置，包括：编码、抓取间隔、重试次数等 private Site site = Site.me().setRetryTimes(3).setSleepTime(1000); @Override public void process(Page page) { Selectable selectable = page.getHtml().css(\"div.content\"); System.out.println(selectable); } @Override public Site getSite() { return site; } public static void main(String[] args) { Spider.create(new ExamplePageProcessor()) .addUrl(\"http://my.oschina.net/flashsword/blog\") .run(); } } Page 对象 当指定的页面被 webmagic 爬下来之后，PageProcessor 的 .process() 方法会被触发执行。 webmagic 在调用 .process() 方法时，传入的 Page 对象就代表着所爬下来的页面。其中，最常用的是获得该页面的 URL 和页面内容。 System.out.println(page.getUrl().toString()); System.out.println(page.getHtml().toString()); // 这个字符串会很长... .css() 方法 通过 page.getHtml() 我们可以从代码中拿到所请求的页面的全部内容。但是，通常我们感兴趣/需要的是页面上的某个或某些内容，而非整个页面内容全部。 .css() 方法借用 CSS 选择器的语法，可以让我们从这个页面内容中选中我们感兴趣/需要的元素片段。例如： Selectable selectable = page.getHtml().css(\"div.content\"); System.out.println(selectable.toString()); 这里的 .css() 方法的参数 div.content 的写法和 CSS 选择器的写法是一摸一样，它匹配/选中的是页面上 元素。 .css() 方法返回的是被选中/符合条件的页面元素中的第一个。如果，想获得所有符合条件的元素（而不仅仅是第一个），那么需要多调用一个 .nodes() 方法： List list = page.getHtml().css(\"div.content\").nodes(); 当然，如果页面上有且仅有一个元素符合选中条件，那么，返回的 List 中也就只有一个 Selectable 对象。 CSS 选择器语法见最后。 对于 .css() 方法返回的 Selectable 对象，可以 再次调用 .css() 方法，表示语句此选中的内容（HTML片段）再进一步在其内部进行选择。例如： Selectable selectable1 = page.getHtml().css(\"div.content\"); Selectable selectable2 = selectable1.css(\"div.text\"); System.out.println(selectable2); XPath 和 .xpath() 方法 当通过 .css() 方法选中了你所需要的元素后，你感兴趣的内容可能是这个/这些元素的属性值，或文本内容。更有甚者，还可能是它们的子孙元素的属性值，或文本内容。 这时，你需要对 .css() 方法的返回的 Selectable 再进一步调用 .xpath() 方法。 显而易见，.xpath() 方法利用了 XPath 概念。XPath 是一门在 XML 文档中查找信息的语言。XPath 可用来在 XML 文档中对元素和属性进行遍历。 XPath 最常用的路径表达式： 表达式 描述 nodename 选取此节点的所有子节点。 / 从根节点选取。 // 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。 . 选取当前节点。 .. 选取当前节点的父节点。 @ 选取属性。 例如： 路径表达式 结果 bookstore 选取 bookstore 元素，不强求它必须是根元素。 /bookstore 选取 bookstore 元素，并且，它必须是根元素。 bookstore/book 选取 bookstore 元素的名为 book 的子元素。 //book 选取所有 book 子元素，不强求它必须是根元素 bookstore//book 选择属于 bookstore 元素的后代中名为 book 的元素，不强求 book 必须是 bookstore 的直接子元素。 /bookstore/book/title 选取 bookstore 的子元素 book 的子元素 title /bookstore/book[1]/title 选取 bookstore 的第一个 book 子元素的 title 子元素。 /bookstore/book/price/text() 选取 booksotre 元素的 book 子元素的 price 子元素的文本内容 /bookstore/book/@lang 选取 booksotre 元素的 book 子元素的 lang 属性的属性值 一个更复杂的 XPATH：/bookstore/book[@lang='eng']/price/text() 选取 booksotre 元素的 lang 属性值为 eng 的 book 子元素的 price 子元素的文本内容。| 更多的语法和示例可参看 w3school 教程。 @Override public void process(Page page) { System.out.println(page.getUrl().toString()); List selectableList = page.getHtml().css(\"li.fl\").nodes(); for (Selectable selectable : selectableList) { String content = selectable.xpath(\"/li/div/p[1]/a/@href\").get(); if (StringUtils.isNotBlank(content)) System.out.println(content); } } Pipeline 机制和 ConsolePipeline 我们对从『爬』到的页面上『抠』出来的数据的处理（System.out.println()）的处理是写死在 .process() 方法中的。 更优雅的方案是使用 webmagic 的 Pipeline 机制。 在创建 Spider 对象（并启动运行时），你可以指定一个或多个 Pipeline 对象： Spider.create(new ExamplePageProcessor()) .addUrl(\"https://www.1905.com/mdb/film/list/year-2019/\") .addPipeline(new ConsolePipeline()) // 看这里 .run(); 当 PageProcessor 的 .process() 方法执行完后，Pipeline 的 .process() 会执行。 在 PageProcessor 中，你可以将需要后续处理的数据放入到 page 对象中： page.putField(\"xxx\", ...); page.putField(\"yyy\", ...); page.putField(\"zzz\", ...); 在 Pipeline 中，你可以再将上面存在 page 中的数据取出来，再进一步进行处理： resultItems.get(\"xxx\"); resultItems.get(\"yyy\"); resultItems.get(\"zzz\"); 另外，可以通过 lambda 表达式来简化自定义 Pipeline 。 另外，Spider 的 Pipeline 可以有多个。这多个 Pipeline 会依次执行（这才是它较管道的原因）。 Spider.create(new App()) .addUrl(\"http://my.oschina.net/flashsword/blog\") .addPipeline((resultItems, task) -> { System.out.println(\"第 1 个 pipeline 被触发执行\"); }) .addPipeline((resultItems, task) -> { System.out.println(\"第 2 个 pipeline 被触发执行\"); }) .addPipeline((resultItems, task) -> { System.out.println(\"第 3 个 pipeline 被触发执行\"); }) .run(); 你可以利用这个特性实现这样的效果：在第 1 个 Pipeline 中做第一道数据加工操作，在第 2 个 Pipeline 中在做第二道数据加工操作，... 。 page.addTargetRequest() 通常，我们需要爬取的并非一个页面，而是一系列页面。常见的需求是这样：爬取第一个页面，从其中摘取某些信息，并以此为依据构造第二个页面 URL，继续爬取第二个页面，...。 在 Processor 的 .process() 方法中，调用 page.addTargetRequest() 可以动态地告知 Spider 接下来要爬取的页面。整个代码结构类似于： @Override public void process(Page page) { if ( page.getUrl().get() 是页面1 ) { ... page.addTargetRequest(页面2); } else if ( page.getUrl().get() 是页面2 ) { ... page.addTargetRequest(页面3); } else if ( page.getUrl().get() 是页面3 ) { ... } ... } 例如： public class SimpleProcessor implements PageProcessor { private static final Logger log = LoggerFactory.getLogger(App.class); // 抓取网站的相关配置，包括：编码、抓取间隔、重试次数等 private Site site = Site.me().setRetryTimes(3).setSleepTime(1000); @Override public void process(Page page) { if (Objects.equals(page.getUrl().get(), \"https://www.1905.com/mdb/film/list/year-2019\")) { List selectableList = page.getHtml().css(\"li.fl>div\").nodes(); for (Selectable selectable : selectableList) { String idContent = selectable.xpath(\"/div/p[1]/a/@href\").get(); if (StringUtils.isNotBlank(idContent)) { String[] tokens = StringUtils.split(idContent, \"/\"); String id = tokens[tokens.length - 1]; log.info(\"{}\", id); page.addTargetRequest(String.format(\"https://www.1905.com/mdb/film/%s/performer/?fr=mdbypsy_dh_yzry\", id)); } } } else if (StringUtils.startsWith(page.getUrl().get(), \"https://www.1905.com/mdb/film/\") && StringUtils.endsWith(page.getUrl().get(), \"/performer/?fr=mdbypsy_dh_yzry\")) { log.info(\"{}\", page.getUrl().get()); } } @Override public Site getSite() { return site; } public static void main(String[] args) { Spider.create(new SimpleProcessor()) .addUrl(\"https://www.1905.com/mdb/film/list/year-2019\") .run(); } } 多线程 默认情况下，Webmagic 仅使用一个线程（当前线程）爬取网页内容，如果有需要，可以指定多个线程： public static void main(String[] args) { Spider.create(new SimpleProcessor()) .addUrl(\"https://www.1905.com/mdb/film/list/year-2019\") .thread(5) .run(); } 一个关于空格的小问题 有时候你在页面上看到的空格有全角、半角之分，看起来并没有任何区别。但是字符串的 .split() 和 trim() 方法处理的都是半角空格。 所以，你会看到调用了 trim() 方法但是似乎没起作用的情况。 这种情况下可以先将全角空格替换为半角空格之后，再作处理。 content = content.replaceAll(\"\\\\u00A0\",\" \"); 附：CSS 选择器 CSS 选择器决定了后续规则将应用于哪些元素。 CSS 核心选择器 选择器 解释 ``* 选中所有的元素 xxx 选中的元素必须是 xxx 类型元素。即， .xxx 选中的元素的 class 属性的值必须 是/有 xxx 。即，class=\"xxx ...\" #xxx 选中的元素的 id 属性的值必须是 xxx 。即，id=xxx 注意，由于 class 属性的值可以有多个，选中同时具备两个 class 属性值的元素的写法为：.xxx.yyy，即，所选中元素的 class = \"xxx yyy\" 。 CSS 属性选择器 属性选择器是基于属性名及属性的值进行选择页面元素。 选择器 解释 [attr] 选中的元素必须具有 attr 属性。 [attr=\"val\"] 选中的元素必须具有 attr 属性，且属性值为 val。 [attr^=\"val\"] 选中的元素必须具有 attr 属性，且属性值是以 val 开头。 [attr$=\"val\"] 选中的元素必须具有 attr 属性，且属性值是以 val 结尾。 [attr*=\"val\"] 选中的元素必须具有 attr 属性，且属性值含有 val（可以有其他值）。 选择器的复合使用 选择器的复合使用，从程序员的角度来看，就是以 与 和 或 的关系组合使用多个选择器，选择页面元素。 选择器的“与”关系：，将两个选择器“紧挨”在一起，就是以 与 的关系使用选择器选择页面元素。其选择结果必定（必须）同时满足两个选择器。 注意：此处两个选择器间不能有空格。有空格则表达了另一种关系，不再是 与 的关系。 选择器的“或”关系：, ，将两个选择器以逗号（,）分隔，就是以 或 的关系使用选择器选择页面元素。其选择结果只需满足两者其一即可。 注意，此处逗号后的空格可有可无。 亲属关系选择器 亲属关系选择器会涉及到元素的层次结构。 选择器 解释 选中的元素要满足 选择器 2 ，并且，祖先 要满足 选择器 1 。 > 选中的元素要满足 选择器 2 ，并且，爸爸 要满足 选择器 1 。 + 选中的元素要满足 选择器 2 ，并且，紧邻的前一个元素 要满足 选择器 1 。 ~ 选中的元素要满足 选择器 2 ，并且，哥哥 要满足 选择器 1 。 "},"Part-I/Gist/jdbc.properties.html":{"url":"Part-I/Gist/jdbc.properties.html","title":"jdbc.properties","keywords":"","body":"jdbc.properties jdbc .properties 和命令行类似，原则上一行就是一个键值对，如果因为值太长需要折行继续编写，那么上一行的行尾需要加 \\ 表示本行还未结束 。 !FILENAME jdbc.properties datasource.driver-class-name=com.mysql.cj.jdbc.Driver datasource.url=jdbc:mysql://127.0.0.1:3306/scott\\ ?useUnicode=true\\ &characterEncoding=utf-8\\ &useSSL=true\\ &serverTimezone=UTC datasource.username=root datasource.password=123456 "},"Part-I/Gist/logback.xml.html":{"url":"Part-I/Gist/logback.xml.html","title":"logback.xml","keywords":"","body":"logback.xml logback.xml 1.0 !FILENAME 简单的例子 %5p --- %-40.40logger{39} : %m%n utf8 logback.xml 2.0 !FILENAME 更复杂的例子 %d{yyyy-MM-dd HH:mm:ss} %5p ---- %-40.40logger{39} : %m%n utf8 %d{yyyy-MM-dd HH:mm:ss.SSS} %5p ---- [%15.15t] %-40.40logger{39} : %m%n utf8 ${LOG_FILE} ${LOG_FILE}.%d{yyyy-MM-dd}.%i.gz 10MB 0 的关联关系 --> "},"Part-I/Gist/pom.xml.html":{"url":"Part-I/Gist/pom.xml.html","title":"pom.xml","keywords":"","body":"pom.xml 文件模板 版本信息来源说明 以下的版本信息截取自 spring-boot-starter 2.0.9 和 mybatis-spring-boot 2.0.1 。 spring-boot-starter 2.0.9 是 spring cloud Finchley.SR4（ Apr, 2019）使用的版本； mybatis-spring-boot 2.0.1 最低支持的 spring boot 版本刚好最低也是支持 2.0.9 。 几个『高版』本的注意事项： lombok 的高版本依赖于 JDK 9，因此版本不要过高。（1.6 和 1.8 版本出现过这种情况）。 hibernate-validator 的高版本（邮箱注解）依赖于高版本的 el-api，tomcat 8 的 el-api 是 3.0 满足需要，但是 tomcat 7 的 el-api 只有 2.2，不满足其要求。 mysql-connector-java 高版本（6 及以上）有两处变动: 驱动类变为：com.mysql.cj.jdbc.Driver，多了个 cj url 中需要明确指定 serverTimezone，例如：...&serverTimezone=UTC properties 1.0 !FILENAME pom 的 properties 部分 UTF-8 1.8 1.8 1.14.8 1.7.26 1.2.3 3.7 5.0.13.RELEASE 1.8.14 3.1.0 2.2 1.2 2.9.8 5.4.3.Final 5.1.47 2.7.9 3.5.1 2.0.1 5.1.8 5.2.18.Final 1.0.2.Final 2.0.1 5.15.9 5.4.3 2.0.12.RELEASE 5.0.12.RELEASE 4.12 1.4.199 dependencies 1.0 SSM logback + lombok + jackson + hibernate-validator hikaricp + mybatis-pagehelper !FILENAME dependencies和build/plugins部分 org.projectlombok lombok ${lombok.version} ch.qos.logback logback-classic ${logback.version} org.apache.commons commons-lang3 ${commons-lang3.version} org.aspectj aspectjweaver ${aspectj.version} com.fasterxml.jackson.core jackson-databind ${jackson.version} org.springframework spring-webmvc ${spring.version} javax.servlet javax.servlet-api ${servlet-api.version} provided javax.servlet.jsp jsp-api ${jsp-api.version} provided javax.servlet jstl ${jstl.version} org.hibernate hibernate-validator ${hibernate-validator.version} org.springframework spring-jdbc ${spring.version} com.zaxxer HikariCP ${hikaricp.version} mysql mysql-connector-java ${mysql.version} org.mybatis mybatis-spring ${mybatis-spring.version} org.mybatis mybatis ${mybatis.version} com.github.pagehelper pagehelper ${pagehelper.version} org.springframework spring-test ${spring.version} test junit junit ${junit.version} test ${project.artifactId} src/main/java **/*.xml **/*.properties src/main/resources org.apache.tomcat.maven tomcat7-maven-plugin 2.2 8080 /${project.artifactId} UTF-8 dependencies 2.0 spring-mvc + mysql-driver + hikaricp org.springframework spring-webmvc ${spring.version} javax.servlet javax.servlet-api ${servlet-api.version} provided javax.servlet.jsp jsp-api ${jsp-api.version} provided javax.servlet jstl ${jstl.version} org.hibernate hibernate-validator ${hibernate-validator.version} mysql mysql-connector-java ${mysql.version} com.zaxxer HikariCP ${hikaricp.version} ${project.artifactId} org.apache.tomcat.maven tomcat7-maven-plugin 2.2 /${project.artifactId} 8080 UTF-8 settings.xml /path/to/local/repo --> nexus-aliyun Nexus aliyun * http://maven.aliyun.com/nexus/content/groups/public jdk-1.8 true 1.8 1.8 1.8 1.8 "},"Part-I/Gist/web.xml.html":{"url":"Part-I/Gist/web.xml.html","title":"web.xml","keywords":"","body":"web.xml 文件模板 web.xml web.xml 只利用一次加载时机 Archetype Created Web Application HelloWeb org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:application-context.xml 1 HelloWeb *.do web.xml 3.0 利用两次加载时机 Archetype Created Web Application org.springframework.web.context.ContextLoaderListener contextConfigLocation classpath:spring/spring-service.xml, classpath:spring/spring-dao.xml HelloWeb org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:spring/spring-web.xml 1 HelloWeb *.do web.xml 4.0 启用 Spring MVC 自带的 POST 请求编码过滤器，解决中文乱码问题。 "},"Part-I/Gist/mybatis-config.xml.html":{"url":"Part-I/Gist/mybatis-config.xml.html","title":"mybatis-config.xml","keywords":"","body":"mybatis-config.xml mybatis-config.xml 1.0 none mybatis-config.xml 2.0 none mybatis-config.xml 3.0 SSM 整合时使用，开启 id 主键回填功能。 "},"Part-I/Gist/spring-dao.xml.html":{"url":"Part-I/Gist/spring-dao.xml.html","title":"spring-dao.xml","keywords":"","body":"spring-dao.xml for Myabtis 默认 Spring 的项目中只能出现一个 context:property-placeholder，你如果想加载多个配置文件，可以在一个配置文件中写多个文件路径名： 另一种办法是下面这样，通过为每一个 placeholder 指定 ignore-unresolvable=\"true\" 让 spring 支持多个 placeholder 。 "},"Part-I/Gist/spring-service.xml.html":{"url":"Part-I/Gist/spring-service.xml.html","title":"spring-service.xml","keywords":"","body":"spring-service.xml for Mybatis for JPA 注意，JPA 的事务管理器和 Mybatis 的事务管理器不一样，不要随便复制粘贴 。其他的部分一样。 "},"Part-I/Gist/spring-web.xml.html":{"url":"Part-I/Gist/spring-web.xml.html","title":"spring-web.xml","keywords":"","body":"spring-web.xml 文件模板 spring-web.xml !FILENAME spring-web.xml "},"Part-I/Gist/dependencies.spring-boot-2.0.9.html":{"url":"Part-I/Gist/dependencies.spring-boot-2.0.9.html","title":"Spring Boot 2.0.9 版本","keywords":"","body":" 5.15.9 2.7.7 1.9.73 2.4.0 1.8.14 3.9.1 4.0.6 2.1.4 3.0.0 1.7.11 2.6.2 3.4.0 1.3.4 1.11 2.2.0 3.7 1.6 2.5.0 2.1.0 2.5.9 10.14.2.0 1.6.1 3.2.6 2.10.6 3.5.3 5.6.16 2.0.3 1.5.0 1.0.1 5.0.7 2.3.28 2.2.6 3.0.0 2.4.16 2.8.5 1.4.199 1.3 3.9.4 1.2.3 5.2.18.Final 1.0.2.Final 6.0.16.Final 2.7.9 2.4.1 2.29 4.1.4 4.5.8 4.4.11 9.1.7.Final 2.9 2.9.8 3.0.12 1.3.2 1.1.0 2.3.1 2.0.1 1.1.4 1.0 1.6.2 1.0.3 1.2 2.0.1.Final 1.1.6 3.0.5 3.3.2.Final 7.6.0.Final 2.0.6 2.9.3 2.26 5.3.4 9.4.15.v20190215 8.5.35.1 2.2.0.v201112011158 1.14 4.5.2 2.9.9 1.1.11 1.1.11 1.5.0 3.10.8 1.5.0 2.4.0 1.2 1.3.1 4.12 5.1.1 1.1.0 1.0.2 1.2.71 5.0.5.RELEASE 3.5.5 2.10.0 1.2.3 1.16.22 2.2.6 1.8 3.1.1 3.0.0 3.7.0 3.0.2 2.8.2 2.10 3.0.0-M2 2.21.0 2.2 2.5.2 3.1.0 3.0.2 3.0.1 3.0.2 2.4.3 3.6 3.0.1 2.21.0 3.1.0 1.0.10 2.15.0 3.6.4 1.7.1 6.2.2.jre8 5.1.47 5.8.2.Final 1.9.22 3.1.8 4.1.34.Final 1.1.0 42.2.5 2.3.1 4.1.4 5.4.3 1.0.2 Bismuth-SR17 3.0.7 1.3.8 2.1.17 1.2.1 3.9.1 2.29.3 4.1.2 3.1.0 1.1.1 1.7.26 1.19 6.6.6 5.0.13.RELEASE 2.0.12.RELEASE 4.0.3.RELEASE 2.0.5.RELEASE Kay-SR14 0.25.1.RELEASE 5.0.13.RELEASE 2.1.12.RELEASE 2.3.2.RELEASE 1.2.0.RELEASE 2.0.3.RELEASE 1.2.4.RELEASE 5.0.12.RELEASE Apple-SR9 3.0.7.RELEASE 3.21.0.1 3.1.0 1.6.2 3.0.11.RELEASE 2.0.1 3.0.4.RELEASE 3.0.4.RELEASE 3.0.4.RELEASE 2.3.0 8.5.39 4.0.10 1.4.27.Final 2.3 3325375 0.35 1.6.3 1.4.01 1.0.2 2.5.1 "},"Part-I/Gist/dependencies.mybatis-spring-boot-2.0.1.html":{"url":"Part-I/Gist/dependencies.mybatis-spring-boot-2.0.1.html","title":"Mybatis Spring 2.0.1 版本","keywords":"","body":"与 spring-boot 2.0.9 对应 3.5.1 2.0.1 2.0.9.RELEASE "}}